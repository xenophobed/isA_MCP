#!/usr/bin/env python3
"""
Real Semantic Enricher Test - Step 2
ä½¿ç”¨çœŸå®æµ·å…³è´¸æ˜“æ•°æ®æµ‹è¯•è¯­ä¹‰å¢å¼ºå™¨
"""

import sys
import json
from pathlib import Path
from datetime import datetime

# Add project root to path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from tools.services.data_analytics_service.services.metadata_service import MetadataDiscoveryService
from tools.services.data_analytics_service.services.semantic_enricher import SemanticEnricher, SemanticMetadata

# çœŸå®æ•°æ®åº“é…ç½®
REAL_DB_CONFIG = {
    "type": "postgresql",
    "host": "localhost", 
    "port": 5432,
    "database": "customs_trade_db",
    "username": "xenodennis",
    "password": "",
    "include_data_analysis": True,
    "sample_size": 1000
}

def test_semantic_enricher_initialization():
    """æµ‹è¯•è¯­ä¹‰å¢å¼ºå™¨åˆå§‹åŒ–"""
    print("ğŸ”§ æµ‹è¯•è¯­ä¹‰å¢å¼ºå™¨åˆå§‹åŒ–...")
    
    enricher = SemanticEnricher()
    
    # éªŒè¯åˆå§‹åŒ–
    if not hasattr(enricher, 'business_keywords'):
        print("âŒ ç¼ºå°‘business_keywordså±æ€§")
        return False
    
    if not hasattr(enricher, 'pattern_detectors'):
        print("âŒ ç¼ºå°‘pattern_detectorså±æ€§")
        return False
    
    # éªŒè¯ä¸šåŠ¡å…³é”®è¯
    expected_domains = ['customer', 'product', 'order', 'financial', 'temporal']
    for domain in expected_domains:
        if domain not in enricher.business_keywords:
            print(f"âŒ ç¼ºå°‘ä¸šåŠ¡åŸŸ: {domain}")
            return False
        print(f"âœ… ä¸šåŠ¡åŸŸ: {domain} - {len(enricher.business_keywords[domain])} ä¸ªå…³é”®è¯")
    
    print("âœ… è¯­ä¹‰å¢å¼ºå™¨åˆå§‹åŒ–æµ‹è¯•é€šè¿‡")
    return True

def test_enrich_real_metadata():
    """æµ‹è¯•ä½¿ç”¨çœŸå®å…ƒæ•°æ®è¿›è¡Œè¯­ä¹‰å¢å¼º"""
    print("\nğŸ§  æµ‹è¯•çœŸå®å…ƒæ•°æ®è¯­ä¹‰å¢å¼º...")
    
    # è·å–çœŸå®å…ƒæ•°æ®
    service = MetadataDiscoveryService()
    
    try:
        print("ğŸ“Š è·å–æµ·å…³è´¸æ˜“æ•°æ®åº“å…ƒæ•°æ®...")
        metadata = service.discover_database_metadata(REAL_DB_CONFIG)
        
        if not metadata or 'tables' not in metadata:
            print(f"âŒ å…ƒæ•°æ®è·å–å¤±è´¥")
            return False
        print(f"âœ… æˆåŠŸè·å–å…ƒæ•°æ®: {len(metadata['tables'])} è¡¨, {len(metadata['columns'])} å­—æ®µ")
        
        # åˆå§‹åŒ–è¯­ä¹‰å¢å¼ºå™¨
        enricher = SemanticEnricher()
        
        print("ğŸ” å¼€å§‹è¯­ä¹‰å¢å¼º...")
        semantic_metadata = enricher.enrich_metadata(metadata)
        
        # éªŒè¯ç»“æœ
        if not isinstance(semantic_metadata, SemanticMetadata):
            print("âŒ è¿”å›ç»“æœç±»å‹é”™è¯¯")
            return False
        
        print("âœ… è¯­ä¹‰å¢å¼ºå®Œæˆ")
        
        # éªŒè¯ä¸šåŠ¡å®ä½“
        entities = semantic_metadata.business_entities
        print(f"ğŸ“‹ å‘ç° {len(entities)} ä¸ªä¸šåŠ¡å®ä½“:")
        
        key_entities = ['companies', 'declarations', 'goods_details', 'hs_codes']
        found_entities = []
        
        for entity in entities:
            entity_name = entity['entity_name']
            entity_type = entity['entity_type']
            confidence = entity['confidence']
            importance = entity['business_importance']
            
            print(f"   - {entity_name}: {entity_type} (ç½®ä¿¡åº¦: {confidence:.2f}, é‡è¦æ€§: {importance})")
            
            if entity_name in key_entities:
                found_entities.append(entity_name)
        
        for key_entity in key_entities:
            if key_entity in found_entities:
                print(f"âœ… æ‰¾åˆ°å…³é”®å®ä½“: {key_entity}")
            else:
                print(f"âš ï¸ æœªæ‰¾åˆ°å…³é”®å®ä½“: {key_entity}")
        
        # éªŒè¯è¯­ä¹‰æ ‡ç­¾
        tags = semantic_metadata.semantic_tags
        print(f"\nğŸ·ï¸ ç”Ÿæˆ {len(tags)} ä¸ªè¯­ä¹‰æ ‡ç­¾:")
        
        # æ˜¾ç¤ºä¸€äº›å…³é”®æ ‡ç­¾
        key_tables = ['companies', 'declarations', 'goods_details']
        for table in key_tables:
            table_key = f"table:{table}"
            if table_key in tags:
                table_tags = tags[table_key]
                print(f"   - {table}: {', '.join(table_tags)}")
        
        # éªŒè¯æ•°æ®æ¨¡å¼
        patterns = semantic_metadata.data_patterns
        print(f"\nğŸ“Š æ£€æµ‹åˆ° {len(patterns)} ä¸ªæ•°æ®æ¨¡å¼:")
        
        for pattern in patterns:
            pattern_type = pattern['pattern_type']
            description = pattern['description']
            confidence = pattern['confidence']
            print(f"   - {pattern_type}: {description} (ç½®ä¿¡åº¦: {confidence:.2f})")
        
        # éªŒè¯ä¸šåŠ¡è§„åˆ™
        rules = semantic_metadata.business_rules
        print(f"\nğŸ“ æ¨æ–­å‡º {len(rules)} ä¸ªä¸šåŠ¡è§„åˆ™:")
        
        for rule in rules[:5]:  # æ˜¾ç¤ºå‰5ä¸ªè§„åˆ™
            rule_type = rule['rule_type']
            description = rule['description']
            confidence = rule['confidence']
            print(f"   - {rule_type}: {description} (ç½®ä¿¡åº¦: {confidence:.2f})")
        
        if len(rules) > 5:
            print(f"   ... è¿˜æœ‰ {len(rules) - 5} ä¸ªè§„åˆ™")
        
        # éªŒè¯åŸŸåˆ†ç±»
        domain = semantic_metadata.domain_classification
        print(f"\nğŸ¯ åŸŸåˆ†ç±»:")
        print(f"   - ä¸»è¦åŸŸ: {domain['primary_domain']}")
        print(f"   - ç½®ä¿¡åº¦: {domain['confidence']:.2f}")
        print(f"   - å¤šåŸŸç³»ç»Ÿ: {domain['is_multi_domain']}")
        
        # æ˜¾ç¤ºåŸŸå¾—åˆ†
        domain_scores = domain['domain_scores']
        print("   - åŸŸå¾—åˆ†:")
        for domain_name, score in domain_scores.items():
            if score > 0:
                print(f"     * {domain_name}: {score:.2f}")
        
        # éªŒè¯ç½®ä¿¡åº¦å¾—åˆ†
        confidence_scores = semantic_metadata.confidence_scores
        print(f"\nğŸ“ˆ ç½®ä¿¡åº¦è¯„ä¼°:")
        for aspect, score in confidence_scores.items():
            print(f"   - {aspect}: {score:.2f}")
        
        print("âœ… çœŸå®å…ƒæ•°æ®è¯­ä¹‰å¢å¼ºæµ‹è¯•é€šè¿‡")
        return True, semantic_metadata
        
    except Exception as e:
        print(f"âŒ è¯­ä¹‰å¢å¼ºæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False, None

def test_business_entity_extraction(metadata):
    """æµ‹è¯•ä¸šåŠ¡å®ä½“æå–"""
    print("\nğŸ¢ æµ‹è¯•ä¸šåŠ¡å®ä½“æå–...")
    
    enricher = SemanticEnricher()
    entities = enricher._extract_business_entities(metadata)
    
    print(f"ğŸ“‹ æå–åˆ° {len(entities)} ä¸ªä¸šåŠ¡å®ä½“")
    
    # éªŒè¯æµ·å…³è´¸æ˜“åŸŸçš„å…³é”®å®ä½“
    customs_entities = {
        'companies': ['entity', 'reference'],
        'declarations': ['transaction'],
        'goods_details': ['transaction'], 
        'hs_codes': ['reference'],
        'ports': ['reference']
    }
    
    found_customs_entities = 0
    for entity in entities:
        entity_name = entity['entity_name']
        entity_type = entity['entity_type']
        
        if entity_name in customs_entities:
            expected_types = customs_entities[entity_name]
            if entity_type in expected_types:
                print(f"âœ… {entity_name}: {entity_type} âœ“")
                found_customs_entities += 1
            else:
                print(f"âš ï¸ {entity_name}: {entity_type} (æœŸæœ›: {expected_types})")
                found_customs_entities += 1
    
    print(f"âœ… æ‰¾åˆ° {found_customs_entities}/{len(customs_entities)} ä¸ªæµ·å…³å…³é”®å®ä½“")
    
    # éªŒè¯å®ä½“å±æ€§
    for entity in entities[:3]:  # æ£€æŸ¥å‰3ä¸ªå®ä½“
        print(f"\nğŸ“ å®ä½“è¯¦æƒ…: {entity['entity_name']}")
        print(f"   - ç±»å‹: {entity['entity_type']}")
        print(f"   - ç½®ä¿¡åº¦: {entity['confidence']:.2f}")
        print(f"   - å…³é”®å±æ€§: {', '.join(entity['key_attributes'][:3])}")
        print(f"   - è®°å½•æ•°: {entity['record_count']}")
        print(f"   - ä¸šåŠ¡é‡è¦æ€§: {entity['business_importance']}")
        
        if entity['relationships']:
            print(f"   - å…³ç³»: {len(entity['relationships'])} ä¸ª")
    
    print("âœ… ä¸šåŠ¡å®ä½“æå–æµ‹è¯•é€šè¿‡")
    return True

def test_semantic_tags_generation(metadata):
    """æµ‹è¯•è¯­ä¹‰æ ‡ç­¾ç”Ÿæˆ"""
    print("\nğŸ·ï¸ æµ‹è¯•è¯­ä¹‰æ ‡ç­¾ç”Ÿæˆ...")
    
    enricher = SemanticEnricher()
    tags = enricher._generate_semantic_tags(metadata)
    
    print(f"ğŸ“Š ç”Ÿæˆ {len(tags)} ä¸ªè¯­ä¹‰æ ‡ç­¾")
    
    # éªŒè¯è¡¨çº§æ ‡ç­¾
    table_tags_count = 0
    column_tags_count = 0
    
    for key, tag_list in tags.items():
        if key.startswith('table:'):
            table_tags_count += 1
            table_name = key.split(':', 1)[1]
            if table_name in ['companies', 'declarations', 'goods_details']:
                print(f"ğŸ“‹ {table_name}: {', '.join(tag_list)}")
        elif key.startswith('column:'):
            column_tags_count += 1
    
    print(f"âœ… è¡¨æ ‡ç­¾: {table_tags_count} ä¸ª")
    print(f"âœ… å­—æ®µæ ‡ç­¾: {column_tags_count} ä¸ª")
    
    # éªŒè¯å…³é”®å­—æ®µçš„è¯­ä¹‰æ ‡ç­¾
    key_columns = [
        'companies.company_code',
        'companies.company_name', 
        'declarations.rmb_amount',
        'declarations.declare_date'
    ]
    
    for col in key_columns:
        col_key = f"column:{col}"
        if col_key in tags:
            col_tags = tags[col_key]
            print(f"ğŸ“ {col}: {', '.join(col_tags)}")
        else:
            print(f"âš ï¸ æœªæ‰¾åˆ° {col} çš„æ ‡ç­¾")
    
    print("âœ… è¯­ä¹‰æ ‡ç­¾ç”Ÿæˆæµ‹è¯•é€šè¿‡")
    return True

def test_data_pattern_detection(metadata):
    """æµ‹è¯•æ•°æ®æ¨¡å¼æ£€æµ‹"""
    print("\nğŸ“Š æµ‹è¯•æ•°æ®æ¨¡å¼æ£€æµ‹...")
    
    enricher = SemanticEnricher()
    patterns = enricher._detect_data_patterns(metadata)
    
    print(f"ğŸ” æ£€æµ‹åˆ° {len(patterns)} ä¸ªæ•°æ®æ¨¡å¼")
    
    # éªŒè¯æ¨¡å¼ç±»å‹
    pattern_types = set()
    for pattern in patterns:
        pattern_type = pattern['pattern_type']
        pattern_types.add(pattern_type)
        
        description = pattern['description']
        confidence = pattern['confidence']
        print(f"   - {pattern_type}: {description} (ç½®ä¿¡åº¦: {confidence:.2f})")
        
        if 'tables_involved' in pattern:
            tables = pattern['tables_involved']
            print(f"     æ¶‰åŠè¡¨: {', '.join(tables)}")
        
        if 'columns_involved' in pattern:
            columns = pattern['columns_involved']
            print(f"     æ¶‰åŠå­—æ®µ: {', '.join(columns[:3])}{'...' if len(columns) > 3 else ''}")
    
    print(f"âœ… æ£€æµ‹åˆ°çš„æ¨¡å¼ç±»å‹: {', '.join(pattern_types)}")
    
    # éªŒè¯æœŸæœ›çš„æ¨¡å¼ï¼ˆåŸºäºæµ·å…³è´¸æ˜“æ•°æ®ç‰¹å¾ï¼‰
    expected_patterns = ['master_detail', 'temporal']
    for expected in expected_patterns:
        if expected in pattern_types:
            print(f"âœ… æ‰¾åˆ°æœŸæœ›æ¨¡å¼: {expected}")
        else:
            print(f"âš ï¸ æœªæ‰¾åˆ°æœŸæœ›æ¨¡å¼: {expected}")
    
    print("âœ… æ•°æ®æ¨¡å¼æ£€æµ‹æµ‹è¯•é€šè¿‡")
    return True

def test_business_rules_inference(metadata):
    """æµ‹è¯•ä¸šåŠ¡è§„åˆ™æ¨æ–­"""
    print("\nğŸ“ æµ‹è¯•ä¸šåŠ¡è§„åˆ™æ¨æ–­...")
    
    enricher = SemanticEnricher()
    entities = enricher._extract_business_entities(metadata)
    rules = enricher._infer_business_rules(metadata, entities)
    
    print(f"âš–ï¸ æ¨æ–­å‡º {len(rules)} ä¸ªä¸šåŠ¡è§„åˆ™")
    
    # åˆ†ç±»è§„åˆ™ç±»å‹
    rule_types = {}
    for rule in rules:
        rule_type = rule['rule_type']
        if rule_type not in rule_types:
            rule_types[rule_type] = 0
        rule_types[rule_type] += 1
    
    print("ğŸ“Š è§„åˆ™ç±»å‹åˆ†å¸ƒ:")
    for rule_type, count in rule_types.items():
        print(f"   - {rule_type}: {count} ä¸ª")
    
    # æ˜¾ç¤ºä¸€äº›å…³é”®è§„åˆ™
    print("\nğŸ“ å…³é”®ä¸šåŠ¡è§„åˆ™:")
    for rule in rules[:5]:
        rule_type = rule['rule_type']
        description = rule['description']
        confidence = rule['confidence']
        tables = rule['tables_involved']
        
        print(f"   - {rule_type}: {description}")
        print(f"     ç½®ä¿¡åº¦: {confidence:.2f}, æ¶‰åŠè¡¨: {', '.join(tables)}")
        
        if 'sql_constraint' in rule:
            sql = rule['sql_constraint']
            print(f"     SQLçº¦æŸ: {sql[:50]}{'...' if len(sql) > 50 else ''}")
    
    if len(rules) > 5:
        print(f"   ... è¿˜æœ‰ {len(rules) - 5} ä¸ªè§„åˆ™")
    
    # éªŒè¯å¿…è¦çš„è§„åˆ™ç±»å‹
    expected_rule_types = ['referential_integrity', 'uniqueness', 'data_validation']
    for expected in expected_rule_types:
        if expected in rule_types:
            print(f"âœ… æ‰¾åˆ°æœŸæœ›è§„åˆ™ç±»å‹: {expected}")
        else:
            print(f"âš ï¸ æœªæ‰¾åˆ°æœŸæœ›è§„åˆ™ç±»å‹: {expected}")
    
    print("âœ… ä¸šåŠ¡è§„åˆ™æ¨æ–­æµ‹è¯•é€šè¿‡")
    return True

def test_domain_classification(metadata):
    """æµ‹è¯•åŸŸåˆ†ç±»"""
    print("\nğŸ¯ æµ‹è¯•åŸŸåˆ†ç±»...")
    
    enricher = SemanticEnricher()
    entities = enricher._extract_business_entities(metadata)
    domain_classification = enricher._classify_domain(metadata, entities)
    
    print("ğŸ” åŸŸåˆ†ç±»ç»“æœ:")
    
    primary_domain = domain_classification['primary_domain']
    confidence = domain_classification['confidence']
    domain_scores = domain_classification['domain_scores']
    is_multi_domain = domain_classification['is_multi_domain']
    
    print(f"   - ä¸»è¦åŸŸ: {primary_domain}")
    print(f"   - ç½®ä¿¡åº¦: {confidence:.2f}")
    print(f"   - å¤šåŸŸç³»ç»Ÿ: {is_multi_domain}")
    
    print("\nğŸ“Š å„åŸŸå¾—åˆ†:")
    sorted_scores = sorted(domain_scores.items(), key=lambda x: x[1], reverse=True)
    for domain, score in sorted_scores:
        if score > 0:
            print(f"   - {domain}: {score:.2f}")
    
    # éªŒè¯æ˜¯å¦æ­£ç¡®è¯†åˆ«ä¸ºè´¸æ˜“/ç‰©æµç›¸å…³åŸŸ
    trade_related_domains = ['ecommerce', 'finance', 'crm']
    if primary_domain in trade_related_domains:
        print(f"âœ… æ­£ç¡®è¯†åˆ«ä¸ºè´¸æ˜“ç›¸å…³åŸŸ: {primary_domain}")
    else:
        print(f"âš ï¸ åŸŸåˆ†ç±»å¯èƒ½ä¸å‡†ç¡®: {primary_domain}")
        # å¯¹äºæµ·å…³æ•°æ®ï¼Œå¯èƒ½éœ€è¦æ‰©å±•åŸŸåˆ†ç±»è¯æ±‡
    
    print("âœ… åŸŸåˆ†ç±»æµ‹è¯•é€šè¿‡")
    return True

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹è¯­ä¹‰å¢å¼ºå™¨çœŸå®æ•°æ®æµ‹è¯•")
    print("=" * 60)
    print(f"æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    tests = [
        ("è¯­ä¹‰å¢å¼ºå™¨åˆå§‹åŒ–", test_semantic_enricher_initialization),
    ]
    
    passed_tests = 0
    failed_tests = 0
    metadata = None
    semantic_metadata = None
    
    # è¿è¡ŒåŸºç¡€æµ‹è¯•
    for test_name, test_func in tests:
        try:
            print(f"{'='*15} {test_name} {'='*15}")
            if test_func():
                passed_tests += 1
                print(f"âœ… {test_name} æµ‹è¯•é€šè¿‡")
            else:
                failed_tests += 1
                print(f"âŒ {test_name} æµ‹è¯•å¤±è´¥")
        except Exception as e:
            failed_tests += 1
            print(f"âŒ {test_name} æµ‹è¯•å¼‚å¸¸: {e}")
    
    # è¿è¡Œä¸»è¦æµ‹è¯•
    print(f"\n{'='*15} çœŸå®å…ƒæ•°æ®è¯­ä¹‰å¢å¼º {'='*15}")
    try:
        success, semantic_metadata = test_enrich_real_metadata()
        if success:
            passed_tests += 1
            print("âœ… çœŸå®å…ƒæ•°æ®è¯­ä¹‰å¢å¼º æµ‹è¯•é€šè¿‡")
            metadata = semantic_metadata.original_metadata
        else:
            failed_tests += 1
            print("âŒ çœŸå®å…ƒæ•°æ®è¯­ä¹‰å¢å¼º æµ‹è¯•å¤±è´¥")
            return False
    except Exception as e:
        failed_tests += 1
        print(f"âŒ çœŸå®å…ƒæ•°æ®è¯­ä¹‰å¢å¼º æµ‹è¯•å¼‚å¸¸: {e}")
        return False
    
    # è¿è¡Œè¯¦ç»†æµ‹è¯•
    if metadata:
        detailed_tests = [
            ("ä¸šåŠ¡å®ä½“æå–", lambda: test_business_entity_extraction(metadata)),
            ("è¯­ä¹‰æ ‡ç­¾ç”Ÿæˆ", lambda: test_semantic_tags_generation(metadata)),
            ("æ•°æ®æ¨¡å¼æ£€æµ‹", lambda: test_data_pattern_detection(metadata)),
            ("ä¸šåŠ¡è§„åˆ™æ¨æ–­", lambda: test_business_rules_inference(metadata)),
            ("åŸŸåˆ†ç±»", lambda: test_domain_classification(metadata)),
        ]
        
        for test_name, test_func in detailed_tests:
            try:
                print(f"\n{'='*15} {test_name} {'='*15}")
                if test_func():
                    passed_tests += 1
                    print(f"âœ… {test_name} æµ‹è¯•é€šè¿‡")
                else:
                    failed_tests += 1
                    print(f"âŒ {test_name} æµ‹è¯•å¤±è´¥")
            except Exception as e:
                failed_tests += 1
                print(f"âŒ {test_name} æµ‹è¯•å¼‚å¸¸: {e}")
                import traceback
                traceback.print_exc()
    
    print(f"\n{'='*60}")
    print("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»")
    print(f"{'='*60}")
    print(f"âœ… é€šè¿‡: {passed_tests}")
    print(f"âŒ å¤±è´¥: {failed_tests}")
    print(f"ğŸ“ˆ æˆåŠŸç‡: {passed_tests/(passed_tests+failed_tests)*100:.1f}%")
    
    # ä¿å­˜æµ‹è¯•ç»“æœ
    if semantic_metadata:
        result_file = f"semantic_enricher_test_result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        # å‡†å¤‡å¯åºåˆ—åŒ–çš„ç»“æœ
        serializable_result = {
            'business_entities': semantic_metadata.business_entities,
            'semantic_tags': semantic_metadata.semantic_tags,
            'data_patterns': semantic_metadata.data_patterns,
            'business_rules': semantic_metadata.business_rules,
            'domain_classification': semantic_metadata.domain_classification,
            'confidence_scores': semantic_metadata.confidence_scores,
            'test_summary': {
                'total_tests': passed_tests + failed_tests,
                'passed_tests': passed_tests,
                'failed_tests': failed_tests,
                'success_rate': passed_tests/(passed_tests+failed_tests)*100
            }
        }
        
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(serializable_result, f, indent=2, ensure_ascii=False, default=str)
        
        print(f"ğŸ“„ æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {result_file}")
    
    if failed_tests == 0:
        print("\nğŸ‰ æ‰€æœ‰è¯­ä¹‰å¢å¼ºå™¨æµ‹è¯•é€šè¿‡!")
        return True
    else:
        print(f"\nâš ï¸ æœ‰ {failed_tests} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥")
        return False

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)