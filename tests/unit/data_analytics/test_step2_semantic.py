#!/usr/bin/env python3
"""
Individual Test for Step 2: Semantic Enricher
æµ‹è¯•è¯­ä¹‰å¢å¼ºå™¨å•ç‹¬åŠŸèƒ½
"""

import sys
import json
from pathlib import Path
from datetime import datetime

# Add project root to path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from tools.services.data_analytics_service.services.semantic_enricher import SemanticEnricher, SemanticMetadata

# Sample metadata for testing (mimicking real customs data structure)
SAMPLE_METADATA = {
    'tables': [
        {
            'table_name': 'companies',
            'table_type': 'table',
            'record_count': 1000,
            'table_comment': 'Company information',
            'data_quality_score': 0.95
        },
        {
            'table_name': 'declarations',
            'table_type': 'table', 
            'record_count': 10000,
            'table_comment': 'Customs declarations',
            'data_quality_score': 0.88
        },
        {
            'table_name': 'goods_details',
            'table_type': 'table',
            'record_count': 30000,
            'table_comment': 'Goods detail information',
            'data_quality_score': 0.92
        },
        {
            'table_name': 'hs_codes',
            'table_type': 'table',
            'record_count': 500,
            'table_comment': 'HS code reference',
            'data_quality_score': 0.98
        },
        {
            'table_name': 'ports',
            'table_type': 'table',
            'record_count': 100,
            'table_comment': 'Port information',
            'data_quality_score': 0.99
        }
    ],
    'columns': [
        # Companies table
        {
            'table_name': 'companies',
            'column_name': 'company_id',
            'data_type': 'integer',
            'is_nullable': False,
            'unique_percentage': 1.0,
            'null_percentage': 0.0
        },
        {
            'table_name': 'companies',
            'column_name': 'company_code',
            'data_type': 'varchar',
            'is_nullable': False,
            'unique_percentage': 1.0,
            'null_percentage': 0.0
        },
        {
            'table_name': 'companies',
            'column_name': 'company_name',
            'data_type': 'varchar',
            'is_nullable': False,
            'unique_percentage': 0.95,
            'null_percentage': 0.02
        },
        {
            'table_name': 'companies',
            'column_name': 'address',
            'data_type': 'text',
            'is_nullable': True,
            'unique_percentage': 0.80,
            'null_percentage': 0.15
        },
        # Declarations table
        {
            'table_name': 'declarations',
            'column_name': 'declaration_id',
            'data_type': 'integer',
            'is_nullable': False,
            'unique_percentage': 1.0,
            'null_percentage': 0.0
        },
        {
            'table_name': 'declarations',
            'column_name': 'company_id',
            'data_type': 'integer',
            'is_nullable': False,
            'unique_percentage': 0.1,
            'null_percentage': 0.0
        },
        {
            'table_name': 'declarations',
            'column_name': 'declare_date',
            'data_type': 'timestamp',
            'is_nullable': False,
            'unique_percentage': 0.8,
            'null_percentage': 0.0
        },
        {
            'table_name': 'declarations',
            'column_name': 'rmb_amount',
            'data_type': 'decimal',
            'is_nullable': True,
            'unique_percentage': 0.9,
            'null_percentage': 0.05
        },
        # Goods details table
        {
            'table_name': 'goods_details',
            'column_name': 'goods_id',
            'data_type': 'integer',
            'is_nullable': False,
            'unique_percentage': 1.0,
            'null_percentage': 0.0
        },
        {
            'table_name': 'goods_details',
            'column_name': 'declaration_id',
            'data_type': 'integer',
            'is_nullable': False,
            'unique_percentage': 0.3,
            'null_percentage': 0.0
        },
        {
            'table_name': 'goods_details',
            'column_name': 'hs_code_id',
            'data_type': 'integer',
            'is_nullable': False,
            'unique_percentage': 0.02,
            'null_percentage': 0.0
        },
        # HS codes table
        {
            'table_name': 'hs_codes',
            'column_name': 'hs_code_id',
            'data_type': 'integer',
            'is_nullable': False,
            'unique_percentage': 1.0,
            'null_percentage': 0.0
        },
        {
            'table_name': 'hs_codes',
            'column_name': 'hs_code',
            'data_type': 'varchar',
            'is_nullable': False,
            'unique_percentage': 1.0,
            'null_percentage': 0.0
        },
        {
            'table_name': 'hs_codes',
            'column_name': 'description',
            'data_type': 'text',
            'is_nullable': True,
            'unique_percentage': 0.98,
            'null_percentage': 0.02
        }
    ],
    'relationships': [
        {
            'constraint_name': 'fk_declarations_company',
            'from_table': 'declarations',
            'from_column': 'company_id',
            'to_table': 'companies',
            'to_column': 'company_id',
            'constraint_type': 'foreign_key'
        },
        {
            'constraint_name': 'fk_goods_declaration',
            'from_table': 'goods_details',
            'from_column': 'declaration_id',
            'to_table': 'declarations',
            'to_column': 'declaration_id',
            'constraint_type': 'foreign_key'
        },
        {
            'constraint_name': 'fk_goods_hs_code',
            'from_table': 'goods_details',
            'from_column': 'hs_code_id',
            'to_table': 'hs_codes',
            'to_column': 'hs_code_id',
            'constraint_type': 'foreign_key'
        }
    ]
}

def test_semantic_enricher_initialization():
    """æµ‹è¯•è¯­ä¹‰å¢å¼ºå™¨åˆå§‹åŒ–"""
    print("ğŸ”§ æµ‹è¯•è¯­ä¹‰å¢å¼ºå™¨åˆå§‹åŒ–...")
    
    enricher = SemanticEnricher()
    
    # éªŒè¯åˆå§‹åŒ–
    assert hasattr(enricher, 'business_keywords'), "ç¼ºå°‘business_keywordså±æ€§"
    assert hasattr(enricher, 'pattern_detectors'), "ç¼ºå°‘pattern_detectorså±æ€§"
    
    # éªŒè¯ä¸šåŠ¡å…³é”®è¯
    expected_domains = ['customer', 'product', 'order', 'financial', 'temporal']
    for domain in expected_domains:
        assert domain in enricher.business_keywords, f"ç¼ºå°‘ä¸šåŠ¡åŸŸ: {domain}"
        print(f"âœ… ä¸šåŠ¡åŸŸ: {domain} - {len(enricher.business_keywords[domain])} ä¸ªå…³é”®è¯")
    
    print("âœ… è¯­ä¹‰å¢å¼ºå™¨åˆå§‹åŒ–æµ‹è¯•é€šè¿‡")
    return True

def test_enrich_metadata():
    """æµ‹è¯•å…ƒæ•°æ®è¯­ä¹‰å¢å¼ºä¸»æµç¨‹"""
    print("\nğŸ§  æµ‹è¯•å…ƒæ•°æ®è¯­ä¹‰å¢å¼º...")
    
    enricher = SemanticEnricher()
    
    print("ğŸ” å¼€å§‹è¯­ä¹‰å¢å¼º...")
    semantic_metadata = enricher.enrich_metadata(SAMPLE_METADATA)
    
    # éªŒè¯è¿”å›ç»“æœç±»å‹
    assert isinstance(semantic_metadata, SemanticMetadata), "è¿”å›ç»“æœç±»å‹é”™è¯¯"
    print("âœ… è¯­ä¹‰å¢å¼ºå®Œæˆ")
    
    # éªŒè¯ä¸šåŠ¡å®ä½“
    entities = semantic_metadata.business_entities
    print(f"ğŸ“‹ å‘ç° {len(entities)} ä¸ªä¸šåŠ¡å®ä½“:")
    
    key_entities = ['companies', 'declarations', 'goods_details', 'hs_codes']
    found_entities = []
    
    for entity in entities:
        entity_name = entity['entity_name']
        entity_type = entity['entity_type']
        confidence = entity['confidence']
        importance = entity['business_importance']
        
        print(f"   - {entity_name}: {entity_type} (ç½®ä¿¡åº¦: {confidence:.2f}, é‡è¦æ€§: {importance})")
        
        if entity_name in key_entities:
            found_entities.append(entity_name)
    
    for key_entity in key_entities:
        if key_entity in found_entities:
            print(f"âœ… æ‰¾åˆ°å…³é”®å®ä½“: {key_entity}")
        else:
            print(f"âš ï¸ æœªæ‰¾åˆ°å…³é”®å®ä½“: {key_entity}")
    
    # éªŒè¯è¯­ä¹‰æ ‡ç­¾
    tags = semantic_metadata.semantic_tags
    print(f"\nğŸ·ï¸ ç”Ÿæˆ {len(tags)} ä¸ªè¯­ä¹‰æ ‡ç­¾:")
    
    # æ˜¾ç¤ºä¸€äº›å…³é”®æ ‡ç­¾
    key_tables = ['companies', 'declarations', 'goods_details']
    for table in key_tables:
        table_key = f"table:{table}"
        if table_key in tags:
            table_tags = tags[table_key]
            print(f"   - {table}: {', '.join(table_tags)}")
    
    # éªŒè¯æ•°æ®æ¨¡å¼
    patterns = semantic_metadata.data_patterns
    print(f"\nğŸ“Š æ£€æµ‹åˆ° {len(patterns)} ä¸ªæ•°æ®æ¨¡å¼:")
    
    for pattern in patterns:
        pattern_type = pattern['pattern_type']
        description = pattern['description']
        confidence = pattern['confidence']
        print(f"   - {pattern_type}: {description} (ç½®ä¿¡åº¦: {confidence:.2f})")
    
    # éªŒè¯ä¸šåŠ¡è§„åˆ™
    rules = semantic_metadata.business_rules
    print(f"\nğŸ“ æ¨æ–­å‡º {len(rules)} ä¸ªä¸šåŠ¡è§„åˆ™:")
    
    for rule in rules[:5]:  # æ˜¾ç¤ºå‰5ä¸ªè§„åˆ™
        rule_type = rule['rule_type']
        description = rule['description']
        confidence = rule['confidence']
        print(f"   - {rule_type}: {description} (ç½®ä¿¡åº¦: {confidence:.2f})")
    
    if len(rules) > 5:
        print(f"   ... è¿˜æœ‰ {len(rules) - 5} ä¸ªè§„åˆ™")
    
    # éªŒè¯åŸŸåˆ†ç±»
    domain = semantic_metadata.domain_classification
    print(f"\nğŸ¯ åŸŸåˆ†ç±»:")
    print(f"   - ä¸»è¦åŸŸ: {domain['primary_domain']}")
    print(f"   - ç½®ä¿¡åº¦: {domain['confidence']:.2f}")
    print(f"   - å¤šåŸŸç³»ç»Ÿ: {domain['is_multi_domain']}")
    
    # æ˜¾ç¤ºåŸŸå¾—åˆ†
    domain_scores = domain['domain_scores']
    print("   - åŸŸå¾—åˆ†:")
    for domain_name, score in domain_scores.items():
        if score > 0:
            print(f"     * {domain_name}: {score:.2f}")
    
    # éªŒè¯ç½®ä¿¡åº¦å¾—åˆ†
    confidence_scores = semantic_metadata.confidence_scores
    print(f"\nğŸ“ˆ ç½®ä¿¡åº¦è¯„ä¼°:")
    for aspect, score in confidence_scores.items():
        print(f"   - {aspect}: {score:.2f}")
    
    print("âœ… å…ƒæ•°æ®è¯­ä¹‰å¢å¼ºæµ‹è¯•é€šè¿‡")
    return True, semantic_metadata

def test_business_entity_extraction():
    """æµ‹è¯•ä¸šåŠ¡å®ä½“æå–"""
    print("\nğŸ¢ æµ‹è¯•ä¸šåŠ¡å®ä½“æå–...")
    
    enricher = SemanticEnricher()
    entities = enricher._extract_business_entities(SAMPLE_METADATA)
    
    print(f"ğŸ“‹ æå–åˆ° {len(entities)} ä¸ªä¸šåŠ¡å®ä½“")
    
    # éªŒè¯æµ·å…³è´¸æ˜“åŸŸçš„å…³é”®å®ä½“
    customs_entities = {
        'companies': ['entity', 'reference'],
        'declarations': ['transaction'],
        'goods_details': ['transaction'], 
        'hs_codes': ['reference'],
        'ports': ['reference']
    }
    
    found_customs_entities = 0
    for entity in entities:
        entity_name = entity['entity_name']
        entity_type = entity['entity_type']
        
        if entity_name in customs_entities:
            expected_types = customs_entities[entity_name]
            if entity_type in expected_types:
                print(f"âœ… {entity_name}: {entity_type} âœ“")
                found_customs_entities += 1
            else:
                print(f"âš ï¸ {entity_name}: {entity_type} (æœŸæœ›: {expected_types})")
                found_customs_entities += 1
    
    print(f"âœ… æ‰¾åˆ° {found_customs_entities}/{len(customs_entities)} ä¸ªæµ·å…³å…³é”®å®ä½“")
    
    # éªŒè¯å®ä½“å±æ€§
    for entity in entities[:3]:  # æ£€æŸ¥å‰3ä¸ªå®ä½“
        print(f"\nğŸ“ å®ä½“è¯¦æƒ…: {entity['entity_name']}")
        print(f"   - ç±»å‹: {entity['entity_type']}")
        print(f"   - ç½®ä¿¡åº¦: {entity['confidence']:.2f}")
        print(f"   - å…³é”®å±æ€§: {', '.join(entity['key_attributes'][:3])}")
        print(f"   - è®°å½•æ•°: {entity['record_count']}")
        print(f"   - ä¸šåŠ¡é‡è¦æ€§: {entity['business_importance']}")
        
        if entity['relationships']:
            print(f"   - å…³ç³»: {len(entity['relationships'])} ä¸ª")
    
    print("âœ… ä¸šåŠ¡å®ä½“æå–æµ‹è¯•é€šè¿‡")
    return True

def test_semantic_tags_generation():
    """æµ‹è¯•è¯­ä¹‰æ ‡ç­¾ç”Ÿæˆ"""
    print("\nğŸ·ï¸ æµ‹è¯•è¯­ä¹‰æ ‡ç­¾ç”Ÿæˆ...")
    
    enricher = SemanticEnricher()
    tags = enricher._generate_semantic_tags(SAMPLE_METADATA)
    
    print(f"ğŸ“Š ç”Ÿæˆ {len(tags)} ä¸ªè¯­ä¹‰æ ‡ç­¾")
    
    # éªŒè¯è¡¨çº§æ ‡ç­¾
    table_tags_count = 0
    column_tags_count = 0
    
    for key, tag_list in tags.items():
        if key.startswith('table:'):
            table_tags_count += 1
            table_name = key.split(':', 1)[1]
            if table_name in ['companies', 'declarations', 'goods_details']:
                print(f"ğŸ“‹ {table_name}: {', '.join(tag_list)}")
        elif key.startswith('column:'):
            column_tags_count += 1
    
    print(f"âœ… è¡¨æ ‡ç­¾: {table_tags_count} ä¸ª")
    print(f"âœ… å­—æ®µæ ‡ç­¾: {column_tags_count} ä¸ª")
    
    # éªŒè¯å…³é”®å­—æ®µçš„è¯­ä¹‰æ ‡ç­¾
    key_columns = [
        'companies.company_code',
        'companies.company_name', 
        'declarations.rmb_amount',
        'declarations.declare_date'
    ]
    
    for col in key_columns:
        col_key = f"column:{col}"
        if col_key in tags:
            col_tags = tags[col_key]
            print(f"ğŸ“ {col}: {', '.join(col_tags)}")
        else:
            print(f"âš ï¸ æœªæ‰¾åˆ° {col} çš„æ ‡ç­¾")
    
    print("âœ… è¯­ä¹‰æ ‡ç­¾ç”Ÿæˆæµ‹è¯•é€šè¿‡")
    return True

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹Step 2è¯­ä¹‰å¢å¼ºå™¨å•ç‹¬æµ‹è¯•")
    print("=" * 60)
    print(f"æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    tests = [
        ("è¯­ä¹‰å¢å¼ºå™¨åˆå§‹åŒ–", test_semantic_enricher_initialization),
        ("ä¸šåŠ¡å®ä½“æå–", test_business_entity_extraction),
        ("è¯­ä¹‰æ ‡ç­¾ç”Ÿæˆ", test_semantic_tags_generation),
    ]
    
    passed_tests = 0
    failed_tests = 0
    semantic_metadata = None
    
    # è¿è¡ŒåŸºç¡€æµ‹è¯•
    for test_name, test_func in tests:
        try:
            print(f"{'='*15} {test_name} {'='*15}")
            if test_func():
                passed_tests += 1
                print(f"âœ… {test_name} æµ‹è¯•é€šè¿‡")
            else:
                failed_tests += 1
                print(f"âŒ {test_name} æµ‹è¯•å¤±è´¥")
        except Exception as e:
            failed_tests += 1
            print(f"âŒ {test_name} æµ‹è¯•å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
    
    # è¿è¡Œä¸»è¦æµ‹è¯•
    print(f"\n{'='*15} å®Œæ•´è¯­ä¹‰å¢å¼ºæµç¨‹ {'='*15}")
    try:
        success, semantic_metadata = test_enrich_metadata()
        if success:
            passed_tests += 1
            print("âœ… å®Œæ•´è¯­ä¹‰å¢å¼ºæµç¨‹ æµ‹è¯•é€šè¿‡")
        else:
            failed_tests += 1
            print("âŒ å®Œæ•´è¯­ä¹‰å¢å¼ºæµç¨‹ æµ‹è¯•å¤±è´¥")
    except Exception as e:
        failed_tests += 1
        print(f"âŒ å®Œæ•´è¯­ä¹‰å¢å¼ºæµç¨‹ æµ‹è¯•å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
    
    print(f"\n{'='*60}")
    print("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»")
    print(f"{'='*60}")
    print(f"âœ… é€šè¿‡: {passed_tests}")
    print(f"âŒ å¤±è´¥: {failed_tests}")
    print(f"ğŸ“ˆ æˆåŠŸç‡: {passed_tests/(passed_tests+failed_tests)*100:.1f}%")
    
    # ä¿å­˜æµ‹è¯•ç»“æœ
    if semantic_metadata:
        result_file = f"step2_test_result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        # å‡†å¤‡å¯åºåˆ—åŒ–çš„ç»“æœ
        serializable_result = {
            'business_entities': semantic_metadata.business_entities,
            'semantic_tags': semantic_metadata.semantic_tags,
            'data_patterns': semantic_metadata.data_patterns,
            'business_rules': semantic_metadata.business_rules,
            'domain_classification': semantic_metadata.domain_classification,
            'confidence_scores': semantic_metadata.confidence_scores,
            'test_summary': {
                'total_tests': passed_tests + failed_tests,
                'passed_tests': passed_tests,
                'failed_tests': failed_tests,
                'success_rate': passed_tests/(passed_tests+failed_tests)*100
            }
        }
        
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(serializable_result, f, indent=2, ensure_ascii=False, default=str)
        
        print(f"ğŸ“„ æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {result_file}")
    
    if failed_tests == 0:
        print("\nğŸ‰ Step 2è¯­ä¹‰å¢å¼ºå™¨æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
        return True
    else:
        print(f"\nâš ï¸ æœ‰ {failed_tests} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥")
        return False

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)