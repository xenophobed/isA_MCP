#!/usr/bin/env python3
"""
Step 4 Test: æŸ¥è¯¢åŒ¹é…æµ‹è¯•
ä½¿ç”¨Step 2çš„è¯­ä¹‰å¢å¼ºç»“æœå’ŒStep 3çš„å‘é‡å­˜å‚¨è¿›è¡ŒæŸ¥è¯¢åŒ¹é…
"""

import sys
import json
import asyncio
from pathlib import Path
from datetime import datetime

# Add project root to path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# ç›´æ¥å¯¼å…¥
sys.path.insert(0, str(project_root / "tools" / "services" / "data_analytics_service" / "services"))

from query_matcher import QueryMatcher, QueryContext, MetadataMatch, QueryPlan
from embedding_storage import EmbeddingStorage
from semantic_enricher import SemanticMetadata

# æµ‹è¯•æŸ¥è¯¢åˆ—è¡¨
TEST_QUERIES = [
    "Show me all companies with their codes",
    "Find customs declarations from last month", 
    "Get products that have been shipped recently",
    "How many companies are registered?",
    "List all shipping containers and their contents",
    "Show trade volume by country",
    "Find all transactions above 100000",
    "Get customer details for company_code ABC123",
    "Show recent import declarations",
    "List all products with their categories"
]

def load_step2_result():
    """åŠ è½½Step 2çš„è¯­ä¹‰å¢å¼ºç»“æœ"""
    result_file = "semantic_enricher_test_result_20250629_021702.json"
    
    try:
        with open(result_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        print(f"âœ… æˆåŠŸåŠ è½½Step 2ç»“æœ: {result_file}")
        return data
    except FileNotFoundError:
        print(f"âŒ æœªæ‰¾åˆ°Step 2ç»“æœæ–‡ä»¶: {result_file}")
        return None
    except Exception as e:
        print(f"âŒ åŠ è½½Step 2ç»“æœå¤±è´¥: {e}")
        return None

async def test_query_matcher_initialization():
    """æµ‹è¯•æŸ¥è¯¢åŒ¹é…å™¨åˆå§‹åŒ–"""
    print("ğŸ”§ æµ‹è¯•æŸ¥è¯¢åŒ¹é…å™¨åˆå§‹åŒ–...")
    
    try:
        # åˆå§‹åŒ–å‘é‡å­˜å‚¨
        embedding_storage = EmbeddingStorage("customs_trade_db")
        await embedding_storage.initialize()
        
        # åˆå§‹åŒ–æŸ¥è¯¢åŒ¹é…å™¨
        query_matcher = QueryMatcher(embedding_storage)
        
        print("âœ… æŸ¥è¯¢åŒ¹é…å™¨åˆå§‹åŒ–æˆåŠŸ")
        return query_matcher
        
    except Exception as e:
        print(f"âŒ æŸ¥è¯¢åŒ¹é…å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None

async def test_query_context_extraction(query_matcher, test_queries):
    """æµ‹è¯•æŸ¥è¯¢ä¸Šä¸‹æ–‡æå–"""
    print("\nğŸ§  æµ‹è¯•æŸ¥è¯¢ä¸Šä¸‹æ–‡æå–...")
    
    if not query_matcher:
        print("âŒ æŸ¥è¯¢åŒ¹é…å™¨å®ä¾‹æ— æ•ˆ")
        return False
    
    extraction_results = []
    
    for i, query in enumerate(test_queries[:5]):  # æµ‹è¯•å‰5ä¸ªæŸ¥è¯¢
        try:
            print(f"\nğŸ“ æŸ¥è¯¢ {i+1}: {query}")
            
            query_context = await query_matcher._extract_query_context(query)
            
            print(f"   å®ä½“: {query_context.entities_mentioned}")
            print(f"   å±æ€§: {query_context.attributes_mentioned}")
            print(f"   æ“ä½œ: {query_context.operations}")
            print(f"   è¿‡æ»¤å™¨: {len(query_context.filters)}")
            print(f"   èšåˆ: {query_context.aggregations}")
            print(f"   ä¸šåŠ¡æ„å›¾: {query_context.business_intent}")
            print(f"   ç½®ä¿¡åº¦: {query_context.confidence_score:.2f}")
            
            extraction_results.append({
                'query': query,
                'context': {
                    'entities': query_context.entities_mentioned,
                    'attributes': query_context.attributes_mentioned,
                    'operations': query_context.operations,
                    'filters': len(query_context.filters),
                    'aggregations': query_context.aggregations,
                    'business_intent': query_context.business_intent,
                    'confidence_score': query_context.confidence_score
                }
            })
            
        except Exception as e:
            print(f"   âŒ æå–å¤±è´¥: {e}")
            return False
    
    print(f"\nğŸ“Š ä¸Šä¸‹æ–‡æå–å®Œæˆï¼Œå¤„ç†äº† {len(extraction_results)} ä¸ªæŸ¥è¯¢")
    return len(extraction_results) > 0

async def test_metadata_matching(query_matcher, semantic_data):
    """æµ‹è¯•å…ƒæ•°æ®åŒ¹é…"""
    print("\nğŸ” æµ‹è¯•å…ƒæ•°æ®åŒ¹é…...")
    
    if not query_matcher or not semantic_data:
        print("âŒ æŸ¥è¯¢åŒ¹é…å™¨æˆ–è¯­ä¹‰æ•°æ®æ— æ•ˆ")
        return False
    
    try:
        # æ„é€ SemanticMetadataå¯¹è±¡
        semantic_metadata = SemanticMetadata(
            original_metadata=semantic_data.get('original_metadata', {}),
            business_entities=semantic_data.get('business_entities', []),
            semantic_tags=semantic_data.get('semantic_tags', {}),
            data_patterns=semantic_data.get('data_patterns', []),
            business_rules=semantic_data.get('business_rules', []),
            domain_classification=semantic_data.get('domain_classification', {}),
            confidence_scores=semantic_data.get('confidence_scores', {})
        )
        
        # æµ‹è¯•æŸ¥è¯¢
        test_query = "Show me all companies with their codes"
        
        print(f"ğŸ” æµ‹è¯•æŸ¥è¯¢: {test_query}")
        
        # æ‰§è¡ŒåŒ¹é…
        query_context, metadata_matches = await query_matcher.match_query_to_metadata(
            test_query, semantic_metadata
        )
        
        print(f"ğŸ“Š åŒ¹é…ç»“æœ:")
        print(f"   æŸ¥è¯¢ä¸Šä¸‹æ–‡ç½®ä¿¡åº¦: {query_context.confidence_score:.2f}")
        print(f"   æ‰¾åˆ°åŒ¹é…é¡¹: {len(metadata_matches)}")
        
        for i, match in enumerate(metadata_matches[:3]):  # æ˜¾ç¤ºå‰3ä¸ªåŒ¹é…
            print(f"   {i+1}. {match.entity_name} ({match.entity_type}) - {match.match_type}")
            print(f"      ç›¸ä¼¼åº¦: {match.similarity_score:.3f}")
            print(f"      ç›¸å…³å±æ€§: {match.relevant_attributes}")
        
        return len(metadata_matches) > 0
        
    except Exception as e:
        print(f"âŒ å…ƒæ•°æ®åŒ¹é…æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

async def test_query_plan_generation(query_matcher, semantic_data):
    """æµ‹è¯•æŸ¥è¯¢è®¡åˆ’ç”Ÿæˆ"""
    print("\nğŸ“‹ æµ‹è¯•æŸ¥è¯¢è®¡åˆ’ç”Ÿæˆ...")
    
    if not query_matcher or not semantic_data:
        print("âŒ æŸ¥è¯¢åŒ¹é…å™¨æˆ–è¯­ä¹‰æ•°æ®æ— æ•ˆ")
        return False
    
    try:
        # æ„é€ SemanticMetadataå¯¹è±¡
        semantic_metadata = SemanticMetadata(
            original_metadata=semantic_data.get('original_metadata', {}),
            business_entities=semantic_data.get('business_entities', []),
            semantic_tags=semantic_data.get('semantic_tags', {}),
            data_patterns=semantic_data.get('data_patterns', []),
            business_rules=semantic_data.get('business_rules', []),
            domain_classification=semantic_data.get('domain_classification', {}),
            confidence_scores=semantic_data.get('confidence_scores', {})
        )
        
        # æµ‹è¯•æŸ¥è¯¢
        test_query = "How many companies are registered?"
        
        print(f"ğŸ“‹ æµ‹è¯•æŸ¥è¯¢: {test_query}")
        
        # å…ˆè·å–åŒ¹é…
        query_context, metadata_matches = await query_matcher.match_query_to_metadata(
            test_query, semantic_metadata
        )
        
        # ç”ŸæˆæŸ¥è¯¢è®¡åˆ’
        query_plan = await query_matcher.generate_query_plan(
            query_context, metadata_matches, semantic_metadata
        )
        
        print(f"ğŸ“Š æŸ¥è¯¢è®¡åˆ’:")
        print(f"   ä¸»è¦è¡¨: {query_plan.primary_tables}")
        print(f"   æ‰€éœ€è¿æ¥: {len(query_plan.required_joins)}")
        print(f"   é€‰æ‹©åˆ—: {query_plan.select_columns}")
        print(f"   WHEREæ¡ä»¶: {query_plan.where_conditions}")
        print(f"   èšåˆå‡½æ•°: {query_plan.aggregations}")
        print(f"   æ’åº: {query_plan.order_by}")
        print(f"   è®¡åˆ’ç½®ä¿¡åº¦: {query_plan.confidence_score:.2f}")
        print(f"   æ›¿ä»£æ–¹æ¡ˆ: {len(query_plan.alternative_plans)}")
        
        return query_plan.confidence_score > 0.0
        
    except Exception as e:
        print(f"âŒ æŸ¥è¯¢è®¡åˆ’ç”Ÿæˆæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

async def test_related_entities_search(query_matcher):
    """æµ‹è¯•ç›¸å…³å®ä½“æœç´¢"""
    print("\nğŸ”— æµ‹è¯•ç›¸å…³å®ä½“æœç´¢...")
    
    if not query_matcher:
        print("âŒ æŸ¥è¯¢åŒ¹é…å™¨å®ä¾‹æ— æ•ˆ")
        return False
    
    try:
        # æµ‹è¯•å®ä½“
        test_entity = "companies"
        
        print(f"ğŸ” æœç´¢ä¸ '{test_entity}' ç›¸å…³çš„å®ä½“...")
        
        related_entities = await query_matcher.find_related_entities(
            test_entity, relationship_type='related'
        )
        
        print(f"ğŸ“Š æœç´¢ç»“æœ:")
        print(f"   æ‰¾åˆ°ç›¸å…³å®ä½“: {len(related_entities)}")
        
        for i, entity in enumerate(related_entities[:3]):  # æ˜¾ç¤ºå‰3ä¸ª
            print(f"   {i+1}. {entity.entity_name} ({entity.entity_type})")
            print(f"      ç›¸ä¼¼åº¦: {entity.similarity_score:.3f}")
            print(f"      å†…å®¹: {entity.content[:60]}...")
        
        return len(related_entities) > 0
        
    except Exception as e:
        print(f"âŒ ç›¸å…³å®ä½“æœç´¢æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

async def test_query_improvements(query_matcher):
    """æµ‹è¯•æŸ¥è¯¢æ”¹è¿›å»ºè®®"""
    print("\nğŸ’¡ æµ‹è¯•æŸ¥è¯¢æ”¹è¿›å»ºè®®...")
    
    if not query_matcher:
        print("âŒ æŸ¥è¯¢åŒ¹é…å™¨å®ä¾‹æ— æ•ˆ")
        return False
    
    try:
        # æ¨¡æ‹Ÿä¸€ä¸ªä½ç½®ä¿¡åº¦çš„æŸ¥è¯¢è®¡åˆ’
        from query_matcher import QueryPlan
        
        mock_query_plan = QueryPlan(
            primary_tables=['companies'],
            required_joins=[],
            select_columns=['companies.id'],
            where_conditions=[],
            aggregations=[],
            order_by=[],
            confidence_score=0.5,  # ä½ç½®ä¿¡åº¦
            alternative_plans=[]
        )
        
        test_query = "show companies"
        
        print(f"ğŸ’¡ ç”Ÿæˆæ”¹è¿›å»ºè®®: {test_query}")
        
        suggestions = await query_matcher.suggest_query_improvements(
            test_query, mock_query_plan
        )
        
        print(f"ğŸ“Š æ”¹è¿›å»ºè®®:")
        for i, suggestion in enumerate(suggestions):
            print(f"   {i+1}. {suggestion}")
        
        return len(suggestions) > 0
        
    except Exception as e:
        print(f"âŒ æŸ¥è¯¢æ”¹è¿›å»ºè®®æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

async def test_comprehensive_query_workflow(query_matcher, semantic_data):
    """æµ‹è¯•å®Œæ•´æŸ¥è¯¢å·¥ä½œæµ"""
    print("\nğŸ”„ æµ‹è¯•å®Œæ•´æŸ¥è¯¢å·¥ä½œæµ...")
    
    if not query_matcher or not semantic_data:
        print("âŒ æŸ¥è¯¢åŒ¹é…å™¨æˆ–è¯­ä¹‰æ•°æ®æ— æ•ˆ")
        return False
    
    try:
        # æ„é€ SemanticMetadataå¯¹è±¡
        semantic_metadata = SemanticMetadata(
            original_metadata=semantic_data.get('original_metadata', {}),
            business_entities=semantic_data.get('business_entities', []),
            semantic_tags=semantic_data.get('semantic_tags', {}),
            data_patterns=semantic_data.get('data_patterns', []),
            business_rules=semantic_data.get('business_rules', []),
            domain_classification=semantic_data.get('domain_classification', {}),
            confidence_scores=semantic_data.get('confidence_scores', {})
        )
        
        # å¤æ‚æŸ¥è¯¢æµ‹è¯•
        complex_query = "Find all customs declarations from companies in China with value greater than 50000 in the last 6 months"
        
        print(f"ğŸ”„ å¤æ‚æŸ¥è¯¢: {complex_query}")
        
        # æ­¥éª¤1: æå–æŸ¥è¯¢ä¸Šä¸‹æ–‡
        query_context = await query_matcher._extract_query_context(complex_query)
        print(f"   âœ… æŸ¥è¯¢ä¸Šä¸‹æ–‡æå–å®Œæˆ (ç½®ä¿¡åº¦: {query_context.confidence_score:.2f})")
        
        # æ­¥éª¤2: åŒ¹é…å…ƒæ•°æ®
        query_context, metadata_matches = await query_matcher.match_query_to_metadata(
            complex_query, semantic_metadata
        )
        print(f"   âœ… å…ƒæ•°æ®åŒ¹é…å®Œæˆ (æ‰¾åˆ° {len(metadata_matches)} ä¸ªåŒ¹é…)")
        
        # æ­¥éª¤3: ç”ŸæˆæŸ¥è¯¢è®¡åˆ’
        query_plan = await query_matcher.generate_query_plan(
            query_context, metadata_matches, semantic_metadata
        )
        print(f"   âœ… æŸ¥è¯¢è®¡åˆ’ç”Ÿæˆå®Œæˆ (ç½®ä¿¡åº¦: {query_plan.confidence_score:.2f})")
        
        # æ­¥éª¤4: ç”Ÿæˆæ”¹è¿›å»ºè®®
        suggestions = await query_matcher.suggest_query_improvements(
            complex_query, query_plan
        )
        print(f"   âœ… æ”¹è¿›å»ºè®®ç”Ÿæˆå®Œæˆ ({len(suggestions)} ä¸ªå»ºè®®)")
        
        # æ­¥éª¤5: æœç´¢ç›¸å…³å®ä½“
        if metadata_matches:
            primary_entity = metadata_matches[0].entity_name
            related_entities = await query_matcher.find_related_entities(primary_entity)
            print(f"   âœ… ç›¸å…³å®ä½“æœç´¢å®Œæˆ (æ‰¾åˆ° {len(related_entities)} ä¸ªç›¸å…³å®ä½“)")
        
        print(f"ğŸ¯ å®Œæ•´å·¥ä½œæµæ€»ç»“:")
        print(f"   - ä¸»è¦è¡¨: {query_plan.primary_tables}")
        print(f"   - é€‰æ‹©åˆ—: {query_plan.select_columns[:3]}")  # å‰3ä¸ª
        print(f"   - è¿‡æ»¤å™¨: {len(query_context.filters)}")
        print(f"   - èšåˆ: {query_plan.aggregations}")
        print(f"   - æ€»ä½“ç½®ä¿¡åº¦: {query_plan.confidence_score:.2f}")
        
        return query_plan.confidence_score > 0.3
        
    except Exception as e:
        print(f"âŒ å®Œæ•´æŸ¥è¯¢å·¥ä½œæµæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹Step 4æŸ¥è¯¢åŒ¹é…æµ‹è¯•")
    print("=" * 60)
    print(f"æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    # åŠ è½½Step 2ç»“æœ
    semantic_data = load_step2_result()
    if not semantic_data:
        print("âŒ æ— æ³•åŠ è½½Step 2ç»“æœï¼Œæµ‹è¯•ç»ˆæ­¢")
        return False
    
    print(f"ğŸ“Š Step 2æ•°æ®æ¦‚å†µ:")
    print(f"   - ä¸šåŠ¡å®ä½“: {len(semantic_data.get('business_entities', []))}")
    print(f"   - è¯­ä¹‰æ ‡ç­¾: {len(semantic_data.get('semantic_tags', {}))}")
    print(f"   - æ•°æ®æ¨¡å¼: {len(semantic_data.get('data_patterns', []))}")
    print(f"   - ä¸šåŠ¡è§„åˆ™: {len(semantic_data.get('business_rules', []))}")
    print()
    
    passed_tests = 0
    failed_tests = 0
    query_matcher = None
    
    # æµ‹è¯•åˆå§‹åŒ–
    print(f"{'='*15} æŸ¥è¯¢åŒ¹é…å™¨åˆå§‹åŒ– {'='*15}")
    try:
        query_matcher = await test_query_matcher_initialization()
        if query_matcher:
            passed_tests += 1
            print("âœ… æŸ¥è¯¢åŒ¹é…å™¨åˆå§‹åŒ– æµ‹è¯•é€šè¿‡")
        else:
            failed_tests += 1
            print("âŒ æŸ¥è¯¢åŒ¹é…å™¨åˆå§‹åŒ– æµ‹è¯•å¤±è´¥")
            return False
    except Exception as e:
        failed_tests += 1
        print(f"âŒ æŸ¥è¯¢åŒ¹é…å™¨åˆå§‹åŒ– æµ‹è¯•å¼‚å¸¸: {e}")
        return False
    
    # è¿è¡Œåç»­æµ‹è¯•
    if query_matcher:
        tests = [
            ("æŸ¥è¯¢ä¸Šä¸‹æ–‡æå–", lambda: test_query_context_extraction(query_matcher, TEST_QUERIES)),
            ("å…ƒæ•°æ®åŒ¹é…", lambda: test_metadata_matching(query_matcher, semantic_data)),
            ("æŸ¥è¯¢è®¡åˆ’ç”Ÿæˆ", lambda: test_query_plan_generation(query_matcher, semantic_data)),
            ("ç›¸å…³å®ä½“æœç´¢", lambda: test_related_entities_search(query_matcher)),
            ("æŸ¥è¯¢æ”¹è¿›å»ºè®®", lambda: test_query_improvements(query_matcher)),
            ("å®Œæ•´æŸ¥è¯¢å·¥ä½œæµ", lambda: test_comprehensive_query_workflow(query_matcher, semantic_data)),
        ]
        
        for test_name, test_func in tests:
            try:
                print(f"\n{'='*15} {test_name} {'='*15}")
                result = await test_func()
                if result:
                    passed_tests += 1
                    print(f"âœ… {test_name} æµ‹è¯•é€šè¿‡")
                else:
                    failed_tests += 1
                    print(f"âŒ {test_name} æµ‹è¯•å¤±è´¥")
            except Exception as e:
                failed_tests += 1
                print(f"âŒ {test_name} æµ‹è¯•å¼‚å¸¸: {e}")
                import traceback
                traceback.print_exc()
    
    print(f"\n{'='*60}")
    print("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»")
    print(f"{'='*60}")
    print(f"âœ… é€šè¿‡: {passed_tests}")
    print(f"âŒ å¤±è´¥: {failed_tests}")
    if passed_tests + failed_tests > 0:
        print(f"ğŸ“ˆ æˆåŠŸç‡: {passed_tests/(passed_tests+failed_tests)*100:.1f}%")
    
    # ä¿å­˜æµ‹è¯•ç»“æœ
    test_result = {
        'test_time': datetime.now().isoformat(),
        'total_tests': passed_tests + failed_tests,
        'passed_tests': passed_tests,
        'failed_tests': failed_tests,
        'success_rate': passed_tests/(passed_tests+failed_tests)*100 if (passed_tests + failed_tests) > 0 else 0,
        'test_queries': TEST_QUERIES,
        'database_source': 'customs_trade_db'
    }
    
    result_file = f"step4_query_matcher_test_result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(result_file, 'w', encoding='utf-8') as f:
        json.dump(test_result, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ“„ æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {result_file}")
    
    if failed_tests == 0:
        print("\nğŸ‰ Step 4æŸ¥è¯¢åŒ¹é…æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
        return True
    else:
        print(f"\nâš ï¸ æœ‰ {failed_tests} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥")
        return False

if __name__ == "__main__":
    success = asyncio.run(main())
    exit(0 if success else 1)