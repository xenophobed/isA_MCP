#!/usr/bin/env python3
"""
Step 3 Test: å‘é‡å­˜å‚¨æµ‹è¯•
ä½¿ç”¨Step 2çš„è¯­ä¹‰å¢å¼ºç»“æœè¿›è¡Œå‘é‡å­˜å‚¨
"""

import sys
import json
import asyncio
from pathlib import Path
from datetime import datetime

# Add project root to path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# ç›´æ¥å¯¼å…¥
sys.path.insert(0, str(project_root / "tools" / "services" / "data_analytics_service" / "services"))

from embedding_storage import EmbeddingStorage, EmbeddingRecord, SearchResult
from semantic_enricher import SemanticMetadata

# åŠ è½½Step 2çš„ç»“æœ
def load_step2_result():
    """åŠ è½½Step 2çš„è¯­ä¹‰å¢å¼ºç»“æœ"""
    result_file = "semantic_enricher_test_result_20250629_021702.json"
    
    try:
        with open(result_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        print(f"âœ… æˆåŠŸåŠ è½½Step 2ç»“æœ: {result_file}")
        return data
    except FileNotFoundError:
        print(f"âŒ æœªæ‰¾åˆ°Step 2ç»“æœæ–‡ä»¶: {result_file}")
        return None
    except Exception as e:
        print(f"âŒ åŠ è½½Step 2ç»“æœå¤±è´¥: {e}")
        return None

async def test_embedding_storage_initialization():
    """æµ‹è¯•å‘é‡å­˜å‚¨åˆå§‹åŒ–"""
    print("ğŸ”§ æµ‹è¯•å‘é‡å­˜å‚¨åˆå§‹åŒ–...")
    
    try:
        storage = EmbeddingStorage("customs_trade_db")
        await storage.initialize()
        print("âœ… å‘é‡å­˜å‚¨åˆå§‹åŒ–æˆåŠŸ")
        return storage
    except Exception as e:
        print(f"âŒ å‘é‡å­˜å‚¨åˆå§‹åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None

async def test_store_semantic_metadata(storage, semantic_data):
    """æµ‹è¯•å­˜å‚¨è¯­ä¹‰å…ƒæ•°æ®"""
    print("\nğŸ’¾ æµ‹è¯•å­˜å‚¨è¯­ä¹‰å…ƒæ•°æ®...")
    
    if not storage:
        print("âŒ å­˜å‚¨å®ä¾‹æ— æ•ˆ")
        return False
    
    try:
        # æ„é€ SemanticMetadataå¯¹è±¡
        semantic_metadata = SemanticMetadata(
            original_metadata=semantic_data.get('original_metadata', {}),
            business_entities=semantic_data.get('business_entities', []),
            semantic_tags=semantic_data.get('semantic_tags', {}),
            data_patterns=semantic_data.get('data_patterns', []),
            business_rules=semantic_data.get('business_rules', []),
            domain_classification=semantic_data.get('domain_classification', {}),
            confidence_scores=semantic_data.get('confidence_scores', {})
        )
        
        print(f"ğŸ“Š å‡†å¤‡å­˜å‚¨:")
        print(f"   - ä¸šåŠ¡å®ä½“: {len(semantic_metadata.business_entities)}")
        print(f"   - è¯­ä¹‰æ ‡ç­¾: {len(semantic_metadata.semantic_tags)}")
        print(f"   - ä¸šåŠ¡è§„åˆ™: {len(semantic_metadata.business_rules)}")
        print(f"   - æ•°æ®æ¨¡å¼: {len(semantic_metadata.data_patterns)}")
        
        # å­˜å‚¨è¯­ä¹‰å…ƒæ•°æ®
        results = await storage.store_semantic_metadata(semantic_metadata)
        
        print(f"ğŸ“Š å­˜å‚¨ç»“æœ:")
        print(f"   - æˆåŠŸå­˜å‚¨: {results['stored_embeddings']} ä¸ªå‘é‡")
        print(f"   - å¤±è´¥: {results['failed_embeddings']} ä¸ª")
        print(f"   - é”™è¯¯æ•°: {len(results['errors'])}")
        
        if results['errors']:
            print("âš ï¸ é”™è¯¯åˆ—è¡¨:")
            for error in results['errors'][:3]:  # æ˜¾ç¤ºå‰3ä¸ªé”™è¯¯
                print(f"   - {error}")
        
        return results['stored_embeddings'] > 0
        
    except Exception as e:
        print(f"âŒ å­˜å‚¨è¯­ä¹‰å…ƒæ•°æ®å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

async def test_semantic_search(storage):
    """æµ‹è¯•è¯­ä¹‰æœç´¢"""
    print("\nğŸ” æµ‹è¯•è¯­ä¹‰æœç´¢...")
    
    if not storage:
        print("âŒ å­˜å‚¨å®ä¾‹æ— æ•ˆ")
        return False
    
    try:
        # æµ‹è¯•æŸ¥è¯¢
        test_queries = [
            ("å…¬å¸ä¼ä¸šä¿¡æ¯", "table"),
            ("æµ·å…³ç”³æŠ¥å•æ®", "table"),
            ("è´§ç‰©è¯¦ç»†ä¿¡æ¯", None),
            ("ä¸šåŠ¡è§„åˆ™çº¦æŸ", "business_rule"),
            ("æ•°æ®æ¨¡å¼å…³ç³»", "data_pattern")
        ]
        
        search_results = []
        
        for query, entity_type in test_queries:
            print(f"ğŸ” æœç´¢: {query} (ç±»å‹: {entity_type or 'å…¨éƒ¨'})")
            
            results = await storage.search_similar_entities(
                query, 
                entity_type=entity_type, 
                limit=3, 
                similarity_threshold=0.3  # é™ä½é˜ˆå€¼
            )
            
            if results:
                print(f"   æ‰¾åˆ° {len(results)} ä¸ªç›¸ä¼¼ç»“æœ:")
                for i, result in enumerate(results):
                    print(f"   {i+1}. {result.entity_name} ({result.entity_type}) - ç›¸ä¼¼åº¦: {result.similarity_score:.3f}")
                    print(f"      {result.content[:60]}...")
                search_results.extend(results)
            else:
                print("   æœªæ‰¾åˆ°ç›¸ä¼¼ç»“æœ")
        
        print(f"ğŸ“Š æœç´¢æµ‹è¯•å®Œæˆï¼Œæ€»å…±æ‰¾åˆ° {len(search_results)} ä¸ªç»“æœ")
        return len(search_results) > 0
        
    except Exception as e:
        print(f"âŒ è¯­ä¹‰æœç´¢æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

async def test_metadata_stats(storage):
    """æµ‹è¯•å…ƒæ•°æ®ç»Ÿè®¡"""
    print("\nğŸ“Š æµ‹è¯•å…ƒæ•°æ®ç»Ÿè®¡...")
    
    if not storage:
        print("âŒ å­˜å‚¨å®ä¾‹æ— æ•ˆ")
        return False
    
    try:
        stats = await storage.get_metadata_stats()
        
        if stats['success']:
            print("ğŸ“ˆ æ•°æ®åº“ç»Ÿè®¡:")
            for stat in stats['stats']:
                print(f"   - {stat['entity_type']}: {stat['total_entities']} ä¸ª (å¹³å‡ç½®ä¿¡åº¦: {stat['avg_confidence']:.2f})")
            return True
        else:
            print(f"âŒ è·å–ç»Ÿè®¡å¤±è´¥: {stats.get('error')}")
            return False
            
    except Exception as e:
        print(f"âŒ å…ƒæ•°æ®ç»Ÿè®¡æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹Step 3å‘é‡å­˜å‚¨æµ‹è¯•")
    print("=" * 60)
    print(f"æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    # åŠ è½½Step 2ç»“æœ
    semantic_data = load_step2_result()
    if not semantic_data:
        print("âŒ æ— æ³•åŠ è½½Step 2ç»“æœï¼Œæµ‹è¯•ç»ˆæ­¢")
        return False
    
    print(f"ğŸ“Š Step 2æ•°æ®æ¦‚å†µ:")
    print(f"   - ä¸šåŠ¡å®ä½“: {len(semantic_data.get('business_entities', []))}")
    print(f"   - è¯­ä¹‰æ ‡ç­¾: {len(semantic_data.get('semantic_tags', {}))}")
    print(f"   - æ•°æ®æ¨¡å¼: {len(semantic_data.get('data_patterns', []))}")
    print(f"   - ä¸šåŠ¡è§„åˆ™: {len(semantic_data.get('business_rules', []))}")
    print()
    
    passed_tests = 0
    failed_tests = 0
    storage = None
    
    # æµ‹è¯•å‘é‡å­˜å‚¨åˆå§‹åŒ–
    print(f"{'='*15} å‘é‡å­˜å‚¨åˆå§‹åŒ– {'='*15}")
    try:
        storage = await test_embedding_storage_initialization()
        if storage:
            passed_tests += 1
            print("âœ… å‘é‡å­˜å‚¨åˆå§‹åŒ– æµ‹è¯•é€šè¿‡")
        else:
            failed_tests += 1
            print("âŒ å‘é‡å­˜å‚¨åˆå§‹åŒ– æµ‹è¯•å¤±è´¥")
            return False
    except Exception as e:
        failed_tests += 1
        print(f"âŒ å‘é‡å­˜å‚¨åˆå§‹åŒ– æµ‹è¯•å¼‚å¸¸: {e}")
        return False
    
    # è¿è¡Œåç»­æµ‹è¯•
    if storage:
        tests = [
            ("å­˜å‚¨è¯­ä¹‰å…ƒæ•°æ®", lambda: test_store_semantic_metadata(storage, semantic_data)),
            ("è¯­ä¹‰æœç´¢", lambda: test_semantic_search(storage)),
            ("å…ƒæ•°æ®ç»Ÿè®¡", lambda: test_metadata_stats(storage)),
        ]
        
        for test_name, test_func in tests:
            try:
                print(f"\n{'='*15} {test_name} {'='*15}")
                result = await test_func()
                if result:
                    passed_tests += 1
                    print(f"âœ… {test_name} æµ‹è¯•é€šè¿‡")
                else:
                    failed_tests += 1
                    print(f"âŒ {test_name} æµ‹è¯•å¤±è´¥")
            except Exception as e:
                failed_tests += 1
                print(f"âŒ {test_name} æµ‹è¯•å¼‚å¸¸: {e}")
                import traceback
                traceback.print_exc()
    
    print(f"\n{'='*60}")
    print("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»")
    print(f"{'='*60}")
    print(f"âœ… é€šè¿‡: {passed_tests}")
    print(f"âŒ å¤±è´¥: {failed_tests}")
    if passed_tests + failed_tests > 0:
        print(f"ğŸ“ˆ æˆåŠŸç‡: {passed_tests/(passed_tests+failed_tests)*100:.1f}%")
    
    # ä¿å­˜æµ‹è¯•ç»“æœ
    test_result = {
        'test_time': datetime.now().isoformat(),
        'total_tests': passed_tests + failed_tests,
        'passed_tests': passed_tests,
        'failed_tests': failed_tests,
        'success_rate': passed_tests/(passed_tests+failed_tests)*100 if (passed_tests + failed_tests) > 0 else 0,
        'database_source': 'customs_trade_db'
    }
    
    result_file = f"step3_embedding_test_result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(result_file, 'w', encoding='utf-8') as f:
        json.dump(test_result, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ“„ æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {result_file}")
    
    if failed_tests == 0:
        print("\nğŸ‰ Step 3å‘é‡å­˜å‚¨æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
        return True
    else:
        print(f"\nâš ï¸ æœ‰ {failed_tests} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥")
        return False

if __name__ == "__main__":
    success = asyncio.run(main())
    exit(0 if success else 1)