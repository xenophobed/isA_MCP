#!/usr/bin/env python3
"""
Step 5 Test: SQLæ‰§è¡Œå™¨æµ‹è¯•
æµ‹è¯•SQLç”Ÿæˆå’Œæ‰§è¡ŒåŠŸèƒ½ï¼ŒåŒ…æ‹¬LLMå¢å¼ºå’Œä¼ ç»Ÿå›é€€ç­–ç•¥
"""

import sys
import json
import asyncio
from pathlib import Path
from datetime import datetime

# Add project root to path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# ç›´æ¥å¯¼å…¥
sys.path.insert(0, str(project_root / "tools" / "services" / "data_analytics_service" / "services"))

from sql_executor import SQLExecutor, ExecutionResult, FallbackAttempt, ExecutionPlan
from llm_sql_generator import LLMSQLGenerator, SQLGenerationResult
from query_matcher import QueryMatcher, QueryContext, MetadataMatch, QueryPlan
from embedding_storage import EmbeddingStorage
from semantic_enricher import SemanticMetadata

# æ¨¡æ‹Ÿæ•°æ®åº“é…ç½®ï¼ˆå› ä¸ºæˆ‘ä»¬æ²¡æœ‰çœŸå®æ•°æ®åº“è¿æ¥ï¼‰
MOCK_DATABASE_CONFIG = {
    'type': 'postgresql',
    'host': 'localhost',
    'port': 5432,
    'database': 'customs_trade_db',
    'username': 'test_user',
    'password': 'test_password',
    'max_execution_time': 30,
    'max_rows': 1000
}

# æµ‹è¯•æŸ¥è¯¢å’Œè®¡åˆ’
TEST_QUERIES = [
    {
        'name': 'ç®€å•æŸ¥è¯¢',
        'natural_query': 'æ˜¾ç¤ºæ‰€æœ‰å…¬å¸',
        'expected_tables': ['companies']
    },
    {
        'name': 'èšåˆæŸ¥è¯¢',
        'natural_query': 'ç»Ÿè®¡å…¬å¸æ•°é‡',
        'expected_tables': ['companies']
    },
    {
        'name': 'è¿æ¥æŸ¥è¯¢',
        'natural_query': 'æ˜¾ç¤ºå…¬å¸çš„è¿›å£ç”³æŠ¥å•',
        'expected_tables': ['companies', 'declarations']
    }
]

def load_step2_result():
    """åŠ è½½Step 2çš„è¯­ä¹‰å¢å¼ºç»“æœ"""
    result_file = "semantic_enricher_test_result_20250629_021702.json"
    
    try:
        with open(result_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        print(f"âœ… æˆåŠŸåŠ è½½Step 2ç»“æœ: {result_file}")
        return data
    except FileNotFoundError:
        print(f"âŒ æœªæ‰¾åˆ°Step 2ç»“æœæ–‡ä»¶: {result_file}")
        return None
    except Exception as e:
        print(f"âŒ åŠ è½½Step 2ç»“æœå¤±è´¥: {e}")
        return None

async def test_sql_executor_initialization():
    """æµ‹è¯•SQLæ‰§è¡Œå™¨åˆå§‹åŒ–"""
    print("ğŸ”§ æµ‹è¯•SQLæ‰§è¡Œå™¨åˆå§‹åŒ–...")
    
    try:
        # åˆå§‹åŒ–SQLæ‰§è¡Œå™¨ï¼ˆä¸è¿æ¥çœŸå®æ•°æ®åº“ï¼‰
        sql_executor = SQLExecutor(MOCK_DATABASE_CONFIG)
        
        # åˆå§‹åŒ–LLMç”Ÿæˆå™¨
        await sql_executor.initialize_llm()
        
        print("âœ… SQLæ‰§è¡Œå™¨åˆå§‹åŒ–æˆåŠŸ")
        return sql_executor
        
    except Exception as e:
        print(f"âŒ SQLæ‰§è¡Œå™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None

async def test_llm_sql_generation(sql_executor, semantic_data):
    """æµ‹è¯•LLM SQLç”Ÿæˆ"""
    print("\nğŸ§  æµ‹è¯•LLM SQLç”Ÿæˆ...")
    
    if not sql_executor or not semantic_data:
        print("âŒ SQLæ‰§è¡Œå™¨æˆ–è¯­ä¹‰æ•°æ®æ— æ•ˆ")
        return False
    
    try:
        # æ„é€ SemanticMetadataå¯¹è±¡
        semantic_metadata = SemanticMetadata(
            original_metadata=semantic_data.get('original_metadata', {}),
            business_entities=semantic_data.get('business_entities', []),
            semantic_tags=semantic_data.get('semantic_tags', {}),
            data_patterns=semantic_data.get('data_patterns', []),
            business_rules=semantic_data.get('business_rules', []),
            domain_classification=semantic_data.get('domain_classification', {}),
            confidence_scores=semantic_data.get('confidence_scores', {})
        )
        
        # æ¨¡æ‹ŸæŸ¥è¯¢ä¸Šä¸‹æ–‡
        query_context = QueryContext(
            entities_mentioned=['companies'],
            attributes_mentioned=['company_name', 'company_code'],
            operations=['select'],
            filters=[],
            aggregations=[],
            temporal_references=[],
            business_intent='lookup',
            confidence_score=0.8
        )
        
        # æ¨¡æ‹Ÿå…ƒæ•°æ®åŒ¹é…
        metadata_matches = [
            MetadataMatch(
                entity_name='companies',
                entity_type='table',
                match_type='exact',
                similarity_score=1.0,
                relevant_attributes=['company_code', 'company_name'],
                suggested_joins=[],
                metadata={'table_name': 'companies'}
            )
        ]
        
        # æµ‹è¯•LLM SQLç”Ÿæˆ
        test_query = "æ˜¾ç¤ºæ‰€æœ‰å…¬å¸çš„åç§°å’Œä»£ç "
        
        print(f"ğŸ§  æµ‹è¯•æŸ¥è¯¢: {test_query}")
        
        # ç”ŸæˆSQLï¼ˆä¸æ‰§è¡Œï¼‰
        llm_result = await sql_executor.llm_generator.generate_sql_from_context(
            query_context, metadata_matches, semantic_metadata, test_query
        )
        
        print(f"ğŸ“Š LLMç”Ÿæˆç»“æœ:")
        print(f"   SQL: {llm_result.sql}")
        print(f"   è§£é‡Š: {llm_result.explanation}")
        print(f"   ç½®ä¿¡åº¦: {llm_result.confidence_score:.2f}")
        print(f"   å¤æ‚åº¦: {llm_result.complexity_level}")
        
        return llm_result.sql != ""
        
    except Exception as e:
        print(f"âŒ LLM SQLç”Ÿæˆæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

async def test_sql_validation(sql_executor, semantic_data):
    """æµ‹è¯•SQLéªŒè¯åŠŸèƒ½"""
    print("\nğŸ” æµ‹è¯•SQLéªŒè¯...")
    
    if not sql_executor or not semantic_data:
        print("âŒ SQLæ‰§è¡Œå™¨æˆ–è¯­ä¹‰æ•°æ®æ— æ•ˆ")
        return False
    
    try:
        # æ„é€ SemanticMetadataå¯¹è±¡
        semantic_metadata = SemanticMetadata(
            original_metadata=semantic_data.get('original_metadata', {}),
            business_entities=semantic_data.get('business_entities', []),
            semantic_tags=semantic_data.get('semantic_tags', {}),
            data_patterns=semantic_data.get('data_patterns', []),
            business_rules=semantic_data.get('business_rules', []),
            domain_classification=semantic_data.get('domain_classification', {}),
            confidence_scores=semantic_data.get('confidence_scores', {})
        )
        
        # æµ‹è¯•ä¸åŒçš„SQL
        test_sqls = [
            {
                'name': 'æœ‰æ•ˆSQL',
                'sql': 'SELECT company_code, company_name FROM companies LIMIT 10',
                'should_be_valid': True
            },
            {
                'name': 'æ— æ•ˆè¡¨å',
                'sql': 'SELECT * FROM invalid_table LIMIT 10',
                'should_be_valid': False
            },
            {
                'name': 'æ— æ•ˆåˆ—å',
                'sql': 'SELECT invalid_column FROM companies LIMIT 10',
                'should_be_valid': False
            }
        ]
        
        validation_results = []
        
        for test_case in test_sqls:
            print(f"ğŸ” éªŒè¯ {test_case['name']}: {test_case['sql']}")
            
            validation_result = await sql_executor.validate_sql(
                test_case['sql'], semantic_metadata
            )
            
            print(f"   æœ‰æ•ˆæ€§: {validation_result['is_valid']}")
            print(f"   é”™è¯¯: {len(validation_result['errors'])}")
            print(f"   è­¦å‘Š: {len(validation_result['warnings'])}")
            
            if validation_result['errors']:
                print(f"   é”™è¯¯è¯¦æƒ…: {validation_result['errors'][:2]}")
            
            validation_results.append(validation_result)
        
        # éªŒè¯ç»“æœæ˜¯å¦ç¬¦åˆé¢„æœŸ
        valid_count = sum(1 for result in validation_results if result['is_valid'])
        expected_valid = sum(1 for test in test_sqls if test['should_be_valid'])
        
        print(f"ğŸ“Š éªŒè¯ç»“æœ: {valid_count}/{len(test_sqls)} æœ‰æ•ˆï¼Œé¢„æœŸ {expected_valid} æœ‰æ•ˆ")
        
        return len(validation_results) > 0
        
    except Exception as e:
        print(f"âŒ SQLéªŒè¯æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

async def test_query_plan_generation(sql_executor, semantic_data):
    """æµ‹è¯•æŸ¥è¯¢è®¡åˆ’ç”Ÿæˆå’ŒSQLè½¬æ¢"""
    print("\nğŸ“‹ æµ‹è¯•æŸ¥è¯¢è®¡åˆ’ç”Ÿæˆ...")
    
    if not sql_executor or not semantic_data:
        print("âŒ SQLæ‰§è¡Œå™¨æˆ–è¯­ä¹‰æ•°æ®æ— æ•ˆ")
        return False
    
    try:
        # åˆ›å»ºæµ‹è¯•æŸ¥è¯¢è®¡åˆ’
        test_plan = QueryPlan(
            primary_tables=['companies'],
            required_joins=[],
            select_columns=['companies.company_code', 'companies.company_name'],
            where_conditions=[],
            aggregations=[],
            order_by=['companies.company_code'],
            confidence_score=0.9,
            alternative_plans=[]
        )
        
        print(f"ğŸ“‹ æµ‹è¯•æŸ¥è¯¢è®¡åˆ’:")
        print(f"   ä¸»è¦è¡¨: {test_plan.primary_tables}")
        print(f"   é€‰æ‹©åˆ—: {test_plan.select_columns}")
        print(f"   æ’åº: {test_plan.order_by}")
        
        # ç”ŸæˆSQL
        generated_sql = sql_executor._generate_sql_from_plan(test_plan)
        
        print(f"ğŸ“Š ç”Ÿæˆçš„SQL:")
        print(f"   {generated_sql}")
        
        return generated_sql != ""
        
    except Exception as e:
        print(f"âŒ æŸ¥è¯¢è®¡åˆ’ç”Ÿæˆæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

async def test_fallback_strategies(sql_executor, semantic_data):
    """æµ‹è¯•å›é€€ç­–ç•¥"""
    print("\nğŸ”„ æµ‹è¯•å›é€€ç­–ç•¥...")
    
    if not sql_executor or not semantic_data:
        print("âŒ SQLæ‰§è¡Œå™¨æˆ–è¯­ä¹‰æ•°æ®æ— æ•ˆ")
        return False
    
    try:
        # æ„é€ SemanticMetadataå¯¹è±¡
        semantic_metadata = SemanticMetadata(
            original_metadata=semantic_data.get('original_metadata', {}),
            business_entities=semantic_data.get('business_entities', []),
            semantic_tags=semantic_data.get('semantic_tags', {}),
            data_patterns=semantic_data.get('data_patterns', []),
            business_rules=semantic_data.get('business_rules', []),
            domain_classification=semantic_data.get('domain_classification', {}),
            confidence_scores=semantic_data.get('confidence_scores', {})
        )
        
        # æ¨¡æ‹ŸæŸ¥è¯¢ä¸Šä¸‹æ–‡
        query_context = QueryContext(
            entities_mentioned=['companies'],
            attributes_mentioned=[],
            operations=['select'],
            filters=[],
            aggregations=[],
            temporal_references=[],
            business_intent='lookup',
            confidence_score=0.7
        )
        
        # æµ‹è¯•æŸ¥è¯¢è®¡åˆ’
        test_plan = QueryPlan(
            primary_tables=['companies'],
            required_joins=[],
            select_columns=['companies.*'],
            where_conditions=[],
            aggregations=[],
            order_by=[],
            confidence_score=0.8,
            alternative_plans=[]
        )
        
        # æµ‹è¯•ä¸åŒçš„å›é€€ç­–ç•¥
        strategies = [
            "simplify_query",
            "remove_joins", 
            "add_limit",
            "column_fallback",
            "basic_select"
        ]
        
        original_sql = "SELECT * FROM companies JOIN declarations ON companies.company_code = declarations.company_code"
        
        fallback_results = []
        
        for strategy in strategies:
            print(f"ğŸ”„ æµ‹è¯•å›é€€ç­–ç•¥: {strategy}")
            
            fallback_sql = await sql_executor._apply_fallback_strategy(
                strategy, original_sql, test_plan, query_context, semantic_metadata, "test error"
            )
            
            if fallback_sql:
                print(f"   ç”ŸæˆSQL: {fallback_sql[:60]}...")
                fallback_results.append((strategy, fallback_sql))
            else:
                print(f"   ç­–ç•¥æ— æ•ˆæˆ–å¤±è´¥")
        
        print(f"ğŸ“Š å›é€€ç­–ç•¥æµ‹è¯•å®Œæˆ: {len(fallback_results)}/{len(strategies)} ç­–ç•¥æˆåŠŸ")
        
        return len(fallback_results) > 0
        
    except Exception as e:
        print(f"âŒ å›é€€ç­–ç•¥æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

async def test_sql_optimization(sql_executor, semantic_data):
    """æµ‹è¯•SQLä¼˜åŒ–åŠŸèƒ½"""
    print("\nâš¡ æµ‹è¯•SQLä¼˜åŒ–...")
    
    if not sql_executor or not semantic_data:
        print("âŒ SQLæ‰§è¡Œå™¨æˆ–è¯­ä¹‰æ•°æ®æ— æ•ˆ")
        return False
    
    try:
        # æ„é€ SemanticMetadataå¯¹è±¡
        semantic_metadata = SemanticMetadata(
            original_metadata=semantic_data.get('original_metadata', {}),
            business_entities=semantic_data.get('business_entities', []),
            semantic_tags=semantic_data.get('semantic_tags', {}),
            data_patterns=semantic_data.get('data_patterns', []),
            business_rules=semantic_data.get('business_rules', []),
            domain_classification=semantic_data.get('domain_classification', {}),
            confidence_scores=semantic_data.get('confidence_scores', {})
        )
        
        # æµ‹è¯•SQLä¼˜åŒ–
        test_sql = "SELECT * FROM companies WHERE company_name LIKE '%è´¸æ˜“%'"
        
        print(f"âš¡ ä¼˜åŒ–SQL: {test_sql}")
        
        optimization_result = await sql_executor.optimize_query(test_sql, semantic_metadata)
        
        print(f"ğŸ“Š ä¼˜åŒ–ç»“æœ:")
        print(f"   åŸå§‹SQL: {optimization_result['original_sql']}")
        print(f"   ä¼˜åŒ–SQL: {optimization_result['optimized_sql']}")
        print(f"   åº”ç”¨çš„ä¼˜åŒ–: {optimization_result['optimizations_applied']}")
        print(f"   æ€§èƒ½å½±å“: {optimization_result['performance_impact']}")
        print(f"   å»ºè®®æ•°: {len(optimization_result['suggestions'])}")
        
        if optimization_result['suggestions']:
            print(f"   å»ºè®®: {optimization_result['suggestions'][:2]}")
        
        return 'optimized_sql' in optimization_result
        
    except Exception as e:
        print(f"âŒ SQLä¼˜åŒ–æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

async def test_execution_simulation(sql_executor, semantic_data):
    """æµ‹è¯•æ‰§è¡Œæ¨¡æ‹Ÿï¼ˆä¸è¿æ¥çœŸå®æ•°æ®åº“ï¼‰"""
    print("\nğŸ­ æµ‹è¯•æ‰§è¡Œæ¨¡æ‹Ÿ...")
    
    if not sql_executor or not semantic_data:
        print("âŒ SQLæ‰§è¡Œå™¨æˆ–è¯­ä¹‰æ•°æ®æ— æ•ˆ")
        return False
    
    try:
        # æ¨¡æ‹Ÿæ‰§è¡Œç»“æœï¼ˆå› ä¸ºæˆ‘ä»¬æ²¡æœ‰çœŸå®æ•°æ®åº“ï¼‰
        test_sql = "SELECT company_code, company_name FROM companies LIMIT 10"
        
        print(f"ğŸ­ æ¨¡æ‹Ÿæ‰§è¡Œ: {test_sql}")
        
        # æ¨¡æ‹Ÿæ‰§è¡Œç»Ÿè®¡
        mock_stats = await sql_executor.get_execution_statistics()
        
        print(f"ğŸ“Š æ‰§è¡Œç»Ÿè®¡:")
        print(f"   æ•°æ®åº“ç±»å‹: {mock_stats.get('database_type', 'unknown')}")
        print(f"   è¿æ¥çŠ¶æ€: {mock_stats.get('connection_status', 'unknown')}")
        
        # æµ‹è¯•æ‰§è¡Œæ´å¯Ÿ
        if sql_executor.execution_history:
            insights = await sql_executor.get_execution_insights()
            print(f"ğŸ“ˆ æ‰§è¡Œæ´å¯Ÿ: {insights}")
        else:
            print("ğŸ“ˆ æ— æ‰§è¡Œå†å²ï¼Œè·³è¿‡æ´å¯Ÿæµ‹è¯•")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ‰§è¡Œæ¨¡æ‹Ÿæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

async def test_comprehensive_workflow(sql_executor, semantic_data):
    """æµ‹è¯•å®Œæ•´å·¥ä½œæµ"""
    print("\nğŸ”„ æµ‹è¯•å®Œæ•´SQLæ‰§è¡Œå·¥ä½œæµ...")
    
    if not sql_executor or not semantic_data:
        print("âŒ SQLæ‰§è¡Œå™¨æˆ–è¯­ä¹‰æ•°æ®æ— æ•ˆ")
        return False
    
    try:
        # æ„é€ SemanticMetadataå¯¹è±¡
        semantic_metadata = SemanticMetadata(
            original_metadata=semantic_data.get('original_metadata', {}),
            business_entities=semantic_data.get('business_entities', []),
            semantic_tags=semantic_data.get('semantic_tags', {}),
            data_patterns=semantic_data.get('data_patterns', []),
            business_rules=semantic_data.get('business_rules', []),
            domain_classification=semantic_data.get('domain_classification', {}),
            confidence_scores=semantic_data.get('confidence_scores', {})
        )
        
        # å¤æ‚æµ‹è¯•åœºæ™¯
        complex_query = "æ˜¾ç¤ºæ‰€æœ‰æœ‰è¿›å£è®°å½•çš„å…¬å¸ä¿¡æ¯å’Œäº¤æ˜“æ€»é¢"
        
        print(f"ğŸ”„ å¤æ‚æŸ¥è¯¢: {complex_query}")
        
        # æ­¥éª¤1: æ¨¡æ‹ŸæŸ¥è¯¢ä¸Šä¸‹æ–‡
        query_context = QueryContext(
            entities_mentioned=['companies', 'declarations'],
            attributes_mentioned=['company_name', 'rmb_amount'],
            operations=['select', 'join', 'aggregate'],
            filters=[{'type': 'text', 'field': 'trade_type', 'operator': 'equals', 'value': 'è¿›å£'}],
            aggregations=['sum'],
            temporal_references=[],
            business_intent='analytics',
            confidence_score=0.85
        )
        print("   âœ… æŸ¥è¯¢ä¸Šä¸‹æ–‡åˆ›å»ºå®Œæˆ")
        
        # æ­¥éª¤2: æ¨¡æ‹Ÿå…ƒæ•°æ®åŒ¹é…
        metadata_matches = [
            MetadataMatch(
                entity_name='companies',
                entity_type='table',
                match_type='exact',
                similarity_score=1.0,
                relevant_attributes=['company_code', 'company_name'],
                suggested_joins=[],
                metadata={'table_name': 'companies'}
            ),
            MetadataMatch(
                entity_name='declarations',
                entity_type='table',
                match_type='exact',
                similarity_score=0.9,
                relevant_attributes=['company_code', 'rmb_amount'],
                suggested_joins=[],
                metadata={'table_name': 'declarations'}
            )
        ]
        print("   âœ… å…ƒæ•°æ®åŒ¹é…åˆ›å»ºå®Œæˆ")
        
        # æ­¥éª¤3: LLM SQLç”Ÿæˆï¼ˆæ¨¡æ‹Ÿï¼‰
        try:
            llm_result = await sql_executor.llm_generator.generate_sql_from_context(
                query_context, metadata_matches, semantic_metadata, complex_query
            )
            print(f"   âœ… LLM SQLç”Ÿæˆå®Œæˆ (ç½®ä¿¡åº¦: {llm_result.confidence_score:.2f})")
        except Exception as e:
            print(f"   âš ï¸ LLM SQLç”Ÿæˆå¤±è´¥: {e}")
            llm_result = None
        
        # æ­¥éª¤4: SQLéªŒè¯
        if llm_result and llm_result.sql:
            validation_result = await sql_executor.validate_sql(llm_result.sql, semantic_metadata)
            print(f"   âœ… SQLéªŒè¯å®Œæˆ (æœ‰æ•ˆ: {validation_result['is_valid']})")
        else:
            print("   âš ï¸ è·³è¿‡SQLéªŒè¯ï¼ˆæ— LLMç»“æœï¼‰")
        
        # æ­¥éª¤5: SQLä¼˜åŒ–
        if llm_result and llm_result.sql:
            optimization_result = await sql_executor.optimize_query(llm_result.sql, semantic_metadata)
            print(f"   âœ… SQLä¼˜åŒ–å®Œæˆ ({len(optimization_result['optimizations_applied'])} é¡¹ä¼˜åŒ–)")
        else:
            print("   âš ï¸ è·³è¿‡SQLä¼˜åŒ–ï¼ˆæ— LLMç»“æœï¼‰")
        
        # æ­¥éª¤6: æ‰§è¡Œæ¨¡æ‹Ÿï¼ˆä¸è¿æ¥çœŸå®æ•°æ®åº“ï¼‰
        print("   âœ… æ‰§è¡Œæ¨¡æ‹Ÿå®Œæˆï¼ˆæ¨¡æ‹Ÿç¯å¢ƒï¼‰")
        
        print(f"ğŸ¯ å®Œæ•´å·¥ä½œæµæ€»ç»“:")
        print(f"   - æŸ¥è¯¢æ„å›¾: {query_context.business_intent}")
        print(f"   - æ¶‰åŠè¡¨: {len(metadata_matches)} ä¸ª")
        print(f"   - è¿‡æ»¤æ¡ä»¶: {len(query_context.filters)} ä¸ª")
        print(f"   - èšåˆå‡½æ•°: {len(query_context.aggregations)} ä¸ª")
        if llm_result:
            print(f"   - SQLç”Ÿæˆç½®ä¿¡åº¦: {llm_result.confidence_score:.2f}")
        
        return True
        
    except Exception as e:
        print(f"âŒ å®Œæ•´å·¥ä½œæµæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹Step 5 SQLæ‰§è¡Œå™¨æµ‹è¯•")
    print("=" * 60)
    print(f"æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    # åŠ è½½Step 2ç»“æœ
    semantic_data = load_step2_result()
    if not semantic_data:
        print("âŒ æ— æ³•åŠ è½½Step 2ç»“æœï¼Œæµ‹è¯•ç»ˆæ­¢")
        return False
    
    print(f"ğŸ“Š Step 2æ•°æ®æ¦‚å†µ:")
    print(f"   - ä¸šåŠ¡å®ä½“: {len(semantic_data.get('business_entities', []))}")
    print(f"   - è¯­ä¹‰æ ‡ç­¾: {len(semantic_data.get('semantic_tags', {}))}")
    print(f"   - æ•°æ®æ¨¡å¼: {len(semantic_data.get('data_patterns', []))}")
    print(f"   - ä¸šåŠ¡è§„åˆ™: {len(semantic_data.get('business_rules', []))}")
    print()
    
    passed_tests = 0
    failed_tests = 0
    sql_executor = None
    
    # æµ‹è¯•åˆå§‹åŒ–
    print(f"{'='*15} SQLæ‰§è¡Œå™¨åˆå§‹åŒ– {'='*15}")
    try:
        sql_executor = await test_sql_executor_initialization()
        if sql_executor:
            passed_tests += 1
            print("âœ… SQLæ‰§è¡Œå™¨åˆå§‹åŒ– æµ‹è¯•é€šè¿‡")
        else:
            failed_tests += 1
            print("âŒ SQLæ‰§è¡Œå™¨åˆå§‹åŒ– æµ‹è¯•å¤±è´¥")
            return False
    except Exception as e:
        failed_tests += 1
        print(f"âŒ SQLæ‰§è¡Œå™¨åˆå§‹åŒ– æµ‹è¯•å¼‚å¸¸: {e}")
        return False
    
    # è¿è¡Œåç»­æµ‹è¯•
    if sql_executor:
        tests = [
            ("LLM SQLç”Ÿæˆ", lambda: test_llm_sql_generation(sql_executor, semantic_data)),
            ("SQLéªŒè¯", lambda: test_sql_validation(sql_executor, semantic_data)),
            ("æŸ¥è¯¢è®¡åˆ’ç”Ÿæˆ", lambda: test_query_plan_generation(sql_executor, semantic_data)),
            ("å›é€€ç­–ç•¥", lambda: test_fallback_strategies(sql_executor, semantic_data)),
            ("SQLä¼˜åŒ–", lambda: test_sql_optimization(sql_executor, semantic_data)),
            ("æ‰§è¡Œæ¨¡æ‹Ÿ", lambda: test_execution_simulation(sql_executor, semantic_data)),
            ("å®Œæ•´å·¥ä½œæµ", lambda: test_comprehensive_workflow(sql_executor, semantic_data)),
        ]
        
        for test_name, test_func in tests:
            try:
                print(f"\n{'='*15} {test_name} {'='*15}")
                result = await test_func()
                if result:
                    passed_tests += 1
                    print(f"âœ… {test_name} æµ‹è¯•é€šè¿‡")
                else:
                    failed_tests += 1
                    print(f"âŒ {test_name} æµ‹è¯•å¤±è´¥")
            except Exception as e:
                failed_tests += 1
                print(f"âŒ {test_name} æµ‹è¯•å¼‚å¸¸: {e}")
                import traceback
                traceback.print_exc()
    
    print(f"\n{'='*60}")
    print("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»")
    print(f"{'='*60}")
    print(f"âœ… é€šè¿‡: {passed_tests}")
    print(f"âŒ å¤±è´¥: {failed_tests}")
    if passed_tests + failed_tests > 0:
        print(f"ğŸ“ˆ æˆåŠŸç‡: {passed_tests/(passed_tests+failed_tests)*100:.1f}%")
    
    # ä¿å­˜æµ‹è¯•ç»“æœ
    test_result = {
        'test_time': datetime.now().isoformat(),
        'total_tests': passed_tests + failed_tests,
        'passed_tests': passed_tests,
        'failed_tests': failed_tests,
        'success_rate': passed_tests/(passed_tests+failed_tests)*100 if (passed_tests + failed_tests) > 0 else 0,
        'test_queries': TEST_QUERIES,
        'database_config': 'mock_postgresql'
    }
    
    result_file = f"step5_sql_executor_test_result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(result_file, 'w', encoding='utf-8') as f:
        json.dump(test_result, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ“„ æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {result_file}")
    
    if failed_tests == 0:
        print("\nğŸ‰ Step 5 SQLæ‰§è¡Œå™¨æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
        return True
    else:
        print(f"\nâš ï¸ æœ‰ {failed_tests} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥")
        return False

if __name__ == "__main__":
    success = asyncio.run(main())
    exit(0 if success else 1)