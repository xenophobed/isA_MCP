#!/usr/bin/env python3
"""
Unit Test: æœç´¢é“¾æ¥æå–éªŒè¯
ç¬¬ä¸€æ­¥éªŒè¯ï¼šç¡®ä¿æˆ‘ä»¬å¯ä»¥æœç´¢å¹¶è·å¾—éœ€è¦çš„é“¾æ¥

ç›®æ ‡ï¼šæµ‹è¯•web servicesçš„æœç´¢å¼•æ“èƒ½åŠ›ï¼ŒéªŒè¯æœç´¢ç»“æœé“¾æ¥æå–åŠŸèƒ½
"""
import asyncio
import sys
import os
from typing import List, Dict, Any

# Add parent directory to path
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))))

from tools.services.web_services.engines.search_engine import SearchEngine, BraveSearchStrategy, SearchProvider
from tools.services.web_services.core.browser_manager import BrowserManager
from tools.services.web_services.strategies.detection.vision_analyzer import VisionAnalyzer

class TestSearchLinkExtraction:
    """æœç´¢é“¾æ¥æå–å•å…ƒæµ‹è¯•"""
    
    def __init__(self):
        self.search_engine = None
        self.browser_manager = None
        self.vision_analyzer = None
        
    async def setup(self):
        """åˆå§‹åŒ–æµ‹è¯•ç¯å¢ƒ"""
        print("ğŸ”§ åˆå§‹åŒ–æµ‹è¯•ç¯å¢ƒ...")
        
        # åˆå§‹åŒ–æœç´¢å¼•æ“
        self.search_engine = SearchEngine()
        
        # è¿™é‡Œéœ€è¦Brave API Key - åœ¨çœŸå®ç¯å¢ƒä¸­åº”è¯¥ä»ç¯å¢ƒå˜é‡è·å–
        # æš‚æ—¶è·³è¿‡APIä¾èµ–çš„éƒ¨åˆ†
        print("âš ï¸  æš‚æ—¶è·³è¿‡Brave APIé…ç½® - éœ€è¦APIå¯†é’¥")
        
        # åˆå§‹åŒ–æµè§ˆå™¨ç®¡ç†å™¨
        self.browser_manager = BrowserManager()
        await self.browser_manager.initialize()
        
        # åˆå§‹åŒ–è§†è§‰åˆ†æå™¨
        self.vision_analyzer = VisionAnalyzer()
        
        print("âœ… æµ‹è¯•ç¯å¢ƒåˆå§‹åŒ–å®Œæˆ")
    
    async def test_search_engine_availability(self):
        """æµ‹è¯•æœç´¢å¼•æ“å¯ç”¨æ€§"""
        print("\nğŸ” æµ‹è¯•1: æœç´¢å¼•æ“å¯ç”¨æ€§æ£€æŸ¥")
        
        try:
            # æ£€æŸ¥æœç´¢å¼•æ“æ˜¯å¦æ­£ç¡®åˆå§‹åŒ–
            assert self.search_engine is not None, "æœç´¢å¼•æ“æœªåˆå§‹åŒ–"
            
            # æ£€æŸ¥å¯ç”¨çš„æä¾›å•†
            providers = self.search_engine.get_available_providers()
            print(f"   å¯ç”¨æä¾›å•†: {providers}")
            
            # åº”è¯¥æ²¡æœ‰æä¾›å•†ï¼Œå› ä¸ºæˆ‘ä»¬è¿˜æ²¡æ³¨å†Œ
            assert len(providers) == 0, f"é¢„æœŸ0ä¸ªæä¾›å•†ï¼Œå®é™…{len(providers)}ä¸ª"
            
            print("   âœ… æœç´¢å¼•æ“åŸºç¡€åŠŸèƒ½æ­£å¸¸")
            return True
            
        except Exception as e:
            print(f"   âŒ æœç´¢å¼•æ“æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    async def test_browser_search_simulation(self):
        """æµ‹è¯•æµè§ˆå™¨æœç´¢æ¨¡æ‹Ÿ"""
        print("\nğŸŒ æµ‹è¯•2: æµè§ˆå™¨æœç´¢æ¨¡æ‹Ÿ")
        
        try:
            # è·å–æµè§ˆå™¨é¡µé¢
            page = await self.browser_manager.get_page("stealth")
            
            # æ¨¡æ‹Ÿè®¿é—®Googleæœç´¢
            test_query = "AirPods 4 ANR price"
            google_search_url = f"https://www.google.com/search?q={test_query.replace(' ', '+')}"
            
            print(f"   è®¿é—®æœç´¢URL: {google_search_url}")
            await page.goto(google_search_url, wait_until='networkidle', timeout=30000)
            
            # è·å–é¡µé¢æ ‡é¢˜éªŒè¯åŠ è½½æˆåŠŸ
            title = await page.title()
            print(f"   é¡µé¢æ ‡é¢˜: {title}")
            
            # éªŒè¯æ˜¯å¦æ˜¯æœç´¢ç»“æœé¡µé¢
            assert "AirPods" in title or "search" in title.lower(), f"é¡µé¢æ ‡é¢˜ä¸ç¬¦åˆæœç´¢é¢„æœŸ: {title}"
            
            # å°è¯•æå–æœç´¢ç»“æœé“¾æ¥
            links = await page.evaluate("""
                () => {
                    const links = Array.from(document.querySelectorAll('a[href]'));
                    return links.map(link => ({
                        text: link.innerText.trim(),
                        href: link.href,
                        isResult: link.closest('[data-result-type]') ? true : false
                    })).filter(link => link.href.startsWith('http') && link.text.length > 0);
                }
            """)
            
            print(f"   æå–åˆ°é“¾æ¥æ•°é‡: {len(links)}")
            
            # ç­›é€‰å¯èƒ½çš„äº§å“é“¾æ¥
            product_links = [
                link for link in links 
                if any(site in link['href'] for site in ['amazon.com', 'apple.com', 'bestbuy.com', 'target.com'])
                and any(keyword in link['text'].lower() for keyword in ['airpods', 'price', 'buy'])
            ]
            
            print(f"   ç­›é€‰å‡ºäº§å“é“¾æ¥: {len(product_links)}")
            for i, link in enumerate(product_links[:3]):  # åªæ˜¾ç¤ºå‰3ä¸ª
                print(f"     {i+1}. {link['text'][:50]}... -> {link['href'][:60]}...")
            
            assert len(links) > 0, "æœªæå–åˆ°ä»»ä½•é“¾æ¥"
            print("   âœ… æµè§ˆå™¨æœç´¢æ¨¡æ‹ŸæˆåŠŸ")
            return product_links
            
        except Exception as e:
            print(f"   âŒ æµè§ˆå™¨æœç´¢æµ‹è¯•å¤±è´¥: {e}")
            return []
    
    async def test_link_classification(self):
        """æµ‹è¯•é“¾æ¥åˆ†ç±»åŠŸèƒ½"""
        print("\nğŸ·ï¸ æµ‹è¯•3: é“¾æ¥åˆ†ç±»åŠŸèƒ½")
        
        try:
            # æ¨¡æ‹Ÿä¸€äº›æµ‹è¯•é“¾æ¥
            test_links = [
                {"text": "Apple AirPods 4 with ANC - Official Store", "href": "https://www.apple.com/airpods-4/"},
                {"text": "AirPods 4 ANR Best Price on Amazon", "href": "https://www.amazon.com/dp/B0C123456"},
                {"text": "Buy AirPods 4 Active Noise Cancellation - Best Buy", "href": "https://www.bestbuy.com/site/airpods"},
                {"text": "Privacy Policy - Google", "href": "https://policies.google.com/privacy"},
                {"text": "Facebook - Log In", "href": "https://www.facebook.com/login"}
            ]
            
            # åˆ†ç±»å‡½æ•°
            def classify_link(link):
                href = link['href'].lower()
                text = link['text'].lower()
                
                # ç”µå•†å¹³å°
                ecommerce_sites = ['amazon.com', 'apple.com', 'bestbuy.com', 'target.com', 'walmart.com']
                if any(site in href for site in ecommerce_sites):
                    if any(keyword in text for keyword in ['airpods', 'price', 'buy']):
                        return 'product_page'
                    return 'ecommerce_other'
                
                # ç¤¾äº¤åª’ä½“
                social_sites = ['facebook.com', 'twitter.com', 'instagram.com', 'linkedin.com']
                if any(site in href for site in social_sites):
                    return 'social_media'
                
                # æ–°é—»/è¯„è®º
                news_sites = ['cnet.com', 'theverge.com', 'techcrunch.com']
                if any(site in href for site in news_sites):
                    return 'news_review'
                
                return 'other'
            
            # åˆ†ç±»æµ‹è¯•é“¾æ¥
            classified_links = {
                'product_page': [],
                'ecommerce_other': [],
                'social_media': [],
                'news_review': [],
                'other': []
            }
            
            for link in test_links:
                category = classify_link(link)
                classified_links[category].append(link)
                print(f"   {link['text'][:40]}... -> {category}")
            
            # éªŒè¯åˆ†ç±»ç»“æœ
            assert len(classified_links['product_page']) >= 2, f"é¢„æœŸè‡³å°‘2ä¸ªäº§å“é¡µé¢ï¼Œå®é™…{len(classified_links['product_page'])}ä¸ª"
            assert len(classified_links['other']) >= 1, f"é¢„æœŸè‡³å°‘1ä¸ªå…¶ä»–é“¾æ¥ï¼Œå®é™…{len(classified_links['other'])}ä¸ª"
            
            print(f"   âœ… é“¾æ¥åˆ†ç±»å®Œæˆ: {sum(len(links) for links in classified_links.values())}ä¸ªé“¾æ¥")
            return classified_links
            
        except Exception as e:
            print(f"   âŒ é“¾æ¥åˆ†ç±»æµ‹è¯•å¤±è´¥: {e}")
            return {}
    
    async def test_link_priority_scoring(self):
        """æµ‹è¯•é“¾æ¥ä¼˜å…ˆçº§è¯„åˆ†"""
        print("\nâ­ æµ‹è¯•4: é“¾æ¥ä¼˜å…ˆçº§è¯„åˆ†")
        
        try:
            # æµ‹è¯•é“¾æ¥è¯„åˆ†å‡½æ•°
            def score_link_priority(link, target_query="AirPods 4 ANR"):
                score = 0
                href = link['href'].lower()
                text = link['text'].lower()
                query_words = target_query.lower().split()
                
                # æ–‡æœ¬ç›¸å…³æ€§è¯„åˆ† (0-40åˆ†)
                text_matches = sum(1 for word in query_words if word in text)
                score += text_matches * 10
                
                # åŸŸåä¿¡ä»»åº¦è¯„åˆ† (0-30åˆ†)
                trusted_domains = {
                    'apple.com': 30,
                    'amazon.com': 25,
                    'bestbuy.com': 20,
                    'target.com': 15,
                    'walmart.com': 15
                }
                for domain, domain_score in trusted_domains.items():
                    if domain in href:
                        score += domain_score
                        break
                
                # URLè·¯å¾„ç›¸å…³æ€§ (0-20åˆ†)
                if any(word in href for word in query_words):
                    score += 15
                
                # ç‰¹æ®Šå…³é”®è¯åŠ åˆ† (0-10åˆ†)
                if any(keyword in text for keyword in ['official', 'buy', 'price', 'store']):
                    score += 5
                
                return min(score, 100)  # æœ€é«˜100åˆ†
            
            # æµ‹è¯•é“¾æ¥
            test_links = [
                {"text": "Apple AirPods 4 with Active Noise Cancellation - Official Apple Store", "href": "https://www.apple.com/airpods-4/"},
                {"text": "Amazon.com: Apple AirPods 4 ANR - Best Price", "href": "https://www.amazon.com/Apple-AirPods-4-ANR/dp/B123"},
                {"text": "Best Buy: AirPods 4 Active Noise Cancellation", "href": "https://www.bestbuy.com/site/apple/airpods-4/"},
                {"text": "Random tech blog post", "href": "https://techblog.com/random-post"},
                {"text": "Facebook login page", "href": "https://www.facebook.com/login"}
            ]
            
            # è®¡ç®—è¯„åˆ†å¹¶æ’åº
            scored_links = []
            for link in test_links:
                score = score_link_priority(link)
                scored_links.append({**link, 'score': score})
                print(f"   {score:3d}åˆ† - {link['text'][:50]}...")
            
            # æŒ‰åˆ†æ•°æ’åº
            scored_links.sort(key=lambda x: x['score'], reverse=True)
            
            # éªŒè¯è¯„åˆ†åˆç†æ€§
            top_link = scored_links[0]
            assert top_link['score'] >= 60, f"æœ€é«˜åˆ†é“¾æ¥è¯„åˆ†è¿‡ä½: {top_link['score']}"
            assert 'apple.com' in top_link['href'] or 'amazon.com' in top_link['href'], "æœ€é«˜åˆ†åº”è¯¥æ˜¯æƒå¨ç”µå•†ç½‘ç«™"
            
            print(f"   âœ… é“¾æ¥è¯„åˆ†å®Œæˆï¼Œæœ€é«˜åˆ†: {top_link['score']}åˆ†")
            return scored_links
            
        except Exception as e:
            print(f"   âŒ é“¾æ¥è¯„åˆ†æµ‹è¯•å¤±è´¥: {e}")
            return []
    
    async def cleanup(self):
        """æ¸…ç†æµ‹è¯•ç¯å¢ƒ"""
        print("\nğŸ§¹ æ¸…ç†æµ‹è¯•ç¯å¢ƒ...")
        
        if self.browser_manager:
            await self.browser_manager.cleanup_all()
        
        print("âœ… æ¸…ç†å®Œæˆ")

async def run_search_link_tests():
    """è¿è¡Œæœç´¢é“¾æ¥æå–æµ‹è¯•å¥—ä»¶"""
    print("ğŸ§ª æœç´¢é“¾æ¥æå–å•å…ƒæµ‹è¯•å¥—ä»¶")
    print("=" * 50)
    
    test_suite = TestSearchLinkExtraction()
    results = {
        'total_tests': 4,
        'passed_tests': 0,
        'failed_tests': 0,
        'test_results': []
    }
    
    try:
        # åˆå§‹åŒ–
        await test_suite.setup()
        
        # æµ‹è¯•1: æœç´¢å¼•æ“å¯ç”¨æ€§
        test1_result = await test_suite.test_search_engine_availability()
        results['test_results'].append(('æœç´¢å¼•æ“å¯ç”¨æ€§', test1_result))
        if test1_result:
            results['passed_tests'] += 1
        else:
            results['failed_tests'] += 1
        
        # æµ‹è¯•2: æµè§ˆå™¨æœç´¢æ¨¡æ‹Ÿ
        test2_result = await test_suite.test_browser_search_simulation()
        results['test_results'].append(('æµè§ˆå™¨æœç´¢æ¨¡æ‹Ÿ', len(test2_result) > 0))
        if len(test2_result) > 0:
            results['passed_tests'] += 1
        else:
            results['failed_tests'] += 1
        
        # æµ‹è¯•3: é“¾æ¥åˆ†ç±»åŠŸèƒ½
        test3_result = await test_suite.test_link_classification()
        results['test_results'].append(('é“¾æ¥åˆ†ç±»åŠŸèƒ½', len(test3_result) > 0))
        if len(test3_result) > 0:
            results['passed_tests'] += 1
        else:
            results['failed_tests'] += 1
        
        # æµ‹è¯•4: é“¾æ¥ä¼˜å…ˆçº§è¯„åˆ†
        test4_result = await test_suite.test_link_priority_scoring()
        results['test_results'].append(('é“¾æ¥ä¼˜å…ˆçº§è¯„åˆ†', len(test4_result) > 0))
        if len(test4_result) > 0:
            results['passed_tests'] += 1
        else:
            results['failed_tests'] += 1
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
        results['failed_tests'] = results['total_tests']
    
    finally:
        await test_suite.cleanup()
    
    # è¾“å‡ºæµ‹è¯•ç»“æœ
    print("\nğŸ“Š æµ‹è¯•ç»“æœæ‘˜è¦")
    print("=" * 30)
    for test_name, result in results['test_results']:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{test_name}: {status}")
    
    print(f"\né€šè¿‡æµ‹è¯•: {results['passed_tests']}/{results['total_tests']}")
    print(f"æˆåŠŸç‡: {(results['passed_tests']/results['total_tests']*100):.1f}%")
    
    if results['passed_tests'] == results['total_tests']:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æœç´¢é“¾æ¥æå–åŠŸèƒ½éªŒè¯æˆåŠŸï¼")
        return True
    else:
        print(f"\nâš ï¸ {results['failed_tests']}ä¸ªæµ‹è¯•å¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥å’Œä¿®å¤")
        return False

if __name__ == "__main__":
    print("ğŸ”— æœç´¢é“¾æ¥æå–éªŒè¯æµ‹è¯•")
    print("éªŒè¯ç¬¬ä¸€æ­¥ï¼šç¡®ä¿æˆ‘ä»¬å¯ä»¥æœç´¢å¹¶è·å¾—éœ€è¦çš„é“¾æ¥")
    print("")
    
    result = asyncio.run(run_search_link_tests())
    sys.exit(0 if result else 1)