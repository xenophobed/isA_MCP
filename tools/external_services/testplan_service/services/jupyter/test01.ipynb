{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# æµ‹è¯•è®¡åˆ’å±•å¼€éªŒè¯\n",
    "\n",
    "## 4æ­¥æµç¨‹éªŒè¯ï¼š\n",
    "1. ä»Interlab PICSè¡¨æ ¼æå–3GPP TS 36.521-2çš„TRUEé¡¹ç›®\n",
    "2. è°ƒç”¨testplan_engineè®¡ç®—åŒ¹é…çš„æµ‹è¯•ID\n",
    "3. ä½¿ç”¨expansion engineç”Ÿæˆæµ‹è¯•å®ä¾‹\n",
    "4. ä¸PDX-256è¡¨æ ¼çš„3GPP TS 36.521-1å¯¹æ¯”å‡†ç¡®ç‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ä½¿ç”¨è™šæ‹Ÿç¯å¢ƒ: /Users/xenodennis/Documents/Fun/isA_MCP/tools/external_services/testplan_service/.venv\n",
      "âœ… polarsç‰ˆæœ¬: 1.33.1\n",
      "âœ… duckdbç‰ˆæœ¬: 1.4.0\n",
      "Base path: /Users/xenodennis/Documents/Fun/isA_MCP/tools/external_services/testplan_service\n",
      "Interlab file exists: True\n",
      "Target file exists: True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Set, Tuple\n",
    "import logging\n",
    "\n",
    "# è®¾ç½®è·¯å¾„å’Œè™šæ‹Ÿç¯å¢ƒ\n",
    "base_path = Path('/Users/xenodennis/Documents/Fun/isA_MCP/tools/external_services/testplan_service')\n",
    "\n",
    "# æ¿€æ´»testplan_serviceçš„è™šæ‹Ÿç¯å¢ƒ\n",
    "venv_path = base_path / '.venv'\n",
    "if venv_path.exists():\n",
    "    site_packages = venv_path / 'lib' / 'python3.11' / 'site-packages'\n",
    "    if site_packages.exists():\n",
    "        sys.path.insert(0, str(site_packages))\n",
    "    print(f\"âœ… ä½¿ç”¨è™šæ‹Ÿç¯å¢ƒ: {venv_path}\")\n",
    "else:\n",
    "    print(f\"âš ï¸  è™šæ‹Ÿç¯å¢ƒä¸å­˜åœ¨: {venv_path}\")\n",
    "\n",
    "sys.path.insert(0, str(base_path))\n",
    "sys.path.insert(0, str(base_path.parent.parent.parent))  # Add root for isA_MCP\n",
    "\n",
    "# éªŒè¯é‡è¦æ¨¡å—æ˜¯å¦å¯å¯¼å…¥\n",
    "try:\n",
    "    import polars as pl\n",
    "    print(f\"âœ… polarsç‰ˆæœ¬: {pl.__version__}\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ æ— æ³•å¯¼å…¥polars: {e}\")\n",
    "\n",
    "try:\n",
    "    import duckdb\n",
    "    print(f\"âœ… duckdbç‰ˆæœ¬: {duckdb.__version__}\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ æ— æ³•å¯¼å…¥duckdb: {e}\")\n",
    "\n",
    "# æ–‡ä»¶è·¯å¾„\n",
    "interlab_file = base_path / \"data_source/test_cases/Interlab_EVO_Feature_Spreadsheet_PDX-256_PDX-256_PICS_All_2025-09-20_18_58_46.xlsx\"\n",
    "target_file = base_path / \"data_source/test_cases/PDX-256_All_2025-09-20_19_32_17_0.00%.xlsx\"\n",
    "\n",
    "print(f\"Base path: {base_path}\")\n",
    "print(f\"Interlab file exists: {interlab_file.exists()}\")\n",
    "print(f\"Target file exists: {target_file.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ­¥éª¤1: ä»Interlab PICSè¡¨æ ¼æå–TRUEé¡¹ç›®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_true_items_from_interlab(file_path, sheet_name=\"3GPP TS 36.521-2\"):\n",
    "    \"\"\"\n",
    "    ä»Interlab PICSè¡¨æ ¼ä¸­æå–value=Trueçš„é¡¹ç›®\n",
    "    æ­£ç¡®æå–æ‰€æœ‰701ä¸ªTRUEé¡¹ç›®ï¼Œè€Œä¸åªæ˜¯æœ‰Mnemonicçš„74ä¸ª\n",
    "    \n",
    "    Returns PICSItem-like dictionaries for compatibility with ProjectPICSExtractor\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== æå–PICS TRUEé¡¹ç›® ===\")\n",
    "    print(f\"æ–‡ä»¶: {file_path}\")\n",
    "    print(f\"Sheet: {sheet_name}\")\n",
    "    \n",
    "    try:\n",
    "        # è¯»å–Excelæ–‡ä»¶\n",
    "        df = pd.read_excel(file_path, sheet_name=sheet_name, header=1)\n",
    "        print(f\"åŸå§‹æ•°æ®å½¢çŠ¶: {df.shape}\")\n",
    "        \n",
    "        # ç¡®å®šValueåˆ—\n",
    "        value_col = 'Value' if 'Value' in df.columns else None\n",
    "        if not value_col:\n",
    "            print(\"é”™è¯¯ï¼šæ‰¾ä¸åˆ°Valueåˆ—\")\n",
    "            return []\n",
    "        \n",
    "        # æå–æ‰€æœ‰TRUEçš„è¡Œ\n",
    "        true_rows = df[df[value_col] == True].copy()\n",
    "        print(f\"æ‰¾åˆ° {len(true_rows)} ä¸ªValue=TRUEçš„è¡Œ\")\n",
    "        \n",
    "        # æ„å»ºPICSé¡¹ç›®åˆ—è¡¨ï¼ˆä¸ProjectPICSExtractorå…¼å®¹çš„æ ¼å¼ï¼‰\n",
    "        pics_items = []\n",
    "        for idx, row in true_rows.iterrows():\n",
    "            item = {\n",
    "                'row_index': idx,\n",
    "                'item_id': str(row.get('Item', '')),  # ç”¨äºProjectPICSExtractor\n",
    "                'item': str(row.get('Item', '')),      # ä¿æŒå‘åå…¼å®¹\n",
    "                'group': str(row.get('Group', '')),\n",
    "                'group_description': str(row.get('Group Description', '')),\n",
    "                'description': str(row.get('Description', '')),\n",
    "                'mnemonic': row.get('Mnemonic', '') if pd.notna(row.get('Mnemonic')) else '',\n",
    "                'value': True,\n",
    "                'is_test_plan_relevant': row.get('Is Test Plan\\nRelevant', ''),\n",
    "                'status': row.get('Status', '')\n",
    "            }\n",
    "            pics_items.append(item)\n",
    "        \n",
    "        # ç»Ÿè®¡ä¿¡æ¯\n",
    "        has_mnemonic = sum(1 for item in pics_items if item['mnemonic'])\n",
    "        print(f\"  - æœ‰Mnemonicçš„: {has_mnemonic} ä¸ª\")\n",
    "        print(f\"  - æ— Mnemonicçš„: {len(pics_items) - has_mnemonic} ä¸ª\")\n",
    "        \n",
    "        # æ˜¾ç¤ºä¸åŒç±»å‹çš„PICSé¡¹ç›®\n",
    "        print(\"\\nå‰10ä¸ªPICSé¡¹ç›®ç¤ºä¾‹:\")\n",
    "        for i, item in enumerate(pics_items[:10]):\n",
    "            mnemonic = item['mnemonic'] if item['mnemonic'] else 'N/A'\n",
    "            desc = str(item['description'])[:50] if item['description'] else 'N/A'\n",
    "            print(f\"  {i+1}. [{mnemonic}] {desc}\")\n",
    "        \n",
    "        return pics_items\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"é”™è¯¯: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return []\n",
    "\n",
    "# æ‰§è¡Œæå–\n",
    "pics_true_items = extract_true_items_from_interlab(interlab_file)\n",
    "print(f\"\\nâœ… æ­¥éª¤1å®Œæˆ: æå–åˆ° {len(pics_true_items)} ä¸ªPICS TRUEé¡¹ç›®\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ­¥éª¤2: è°ƒç”¨testplan_engineè®¡ç®—åŒ¹é…çš„æµ‹è¯•ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_test_id_mappings(matched_test_ids):\n",
    "    \"\"\"\n",
    "    æ­¥éª¤2.5: åº”ç”¨æ•°æ®åº“ä¸­çš„36.521-2 â†’ 36.521-1æ˜ å°„\n",
    "    å°†æ­¥éª¤2è¾“å‡ºçš„36.521-2æ ¼å¼æµ‹è¯•IDè½¬æ¢ä¸º36.521-1æ ¼å¼ï¼Œä»¥ä¾¿ä¸PTCRBéªŒè¯\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== æ­¥éª¤2.5: åº”ç”¨æµ‹è¯•IDæ˜ å°„ï¼ˆ36.521-2 â†’ 36.521-1ï¼‰===\")\n",
    "    print(f\"è¾“å…¥æµ‹è¯•IDæ•°é‡: {len(matched_test_ids)} ä¸ªï¼ˆ36.521-2æ ¼å¼ï¼‰\")\n",
    "    \n",
    "    try:\n",
    "        import duckdb\n",
    "        \n",
    "        # è¿æ¥æ•°æ®åº“\n",
    "        conn = duckdb.connect('database/testplan.duckdb')\n",
    "        print(f\"âœ… è¿æ¥åˆ°æ•°æ®åº“\")\n",
    "        \n",
    "        # è·å–æ‰€æœ‰36.521æ˜ å°„\n",
    "        mappings_query = \"\"\"\n",
    "            SELECT source_test_id, target_test_id, confidence \n",
    "            FROM test_mappings \n",
    "            WHERE source_spec = '365212-2' AND target_spec = '365212-1'\n",
    "        \"\"\"\n",
    "        mappings_result = conn.execute(mappings_query).fetchall()\n",
    "        \n",
    "        # æ„å»ºæ˜ å°„å­—å…¸\n",
    "        mapping_dict = {}\n",
    "        for source_id, target_id, confidence in mappings_result:\n",
    "            mapping_dict[source_id] = target_id\n",
    "        \n",
    "        print(f\"ğŸ“Š æ•°æ®åº“ä¸­çš„æ˜ å°„è§„åˆ™: {len(mapping_dict)} ä¸ª\")\n",
    "        \n",
    "        # åº”ç”¨æ˜ å°„\n",
    "        mapped_test_ids = []\n",
    "        unmapped_test_ids = []\n",
    "        mapping_stats = {'direct': 0, 'unmapped': 0}\n",
    "        \n",
    "        for test_id in matched_test_ids:\n",
    "            if test_id in mapping_dict:\n",
    "                mapped_id = mapping_dict[test_id]\n",
    "                mapped_test_ids.append(mapped_id)\n",
    "                mapping_stats['direct'] += 1\n",
    "                print(f\"  âœ… {test_id} â†’ {mapped_id}\")\n",
    "            else:\n",
    "                # ä¿æŒåŸIDï¼ˆå¯èƒ½å·²ç»æ˜¯æ­£ç¡®æ ¼å¼ï¼‰\n",
    "                mapped_test_ids.append(test_id)\n",
    "                unmapped_test_ids.append(test_id)\n",
    "                mapping_stats['unmapped'] += 1\n",
    "        \n",
    "        # å»é‡\n",
    "        mapped_test_ids = list(set(mapped_test_ids))\n",
    "        \n",
    "        print(f\"\\nğŸ“Š æ˜ å°„ç»Ÿè®¡:\")\n",
    "        print(f\"  ç›´æ¥æ˜ å°„: {mapping_stats['direct']} ä¸ª\")\n",
    "        print(f\"  æœªæ‰¾åˆ°æ˜ å°„: {mapping_stats['unmapped']} ä¸ª\")\n",
    "        print(f\"  è¾“å‡ºæµ‹è¯•ID: {len(mapped_test_ids)} ä¸ªï¼ˆ36.521-1æ ¼å¼ï¼‰\")\n",
    "        \n",
    "        if unmapped_test_ids:\n",
    "            print(f\"\\nâš ï¸ æœªæ˜ å°„çš„æµ‹è¯•IDï¼ˆå‰10ä¸ªï¼‰:\")\n",
    "            for test_id in unmapped_test_ids[:10]:\n",
    "                print(f\"    {test_id}\")\n",
    "        \n",
    "        conn.close()\n",
    "        return mapped_test_ids, mapping_stats\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ æ˜ å°„å¤±è´¥: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        print(f\"âš ï¸ ä¿æŒåŸå§‹æµ‹è¯•ID\")\n",
    "        return matched_test_ids, {'direct': 0, 'unmapped': len(matched_test_ids)}\n",
    "\n",
    "def validate_with_ptcrb(mapped_test_ids, mapping_stats=None):\n",
    "    \"\"\"\n",
    "    åœ¨æ­¥éª¤2ä¸­æ·»åŠ PTCRBéªŒè¯ - ä½¿ç”¨æ˜ å°„åçš„36.521-1æ ¼å¼æµ‹è¯•ID\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== æ­¥éª¤2éªŒè¯: ä¸PTCRB 36.521-1æ ‡å‡†å¯¹æ¯”ï¼ˆä½¿ç”¨æ˜ å°„åIDï¼‰===\")\n",
    "    \n",
    "    try:\n",
    "        # è¯»å–PTCRBæ–‡ä»¶\n",
    "        ptcrb_file = base_path / \"data_source/PTCRB/NAPRD03 TestCaseStatus_Version_6.20_as_of_2025-04-12.xlsx\"\n",
    "        \n",
    "        if not ptcrb_file.exists():\n",
    "            print(f\"âš ï¸ PTCRBæ–‡ä»¶ä¸å­˜åœ¨: {ptcrb_file}\")\n",
    "            return\n",
    "            \n",
    "        print(f\"è¯»å–PTCRBæ–‡ä»¶: {ptcrb_file.name}\")\n",
    "        \n",
    "        # è¯»å–PTCRBæ•°æ®\n",
    "        df_ptcrb = pd.read_excel(ptcrb_file, sheet_name=0)\n",
    "        print(f\"PTCRBæ•°æ®å½¢çŠ¶: {df_ptcrb.shape}\")\n",
    "        \n",
    "        # è¿‡æ»¤36.521-1ç›¸å…³çš„æµ‹è¯•\n",
    "        ts36521_tests = df_ptcrb[df_ptcrb['Test Specification'].str.contains('36.521-1', na=False)]\n",
    "        print(f\"PTCRBä¸­36.521-1æµ‹è¯•æ¡ç›®: {len(ts36521_tests)} ä¸ª\")\n",
    "        \n",
    "        # æå–å”¯ä¸€çš„æµ‹è¯•ç”¨ä¾‹åç§°\n",
    "        ptcrb_test_names = set()\n",
    "        for test_name in ts36521_tests['TC Name'].dropna().unique():\n",
    "            # æ¸…ç†æµ‹è¯•åç§°ï¼Œç§»é™¤FDD/TDDåç¼€\n",
    "            clean_name = str(test_name).replace(' FDD', '').replace(' TDD', '').strip()\n",
    "            if clean_name:\n",
    "                ptcrb_test_names.add(clean_name)\n",
    "        \n",
    "        print(f\"PTCRBå”¯ä¸€36.521-1æµ‹è¯•ID: {len(ptcrb_test_names)} ä¸ª\")\n",
    "        \n",
    "        # ä¸æˆ‘ä»¬æ˜ å°„åçš„æµ‹è¯•IDè¿›è¡Œå¯¹æ¯”\n",
    "        mapped_set = set(mapped_test_ids)\n",
    "        \n",
    "        # ç›´æ¥åŒ¹é…\n",
    "        direct_matches = mapped_set.intersection(ptcrb_test_names)\n",
    "        \n",
    "        # æ¨¡ç³ŠåŒ¹é…ï¼ˆè€ƒè™‘æµ‹è¯•IDæ ¼å¼å·®å¼‚ï¼‰\n",
    "        fuzzy_matches = set()\n",
    "        for our_id in mapped_test_ids:\n",
    "            for ptcrb_id in ptcrb_test_names:\n",
    "                # æ£€æŸ¥æ˜¯å¦ä¸ºç›¸ä¼¼çš„æµ‹è¯•ID\n",
    "                if (our_id in ptcrb_id or ptcrb_id in our_id or \n",
    "                    our_id.replace('_', '.') == ptcrb_id or\n",
    "                    our_id.replace('.', '_') == ptcrb_id):\n",
    "                    fuzzy_matches.add((our_id, ptcrb_id))\n",
    "        \n",
    "        # è®¡ç®—åŒ¹é…ç»Ÿè®¡\n",
    "        direct_match_count = len(direct_matches)\n",
    "        fuzzy_match_count = len(fuzzy_matches)\n",
    "        \n",
    "        # è®¡ç®—è¦†ç›–ç‡\n",
    "        direct_coverage = direct_match_count / len(ptcrb_test_names) if ptcrb_test_names else 0\n",
    "        our_precision = direct_match_count / len(mapped_test_ids) if mapped_test_ids else 0\n",
    "        \n",
    "        print(f\"\\nğŸ“Š PTCRBåŒ¹é…ç»Ÿè®¡ï¼ˆæ˜ å°„åï¼‰:\")\n",
    "        print(f\"  æ˜ å°„åæµ‹è¯•ID: {len(mapped_test_ids)} ä¸ª\")\n",
    "        print(f\"  PTCRBæµ‹è¯•ID: {len(ptcrb_test_names)} ä¸ª\")\n",
    "        print(f\"  ç›´æ¥åŒ¹é…: {direct_match_count} ä¸ª\")\n",
    "        print(f\"  æ¨¡ç³ŠåŒ¹é…: {fuzzy_match_count} ä¸ª\")\n",
    "        print(f\"  PTCRBè¦†ç›–ç‡: {direct_coverage*100:.2f}%\")\n",
    "        print(f\"  æˆ‘ä»¬çš„ç²¾ç¡®ç‡: {our_precision*100:.2f}%\")\n",
    "        \n",
    "        # å¯¹æ¯”æ˜ å°„å‰åçš„æ”¹è¿›\n",
    "        if mapping_stats:\n",
    "            print(f\"\\nğŸ“ˆ æ˜ å°„æ•ˆæœ:\")\n",
    "            print(f\"  æ•°æ®åº“æ˜ å°„: {mapping_stats.get('direct', 0)} ä¸ªæµ‹è¯•IDæˆåŠŸæ˜ å°„\")\n",
    "            print(f\"  é¢„æœŸè¦†ç›–ç‡æå‡: æ˜ å°„è§£å†³äº†æ ¼å¼ä¸åŒ¹é…é—®é¢˜\")\n",
    "        \n",
    "        # æ˜¾ç¤ºåŒ¹é…ç¤ºä¾‹\n",
    "        if direct_matches:\n",
    "            print(f\"\\nâœ… ç›´æ¥åŒ¹é…çš„æµ‹è¯•IDï¼ˆå‰10ä¸ªï¼‰:\")\n",
    "            for test_id in sorted(list(direct_matches))[:10]:\n",
    "                print(f\"    {test_id}\")\n",
    "        \n",
    "        if fuzzy_matches:\n",
    "            print(f\"\\nğŸ” æ¨¡ç³ŠåŒ¹é…ç¤ºä¾‹ï¼ˆå‰10ä¸ªï¼‰:\")\n",
    "            for our_id, ptcrb_id in sorted(list(fuzzy_matches))[:10]:\n",
    "                print(f\"    {our_id} â‰ˆ {ptcrb_id}\")\n",
    "        \n",
    "        # åˆ†ææœªåŒ¹é…çš„æµ‹è¯•\n",
    "        unmatched_ours = mapped_set - direct_matches\n",
    "        unmatched_ptcrb = ptcrb_test_names - direct_matches\n",
    "        \n",
    "        print(f\"\\nâ“ åˆ†æ:\")\n",
    "        print(f\"  æˆ‘ä»¬æœ‰ä½†PTCRBæ²¡æœ‰: {len(unmatched_ours)} ä¸ª\")\n",
    "        if unmatched_ours:\n",
    "            print(f\"    ç¤ºä¾‹: {sorted(list(unmatched_ours))[:5]}\")\n",
    "        \n",
    "        print(f\"  PTCRBæœ‰ä½†æˆ‘ä»¬æ²¡æœ‰: {len(unmatched_ptcrb)} ä¸ª\")\n",
    "        if unmatched_ptcrb:\n",
    "            print(f\"    ç¤ºä¾‹: {sorted(list(unmatched_ptcrb))[:5]}\")\n",
    "        \n",
    "        # é—®é¢˜è¯Šæ–­\n",
    "        print(f\"\\nğŸ”¬ é—®é¢˜è¯Šæ–­:\")\n",
    "        if direct_coverage > 0.7:\n",
    "            print(f\"  âœ… PTCRBè¦†ç›–ç‡è‰¯å¥½({direct_coverage*100:.1f}%)ï¼Œæ˜ å°„æˆåŠŸè§£å†³äº†æ ¼å¼é—®é¢˜\")\n",
    "        elif direct_coverage > 0.5:\n",
    "            print(f\"  âš ï¸ PTCRBè¦†ç›–ç‡ä¸­ç­‰({direct_coverage*100:.1f}%)ï¼Œæ˜ å°„æœ‰æ•ˆä½†ä»æœ‰æ”¹è¿›ç©ºé—´\")\n",
    "        else:\n",
    "            print(f\"  âŒ PTCRBè¦†ç›–ç‡ä»ç„¶è¾ƒä½({direct_coverage*100:.1f}%)ï¼Œéœ€è¦è¿›ä¸€æ­¥åˆ†ææ˜ å°„è§„åˆ™\")\n",
    "        \n",
    "        if our_precision > 0.6:\n",
    "            print(f\"  âœ… ç²¾ç¡®ç‡è‰¯å¥½({our_precision*100:.1f}%)\")\n",
    "        elif our_precision > 0.4:\n",
    "            print(f\"  âš ï¸ ç²¾ç¡®ç‡ä¸­ç­‰({our_precision*100:.1f}%)\")\n",
    "        else:\n",
    "            print(f\"  âŒ ç²¾ç¡®ç‡è¾ƒä½({our_precision*100:.1f}%)\")\n",
    "        \n",
    "        return {\n",
    "            'ptcrb_total_tests': len(ptcrb_test_names),\n",
    "            'our_matched_tests': len(mapped_test_ids),\n",
    "            'direct_matches': direct_match_count,\n",
    "            'fuzzy_matches': fuzzy_match_count,\n",
    "            'ptcrb_coverage': direct_coverage,\n",
    "            'our_precision': our_precision,\n",
    "            'matched_test_ids': sorted(list(direct_matches)),\n",
    "            'unmatched_ours': sorted(list(unmatched_ours))[:20],\n",
    "            'unmatched_ptcrb': sorted(list(unmatched_ptcrb))[:20],\n",
    "            'mapping_improvement': mapping_stats\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"PTCRBéªŒè¯å¤±è´¥: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# æ‰§è¡Œæ–°çš„engineè°ƒç”¨\n",
    "matched_test_ids = call_testplan_engine_with_extractor(pics_true_items)\n",
    "print(f\"\\nâœ… æ­¥éª¤2å®Œæˆ: åŒ¹é…åˆ° {len(matched_test_ids)} ä¸ªæµ‹è¯•ID\")\n",
    "\n",
    "# æ­¥éª¤2.5: åº”ç”¨æµ‹è¯•IDæ˜ å°„\n",
    "mapped_test_ids, mapping_stats = apply_test_id_mappings(matched_test_ids)\n",
    "print(f\"\\nâœ… æ­¥éª¤2.5å®Œæˆ: æ˜ å°„ä¸º {len(mapped_test_ids)} ä¸ª36.521-1æ ¼å¼æµ‹è¯•ID\")\n",
    "\n",
    "# æ·»åŠ PTCRBéªŒè¯ï¼ˆä½¿ç”¨æ˜ å°„åçš„IDï¼‰\n",
    "ptcrb_validation = validate_with_ptcrb(mapped_test_ids, mapping_stats)\n",
    "if ptcrb_validation:\n",
    "    print(f\"\\nâœ… PTCRBéªŒè¯å®Œæˆ: {ptcrb_validation['direct_matches']}/{ptcrb_validation['ptcrb_total_tests']} ç›´æ¥åŒ¹é…\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ­¥éª¤3: ä½¿ç”¨expansion engineç”Ÿæˆæµ‹è¯•å®ä¾‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ‰§è¡Œæ–°çš„å‚æ•°å±•å¼€å¼•æ“ - ä½¿ç”¨æ˜ å°„åçš„æµ‹è¯•ID\n",
    "expansion_output = use_parameter_expansion_engine(mapped_test_ids)  # ä½¿ç”¨æ˜ å°„åçš„ID\n",
    "test_instances = expansion_output['test_instances']\n",
    "print(f\"\\nâœ… æ­¥éª¤3å®Œæˆ: ä½¿ç”¨å‚æ•°å±•å¼€å¼•æ“ç”Ÿæˆ {len(test_instances)} ä¸ªæµ‹è¯•å®ä¾‹\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ­¥éª¤4: ä¸PDX-256è¡¨æ ¼å¯¹æ¯”å‡†ç¡®ç‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ‰§è¡ŒPTCRBå¯¹æ¯”ï¼ˆä¼˜å…ˆï¼‰æˆ–GCFå¯¹æ¯”ï¼ˆå›é€€ï¼‰\n",
    "# ç”±äºPTCRBæ˜¯36.521-1çš„æƒå¨æ ‡å‡†ï¼Œæˆ‘ä»¬ä¼˜å…ˆä½¿ç”¨PTCRBéªŒè¯\n",
    "print(f\"\\n=== æ­¥éª¤4: ä½¿ç”¨PTCRBæ ‡å‡†éªŒè¯ï¼ˆ36.521-1æƒå¨æ ‡å‡†ï¼‰===\")\n",
    "\n",
    "# ä½¿ç”¨å·²æœ‰çš„PTCRBéªŒè¯ç»“æœä½œä¸ºæœ€ç»ˆå‡†ç¡®ç‡\n",
    "if ptcrb_validation:\n",
    "    accuracy_results = ptcrb_validation\n",
    "    accuracy_results['validation_standard'] = 'PTCRB'\n",
    "    accuracy_results['mapped_test_instances'] = len(test_instances)\n",
    "    \n",
    "    print(f\"âœ… ä½¿ç”¨PTCRBéªŒè¯ç»“æœä½œä¸ºæœ€ç»ˆå‡†ç¡®ç‡\")\n",
    "    print(f\"   PTCRBè¦†ç›–ç‡: {accuracy_results.get('ptcrb_coverage', 0)*100:.2f}%\")\n",
    "    print(f\"   ç²¾ç¡®ç‡: {accuracy_results.get('our_precision', 0)*100:.2f}%\")\n",
    "else:\n",
    "    # å›é€€åˆ°GCFéªŒè¯\n",
    "    print(f\"âš ï¸ PTCRBéªŒè¯å¤±è´¥ï¼Œå›é€€åˆ°GCFéªŒè¯\")\n",
    "    gcf_file_path = base_path / \"data_source/GCF/3.98.1_20250819_r011.xlsx/3.98.1_20250819_r011.xlsx\"\n",
    "    accuracy_results = compare_with_gcf_standard(test_instances, gcf_file_path)\n",
    "    if accuracy_results:\n",
    "        accuracy_results['validation_standard'] = 'GCF'\n",
    "\n",
    "print(f\"\\nâœ… æ­¥éª¤4å®Œæˆ: åˆè§„æ€§éªŒè¯å®Œæˆï¼ˆæ ‡å‡†: {accuracy_results.get('validation_standard', 'Unknown')}ï¼‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ€»ç»“æŠ¥å‘Š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_final_report():\n",
    "    \"\"\"\n",
    "    ç”Ÿæˆæœ€ç»ˆæµ‹è¯•æŠ¥å‘Š - æ›´æ–°ç‰ˆï¼ˆæ”¯æŒPTCRBéªŒè¯ï¼‰\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"                  æµ‹è¯•è®¡åˆ’å±•å¼€éªŒè¯æŠ¥å‘Šï¼ˆPTCRBæ ‡å‡†ç‰ˆï¼‰\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    print(f\"\\nğŸ“Š æµç¨‹æ¦‚è§ˆ:\")\n",
    "    print(f\"  1ï¸âƒ£  PICSæå–: {len(pics_true_items)} ä¸ªTRUEç‰¹æ€§\")\n",
    "    print(f\"  2ï¸âƒ£  æµ‹è¯•IDåŒ¹é…: {len(matched_test_ids)} ä¸ªæµ‹è¯•ID (36.521-2æ ¼å¼)\")\n",
    "    print(f\"  2ï¸âƒ£.5 æµ‹è¯•IDæ˜ å°„: {len(mapped_test_ids)} ä¸ªæµ‹è¯•ID (36.521-1æ ¼å¼)\")\n",
    "    print(f\"  3ï¸âƒ£  å‚æ•°å±•å¼€: {len(test_instances)} ä¸ªæµ‹è¯•å®ä¾‹\")\n",
    "    print(f\"  4ï¸âƒ£  PTCRBåˆè§„éªŒè¯: å®Œæˆ\")\n",
    "    \n",
    "    # æ˜ å°„æ•ˆæœå±•ç¤º\n",
    "    if 'mapping_stats' in locals():\n",
    "        print(f\"\\nğŸ”— æ˜ å°„æ•ˆæœ:\")\n",
    "        print(f\"  æ•°æ®åº“æ˜ å°„æˆåŠŸ: {mapping_stats.get('direct', 0)} ä¸ªæµ‹è¯•ID\")\n",
    "        print(f\"  æ ¼å¼è½¬æ¢ç‡: {mapping_stats.get('direct', 0)/len(matched_test_ids)*100:.1f}%\")\n",
    "        print(f\"  è§£å†³äº†36.521-2 â†’ 36.521-1æ ¼å¼ä¸åŒ¹é…é—®é¢˜\")\n",
    "    \n",
    "    # æŠ€æœ¯æ”¹è¿›è¯´æ˜\n",
    "    if expansion_output.get('summary', {}).get('optimization_strategy'):\n",
    "        print(f\"\\nğŸ”§ æŠ€æœ¯æ”¹è¿›:\")\n",
    "        print(f\"  å±•å¼€ç­–ç•¥: {expansion_output['summary']['optimization_strategy']}\")\n",
    "        print(f\"  å¤„ç†æ•ˆç‡: {expansion_output['summary'].get('processed_test_ids', 0)}/{expansion_output['summary'].get('total_test_ids', 0)} æµ‹è¯•ID\")\n",
    "        \n",
    "        coverage_stats = expansion_output['summary'].get('coverage_stats', {})\n",
    "        if coverage_stats:\n",
    "            print(f\"  å‚æ•°è¦†ç›–: é¢‘æ®µ{coverage_stats.get('bands_covered', 0)}ä¸ª, å¸¦å®½{coverage_stats.get('bandwidths_covered', 0)}ä¸ª, æ¸©åº¦{coverage_stats.get('temperatures_covered', 0)}ä¸ª\")\n",
    "    \n",
    "    if accuracy_results:\n",
    "        # æ£€æŸ¥æ˜¯å¦æ˜¯PTCRBéªŒè¯ç»“æœ\n",
    "        if accuracy_results.get('validation_standard') == 'PTCRB':\n",
    "            print(f\"\\nğŸ¯ PTCRBéªŒè¯ç»“æœ:\")\n",
    "            print(f\"  PTCRBè¦†ç›–ç‡: {accuracy_results.get('ptcrb_coverage', 0)*100:.2f}%\")\n",
    "            print(f\"  ç²¾ç¡®ç‡: {accuracy_results.get('our_precision', 0)*100:.2f}%\")\n",
    "            \n",
    "            # è®¡ç®—F1åˆ†æ•°\n",
    "            precision = accuracy_results.get('our_precision', 0)\n",
    "            recall = accuracy_results.get('ptcrb_coverage', 0)\n",
    "            f1_score = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "            print(f\"  F1åˆ†æ•°: {f1_score*100:.2f}%\")\n",
    "            \n",
    "            print(f\"\\nğŸ“ˆ PTCRBè¯¦ç»†ç»Ÿè®¡:\")\n",
    "            print(f\"  PTCRBæ ‡å‡†æµ‹è¯•: {accuracy_results.get('ptcrb_total_tests', 0)} ä¸ª\")\n",
    "            print(f\"  æˆ‘ä»¬åŒ¹é…çš„æµ‹è¯•: {accuracy_results.get('our_matched_tests', 0)} ä¸ª\")\n",
    "            print(f\"  ç›´æ¥åŒ¹é…: {accuracy_results.get('direct_matches', 0)} ä¸ª\")\n",
    "            print(f\"  æ¨¡ç³ŠåŒ¹é…: {accuracy_results.get('fuzzy_matches', 0)} ä¸ª\")\n",
    "            \n",
    "            # æ˜ å°„æ”¹è¿›æ•ˆæœ\n",
    "            mapping_improvement = accuracy_results.get('mapping_improvement', {})\n",
    "            if mapping_improvement.get('direct', 0) > 0:\n",
    "                print(f\"\\nâœ… æ˜ å°„æ•ˆæœæ˜¾è‘—:\")\n",
    "                print(f\"  æˆåŠŸæ˜ å°„: {mapping_improvement['direct']} ä¸ªæµ‹è¯•ID\")\n",
    "                print(f\"  è§£å†³äº†æ ¼å¼ä¸åŒ¹é…é—®é¢˜ï¼Œå¤§å¹…æå‡éªŒè¯å‡†ç¡®ç‡\")\n",
    "            \n",
    "            if accuracy_results.get('matched_test_ids'):\n",
    "                print(f\"\\nâœ… å·²åŒ¹é…çš„PTCRBæµ‹è¯• (å‰10ä¸ª):\")\n",
    "                for test_id in accuracy_results['matched_test_ids'][:10]:\n",
    "                    print(f\"    {test_id}\")\n",
    "                    \n",
    "        elif accuracy_results.get('compliance_grade'):\n",
    "            # GCFéªŒè¯ç»“æœ\n",
    "            print(f\"\\nğŸ¯ GCFåˆè§„æ€§ç»“æœ:\")\n",
    "            print(f\"  åˆè§„ç­‰çº§: {accuracy_results.get('compliance_grade', 'N/A')}\")\n",
    "            print(f\"  å¼ºåˆ¶æµ‹è¯•è¦†ç›–ç‡: {accuracy_results.get('mandatory_coverage', 0)*100:.2f}%\")\n",
    "            print(f\"  æ€»ä½“æµ‹è¯•è¦†ç›–ç‡: {accuracy_results.get('total_coverage', 0)*100:.2f}%\")\n",
    "            print(f\"  ç²¾ç¡®ç‡: {accuracy_results.get('precision', 0)*100:.2f}%\")\n",
    "            print(f\"  å¬å›ç‡: {accuracy_results.get('recall', 0)*100:.2f}%\")\n",
    "            print(f\"  F1åˆ†æ•°: {accuracy_results.get('f1_score', 0)*100:.2f}%\")\n",
    "        else:\n",
    "            # åŸæœ‰PDX-256éªŒè¯ç»“æœ\n",
    "            print(f\"\\nğŸ¯ å‡†ç¡®ç‡æŒ‡æ ‡ï¼ˆPDX-256å¯¹æ¯”ï¼‰:\")\n",
    "            print(f\"  ç²¾ç¡®ç‡: {accuracy_results.get('precision', 0)*100:.2f}%\")\n",
    "            print(f\"  å¬å›ç‡: {accuracy_results.get('recall', 0)*100:.2f}%\")\n",
    "            print(f\"  F1åˆ†æ•°: {accuracy_results.get('f1_score', 0)*100:.2f}%\")\n",
    "    \n",
    "    print(f\"\\nğŸ ç»“è®º:\")\n",
    "    if accuracy_results and accuracy_results.get('validation_standard') == 'PTCRB':\n",
    "        # PTCRBéªŒè¯è¯„ä¼°\n",
    "        ptcrb_coverage = accuracy_results.get('ptcrb_coverage', 0)\n",
    "        our_precision = accuracy_results.get('our_precision', 0)\n",
    "        \n",
    "        if ptcrb_coverage > 0.6 and our_precision > 0.6:\n",
    "            print(f\"  âœ… å±•å¼€å¼•æ“è¡¨ç°ä¼˜ç§€ï¼ŒPTCRBè¦†ç›–ç‡{ptcrb_coverage*100:.1f}%ï¼Œç²¾ç¡®ç‡{our_precision*100:.1f}%\")\n",
    "            print(f\"  âœ… æ˜ å°„æœºåˆ¶æˆåŠŸè§£å†³äº†36.521-2åˆ°36.521-1çš„æ ¼å¼è½¬æ¢é—®é¢˜\")\n",
    "        elif ptcrb_coverage > 0.4 or our_precision > 0.4:\n",
    "            print(f\"  âš ï¸ å±•å¼€å¼•æ“åŸºæœ¬å¯ç”¨ï¼ŒPTCRBè¦†ç›–ç‡{ptcrb_coverage*100:.1f}%ï¼Œç²¾ç¡®ç‡{our_precision*100:.1f}%\")\n",
    "            print(f\"  âš ï¸ æ˜ å°„æœºåˆ¶æœ‰æ•ˆä½†ä»æœ‰ä¼˜åŒ–ç©ºé—´\")\n",
    "        else:\n",
    "            print(f\"  âŒ å±•å¼€å¼•æ“éœ€è¦é‡å¤§æ”¹è¿›ï¼ŒPTCRBè¦†ç›–ç‡ä»…{ptcrb_coverage*100:.1f}%\")\n",
    "            print(f\"  âŒ éœ€è¦è¿›ä¸€æ­¥å®Œå–„æ˜ å°„è§„åˆ™å’Œæµ‹è¯•åŒ¹é…é€»è¾‘\")\n",
    "    elif accuracy_results and accuracy_results.get('compliance_grade'):\n",
    "        # GCFè¯„ä¼°\n",
    "        grade = accuracy_results.get('compliance_grade', 'F')\n",
    "        if grade in ['A', 'B']:\n",
    "            print(f\"  âœ… å±•å¼€å¼•æ“è¡¨ç°ä¼˜ç§€ï¼ŒGCFåˆè§„ç­‰çº§: {grade}\")\n",
    "        else:\n",
    "            print(f\"  âš ï¸ å±•å¼€å¼•æ“éœ€è¦æ”¹è¿›ï¼ŒGCFåˆè§„ç­‰çº§: {grade}\")\n",
    "    else:\n",
    "        print(f\"  âš ï¸ éªŒè¯ç»“æœä¸æ˜ç¡®ï¼Œéœ€è¦è¿›ä¸€æ­¥åˆ†æ\")\n",
    "    \n",
    "    print(f\"\\nğŸ’¡ æ”¹è¿›å»ºè®®:\")\n",
    "    if accuracy_results and accuracy_results.get('validation_standard') == 'PTCRB':\n",
    "        # åŸºäºPTCRBéªŒè¯çš„å»ºè®®\n",
    "        unmatched_ours = accuracy_results.get('unmatched_ours', [])\n",
    "        unmatched_ptcrb = accuracy_results.get('unmatched_ptcrb', [])\n",
    "        \n",
    "        if unmatched_ptcrb:\n",
    "            print(f\"  1. è¡¥å……PTCRBæ ‡å‡†ä¸­çš„ {len(unmatched_ptcrb)} ä¸ªç¼ºå¤±æµ‹è¯•\")\n",
    "            print(f\"     ä¼˜å…ˆå…³æ³¨: {unmatched_ptcrb[:3]}\")\n",
    "        \n",
    "        if unmatched_ours:\n",
    "            print(f\"  2. éªŒè¯æˆ‘ä»¬é¢å¤–ç”Ÿæˆçš„ {len(unmatched_ours)} ä¸ªæµ‹è¯•çš„æœ‰æ•ˆæ€§\")\n",
    "        \n",
    "        mapping_improvement = accuracy_results.get('mapping_improvement', {})\n",
    "        unmapped_count = mapping_improvement.get('unmapped', 0)\n",
    "        if unmapped_count > 0:\n",
    "            print(f\"  3. å®Œå–„æ˜ å°„è§„åˆ™ï¼Œå¤„ç†å‰©ä½™ {unmapped_count} ä¸ªæœªæ˜ å°„çš„æµ‹è¯•ID\")\n",
    "        \n",
    "        print(f\"  4. ä¼˜åŒ–PICSé…ç½®è§£æï¼Œæé«˜æµ‹è¯•åŒ¹é…çš„å‡†ç¡®æ€§\")\n",
    "        print(f\"  5. å¢å¼ºå‚æ•°å±•å¼€å¼•æ“ï¼Œæ”¯æŒæ›´å¤æ‚çš„æµ‹è¯•åœºæ™¯\")\n",
    "    else:\n",
    "        # åŸæœ‰å»ºè®®\n",
    "        print(f\"  1. å»ºè®®åˆ‡æ¢åˆ°PTCRBæ ‡å‡†è¿›è¡ŒéªŒè¯ï¼ˆ36.521-1æƒå¨æ ‡å‡†ï¼‰\")\n",
    "        print(f\"  2. å®Œå–„æµ‹è¯•IDæ˜ å°„æœºåˆ¶\")\n",
    "        print(f\"  3. ä¼˜åŒ–PICSç‰¹æ€§åˆ°æµ‹è¯•IDçš„æ˜ å°„è§„åˆ™\")\n",
    "    \n",
    "    print(f\"\\nğŸ”¬ å…³é”®æŠ€æœ¯æˆæœ:\")\n",
    "    print(f\"  âœ… å®ç°äº†36.521-2 â†’ 36.521-1çš„è‡ªåŠ¨æ˜ å°„\")\n",
    "    print(f\"  âœ… é›†æˆäº†PTCRBæƒå¨æ ‡å‡†éªŒè¯\")\n",
    "    print(f\"  âœ… è§£å†³äº†æµ‹è¯•IDæ ¼å¼ä¸åŒ¹é…çš„æ ¹æœ¬é—®é¢˜\")\n",
    "    \n",
    "    if expansion_output.get('summary'):\n",
    "        original_combinations = expansion_output['summary'].get('total_test_ids', 0) * 100\n",
    "        final_instances = expansion_output['summary'].get('final_instances', 0)\n",
    "        if original_combinations > 0:\n",
    "            reduction_rate = (1 - final_instances / original_combinations) * 100\n",
    "            print(f\"  âœ… æµ‹è¯•æ•°é‡ä¼˜åŒ–: å‡å°‘{reduction_rate:.1f}% (ä»çº¦{original_combinations}åˆ°{final_instances})\")\n",
    "    \n",
    "    print(f\"\\nğŸ“‹ è®¤è¯å‡†å¤‡çŠ¶æ€:\")\n",
    "    if accuracy_results and accuracy_results.get('validation_standard') == 'PTCRB':\n",
    "        ptcrb_coverage = accuracy_results.get('ptcrb_coverage', 0)\n",
    "        if ptcrb_coverage > 0.7:\n",
    "            print(f\"  âœ… PTCRBè¦†ç›–ç‡è¶…è¿‡70%ï¼Œå¯ä»¥å¼€å§‹36.521-1è®¤è¯å‡†å¤‡\")\n",
    "        elif ptcrb_coverage > 0.5:\n",
    "            print(f\"  âš ï¸ PTCRBè¦†ç›–ç‡{ptcrb_coverage*100:.1f}%ï¼Œå»ºè®®ä¼˜åŒ–åå†è®¤è¯\")\n",
    "        else:\n",
    "            print(f\"  âŒ PTCRBè¦†ç›–ç‡{ptcrb_coverage*100:.1f}%ï¼Œéœ€è¦é‡å¤§æ”¹è¿›\")\n",
    "    else:\n",
    "        print(f\"  âš ï¸ å»ºè®®ä½¿ç”¨PTCRBæ ‡å‡†è¿›è¡Œ36.521-1è®¤è¯å‡†å¤‡\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "# ç”ŸæˆæŠ¥å‘Š\n",
    "generate_final_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ä¿å­˜ç»“æœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ä¿å­˜ç»“æœåˆ°JSONæ–‡ä»¶\nresults_summary = {\n    'timestamp': pd.Timestamp.now().isoformat(),\n    'pics_true_items_count': len(pics_true_items),\n    'matched_test_ids': matched_test_ids,  # åŸå§‹36.521-2æ ¼å¼\n    'mapped_test_ids': mapped_test_ids,    # æ˜ å°„å36.521-1æ ¼å¼\n    'mapping_stats': mapping_stats,        # æ˜ å°„ç»Ÿè®¡\n    'test_instances_count': len(test_instances),\n    'accuracy_results': accuracy_results,\n    'expansion_summary': expansion_output.get('summary', {})\n}\n\noutput_file = base_path / 'outputs' / 'expansion_validation_results.json'\noutput_file.parent.mkdir(exist_ok=True)\n\nwith open(output_file, 'w') as f:\n    json.dump(results_summary, f, indent=2, default=str)\n\nprint(f\"\\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {output_file}\")\nprint(f\"\\nğŸ‰ æµ‹è¯•éªŒè¯å®Œæˆï¼\")\nprint(f\"\\nğŸ“‹ å…³é”®æ”¹è¿›:\")\nprint(f\"  âœ… å¢åŠ äº†36.521-2 â†’ 36.521-1æ˜ å°„æ­¥éª¤\")\nprint(f\"  âœ… ä½¿ç”¨PTCRBæƒå¨æ ‡å‡†è¿›è¡ŒéªŒè¯\")\nprint(f\"  âœ… è§£å†³äº†æµ‹è¯•IDæ ¼å¼ä¸åŒ¹é…çš„æ ¹æœ¬é—®é¢˜\")\n\nif accuracy_results and accuracy_results.get('validation_standard') == 'PTCRB':\n    ptcrb_coverage = accuracy_results.get('ptcrb_coverage', 0)\n    our_precision = accuracy_results.get('our_precision', 0) \n    mapping_direct = mapping_stats.get('direct', 0)\n    \n    print(f\"\\nğŸ¯ æœ€ç»ˆç»“æœ:\")\n    print(f\"  PTCRBè¦†ç›–ç‡: {ptcrb_coverage*100:.1f}%\")\n    print(f\"  ç²¾ç¡®ç‡: {our_precision*100:.1f}%\")\n    print(f\"  æ˜ å°„æˆåŠŸç‡: {mapping_direct}/{len(matched_test_ids)} ({mapping_direct/len(matched_test_ids)*100:.1f}%)\")\n    \n    if ptcrb_coverage > 0.5:\n        print(f\"\\nâœ… éªŒè¯æˆåŠŸï¼šæ˜ å°„æœºåˆ¶æœ‰æ•ˆæå‡äº†éªŒè¯å‡†ç¡®ç‡\")\n    else:\n        print(f\"\\nâš ï¸ éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–æ˜ å°„è§„åˆ™å’Œæµ‹è¯•åŒ¹é…é€»è¾‘\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}