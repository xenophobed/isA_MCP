#!/usr/bin/env python3
"""
Enhanced 3GPP-2 PICS Extractor for Interlab Excel Template Generation

è¿™ä¸ªæœåŠ¡ä»3GPP -2æ–‡æ¡£ä¸­æå–PICSæ•°æ®ï¼Œå¹¶ç”ŸæˆInterlab Excelæ¨¡æ¿æ ¼å¼
å‚è€ƒæ–‡ä»¶ï¼šInterlab_EVO_Feature_Spreadsheet_Template_All_20250920.xlsx

åŠŸèƒ½ï¼š
1. ä»3GPP -2æ–‡æ¡£çš„PICSè¡¨æ ¼ä¸­æå–ç»“æ„åŒ–æ•°æ®
2. è½¬æ¢ä¸ºInterlab Excelæ¨¡æ¿æ ¼å¼
3. æ”¯æŒå¤šä¸ª3GPP -2è§„èŒƒï¼ˆ34.121-2, 34.123-2, 34.229-2, 36.521-2, 36.523-2, 38.508-2ï¼‰
4. ç”Ÿæˆå®Œæ•´çš„Excelå·¥ä½œç°¿ï¼ŒåŒ…å«æ‰€æœ‰å¿…è¦çš„å·¥ä½œè¡¨å’Œæ ¼å¼
"""

import logging
import pandas as pd
import uuid
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, field
import re
import sys

# å¯¼å…¥ç°æœ‰çš„3GPP-2æ–‡æ¡£æå–å™¨
import importlib.util
spec = importlib.util.spec_from_file_location("gpp_2_docs_extractor", Path(__file__).parent / "3gpp-2-docs-extractor.py")
extractor_module = importlib.util.module_from_spec(spec)
spec.loader.exec_module(extractor_module)
ApplicabilityExtractor = extractor_module.ApplicabilityExtractor

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class PICSItem:
    """PICSé¡¹ç›®æ•°æ®ç»“æ„ - é€‚é…Interlabæ ¼å¼"""
    group: str                    # è¡¨æ ¼ç»„åï¼Œå¦‚"Table A.4.1-1"
    group_description: str        # ç»„æè¿°ï¼Œå¦‚"UE Radio Technologies"
    item: str                     # PICSé¡¹ç›®IDï¼Œå¦‚"A.4.1-1/1"
    description: str              # åŠŸèƒ½æè¿°
    mnemonic: Optional[str] = None        # åŠ©è®°ç¬¦
    value: str = "FALSE"                  # é»˜è®¤å€¼
    allowed_settings: str = "TRUE|FALSE"  # å…è®¸çš„è®¾ç½®
    is_test_plan_relevant: str = "TRUE"   # æ˜¯å¦ä¸æµ‹è¯•è®¡åˆ’ç›¸å…³
    status: str = "Optional"              # çŠ¶æ€
    response_details: str = ""            # å“åº”è¯¦æƒ…
    feature_id: str = ""                  # åŠŸèƒ½IDï¼ˆUUIDï¼‰
    external_feature_gid: str = ""       # å¤–éƒ¨åŠŸèƒ½ç»„IDï¼ˆUUIDï¼‰
    supported_start_value: str = "FALSE" # æ”¯æŒçš„èµ·å§‹å€¼
    
    def to_dict(self) -> Dict:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return {
            'Group': self.group,
            'Group Description': self.group_description,
            'Item': self.item,
            'Description': self.description,
            'Mnemonic': self.mnemonic,
            'Value': self.value,
            'Allowed\nSettings': self.allowed_settings,
            'Is Test Plan\nRelevant': self.is_test_plan_relevant,
            'Status': self.status,
            'Response Details': self.response_details,
            'FeatureID': self.feature_id,
            'ExternalFeatureGID': self.external_feature_gid,
            'SupportedStartValue': self.supported_start_value
        }


@dataclass
class SpecificationPICS:
    """è§„èŒƒçš„PICSæ•°æ®"""
    spec_name: str
    spec_version: str
    pics_items: List[PICSItem]
    extraction_metadata: Dict = field(default_factory=dict)


class Enhanced3GPP2PICSExtractor:
    """å¢å¼ºçš„3GPP-2 PICSæå–å™¨ - ç”ŸæˆInterlab Excelæ¨¡æ¿"""
    
    def __init__(self):
        """åˆå§‹åŒ–æå–å™¨"""
        self.supported_specs = {
            '34.121-2': 'TS 34.121-2',
            '34.123-2': 'TS 34.123-2', 
            '34.229-2': 'TS 34.229-2',
            '36.521-2': 'TS 36.521-2',
            '36.523-2': 'TS 36.523-2',
            '38.508-2': 'TS 38.508-2'
        }
        
        self.data_source_base = Path("data_source/3GPP")
        logger.info(f"Initialized Enhanced3GPP2PICSExtractor for {len(self.supported_specs)} specifications")
    
    def extract_all_specs_to_excel(self, output_path: str = "generated_interlab_template.xlsx") -> Dict[str, Any]:
        """
        æå–æ‰€æœ‰æ”¯æŒçš„3GPP -2è§„èŒƒå¹¶ç”ŸæˆInterlab Excelæ¨¡æ¿
        
        Args:
            output_path: è¾“å‡ºExcelæ–‡ä»¶è·¯å¾„
            
        Returns:
            Dict: æå–ç»“æœæ‘˜è¦
        """
        logger.info("ğŸš€ Starting enhanced PICS extraction for all 3GPP -2 specifications...")
        
        all_spec_data = {}
        extraction_summary = {
            'total_specs_processed': 0,
            'total_pics_items': 0,
            'successful_specs': [],
            'failed_specs': [],
            'output_file': output_path
        }
        
        # 1. æå–æ¯ä¸ªè§„èŒƒçš„PICSæ•°æ®
        for spec_id, spec_name in self.supported_specs.items():
            logger.info(f"\nğŸ“„ Processing {spec_name} ({spec_id})...")
            
            try:
                spec_pics = self._extract_spec_pics(spec_id, spec_name)
                if spec_pics and spec_pics.pics_items:
                    all_spec_data[spec_id] = spec_pics
                    extraction_summary['total_pics_items'] += len(spec_pics.pics_items)
                    extraction_summary['successful_specs'].append(spec_id)
                    logger.info(f"âœ… Extracted {len(spec_pics.pics_items)} PICS items from {spec_name}")
                else:
                    logger.warning(f"âš ï¸ No PICS items extracted from {spec_name}")
                    extraction_summary['failed_specs'].append(spec_id)
                    
            except Exception as e:
                logger.error(f"âŒ Failed to extract {spec_name}: {e}")
                extraction_summary['failed_specs'].append(spec_id)
        
        extraction_summary['total_specs_processed'] = len(extraction_summary['successful_specs'])
        
        # 2. ç”ŸæˆExcelæ¨¡æ¿
        if all_spec_data:
            logger.info(f"\nğŸ“Š Generating Interlab Excel template with {extraction_summary['total_pics_items']} total PICS items...")
            self._generate_interlab_excel(all_spec_data, output_path)
            logger.info(f"âœ… Excel template generated: {output_path}")
        else:
            logger.error("âŒ No PICS data extracted, cannot generate Excel template")
        
        # 3. è¾“å‡ºæ‘˜è¦
        logger.info(f"\nğŸ¯ Extraction Summary:")
        logger.info(f"   Processed specs: {extraction_summary['total_specs_processed']}/{len(self.supported_specs)}")
        logger.info(f"   Total PICS items: {extraction_summary['total_pics_items']}")
        logger.info(f"   Successful: {extraction_summary['successful_specs']}")
        if extraction_summary['failed_specs']:
            logger.info(f"   Failed: {extraction_summary['failed_specs']}")
        
        return extraction_summary
    
    def _extract_spec_pics(self, spec_id: str, spec_name: str) -> Optional[SpecificationPICS]:
        """
        æå–å•ä¸ªè§„èŒƒçš„PICSæ•°æ®
        
        Args:
            spec_id: è§„èŒƒIDï¼Œå¦‚"36.521-2"
            spec_name: è§„èŒƒåç§°ï¼Œå¦‚"TS 36.521-2"
            
        Returns:
            SpecificationPICS: æå–çš„PICSæ•°æ®ï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å›None
        """
        # æŸ¥æ‰¾è§„èŒƒæ–‡æ¡£
        spec_folders = list(self.data_source_base.glob(f"TS {spec_id}"))
        
        if not spec_folders:
            # å°è¯•å…¶ä»–å¯èƒ½çš„å‘½åæ¨¡å¼
            spec_folders = list(self.data_source_base.glob(f"*{spec_id}*"))
        
        if not spec_folders:
            logger.warning(f"Cannot find folder for {spec_name}")
            return None
        
        spec_folder = spec_folders[0]
        logger.info(f"   Found spec folder: {spec_folder}")
        
        # æŸ¥æ‰¾æ–‡æ¡£æ–‡ä»¶ï¼Œè¿‡æ»¤æ‰ä¸´æ—¶æ–‡ä»¶
        doc_files = []
        for pattern in ['*.docx', '*.doc']:
            files = list(spec_folder.rglob(pattern))
            # è¿‡æ»¤æ‰ä¸´æ—¶æ–‡ä»¶ï¼ˆä»¥~$å¼€å¤´ï¼‰
            files = [f for f in files if not f.name.startswith('~$')]
            doc_files.extend(files)
        
        if not doc_files:
            logger.warning(f"No documents found in {spec_folder}")
            return None
        
        # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„æ–‡æ¡£
        doc_file = doc_files[0]
        logger.info(f"   Using document: {doc_file.name}")
        
        try:
            # ä½¿ç”¨ç°æœ‰çš„ApplicabilityExtractoræå–PICSæ•°æ®
            extractor = ApplicabilityExtractor(str(doc_file))
            
            # ä½¿ç”¨å¼‚æ­¥è°ƒç”¨
            import asyncio
            extraction_result = asyncio.run(extractor.extract_all())
            
            if not extraction_result:
                logger.warning(f"No extraction result from {doc_file}")
                return None
            
            # è½¬æ¢ä¸ºEnhanced PICSæ ¼å¼
            pics_items = self._convert_to_enhanced_pics(extraction_result, spec_id, spec_name)
            
            spec_pics = SpecificationPICS(
                spec_name=spec_name,
                spec_version=spec_id,
                pics_items=pics_items,
                extraction_metadata={
                    'source_document': str(doc_file),
                    'extraction_date': pd.Timestamp.now().isoformat(),
                    'original_pics_count': len(extraction_result.get('conditions', {}).get('pics_conditions', [])),
                    'enhanced_pics_count': len(pics_items)
                }
            )
            
            return spec_pics
            
        except Exception as e:
            logger.error(f"Failed to extract PICS from {doc_file}: {e}")
            return None
    
    def _convert_to_enhanced_pics(self, extraction_result: Dict, spec_id: str, spec_name: str) -> List[PICSItem]:
        """
        å°†ç°æœ‰çš„PICSæå–ç»“æœè½¬æ¢ä¸ºå¢å¼ºçš„PICSæ ¼å¼
        
        Args:
            extraction_result: æ¥è‡ªApplicabilityExtractorçš„æå–ç»“æœ
            spec_id: è§„èŒƒID
            spec_name: è§„èŒƒåç§°
            
        Returns:
            List[PICSItem]: è½¬æ¢åçš„PICSé¡¹ç›®åˆ—è¡¨
        """
        pics_items = []
        
        # è·å–PICSæ¡ä»¶æ•°æ®
        pics_conditions = extraction_result.get('conditions', {}).get('pics_conditions', [])
        
        for pics_condition in pics_conditions:
            # è§£æPICSé¡¹ç›®æ•°æ®
            condition_id = pics_condition.get('condition_id', '')
            definition = pics_condition.get('definition', '')
            
            # ä»condition_idæ¨æ–­groupå’Œitem
            group, item = self._parse_pics_id(condition_id)
            
            # ç”ŸæˆUUID
            feature_id = str(uuid.uuid4())
            external_feature_gid = str(uuid.uuid4())
            
            # æ¨æ–­mnemonicï¼ˆå¦‚æœdefinitionä¸­åŒ…å«ï¼‰
            mnemonic = self._extract_mnemonic(definition)
            
            # æ¨æ–­statusï¼ˆåŸºäºè§„èŒƒå’Œé¡¹ç›®ç±»å‹ï¼‰
            status = self._infer_status(condition_id, definition)
            
            # æ¨æ–­supported_start_valueï¼ˆåŸºäºé¡¹ç›®ç±»å‹ï¼‰
            supported_start_value = self._infer_supported_start_value(condition_id, definition)
            
            pics_item = PICSItem(
                group=group,
                group_description=self._get_group_description(group, spec_id),
                item=item,
                description=definition,
                mnemonic=mnemonic,
                value="FALSE",  # é»˜è®¤å€¼
                allowed_settings="TRUE|FALSE",
                is_test_plan_relevant="TRUE",
                status=status,
                response_details="",
                feature_id=feature_id,
                external_feature_gid=external_feature_gid,
                supported_start_value=supported_start_value
            )
            
            pics_items.append(pics_item)
        
        return pics_items
    
    def _parse_pics_id(self, condition_id: str) -> Tuple[str, str]:
        """
        è§£æPICS IDä»¥æå–groupå’Œitem
        
        Args:
            condition_id: PICSæ¡ä»¶IDï¼Œå¦‚"A.4.1-1/1"
            
        Returns:
            Tuple[str, str]: (group, item)
        """
        if not condition_id:
            return "Unknown", "Unknown"
        
        # å°è¯•åŒ¹é…æ ‡å‡†PICS IDæ ¼å¼
        match = re.match(r'(A\.\d+(?:\.\d+)*(?:-\d+)?)', condition_id)
        if match:
            base_id = match.group(1)
            # æ¨æ–­è¡¨æ ¼åç§°
            group = f"Table {base_id}"
            item = condition_id
            return group, item
        
        # å¦‚æœæ˜¯PC_å¼€å¤´çš„æ¡ä»¶
        if condition_id.startswith('PC_'):
            return "Protocol Conditions", condition_id
        
        # å…¶ä»–æ ¼å¼
        return "Other Conditions", condition_id
    
    def _extract_mnemonic(self, definition: str) -> Optional[str]:
        """
        ä»å®šä¹‰ä¸­æå–mnemonicï¼ˆåŠ©è®°ç¬¦ï¼‰
        
        Args:
            definition: åŠŸèƒ½å®šä¹‰å­—ç¬¦ä¸²
            
        Returns:
            Optional[str]: æå–çš„mnemonicï¼Œå¦‚æœæ²¡æœ‰åˆ™è¿”å›None
        """
        if not definition:
            return None
        
        # å¯»æ‰¾å¸¸è§çš„mnemonicæ¨¡å¼
        mnemonic_patterns = [
            r'pc_(\w+)',
            r'mnemonic[:\s]+(\w+)',
            r'\((\w+)\)',
        ]
        
        for pattern in mnemonic_patterns:
            match = re.search(pattern, definition, re.IGNORECASE)
            if match:
                return match.group(1)
        
        return None
    
    def _infer_status(self, condition_id: str, definition: str) -> str:
        """
        æ¨æ–­PICSé¡¹ç›®çš„çŠ¶æ€
        
        Args:
            condition_id: PICSæ¡ä»¶ID
            definition: åŠŸèƒ½å®šä¹‰
            
        Returns:
            str: æ¨æ–­çš„çŠ¶æ€ï¼ˆMandatory, Optionalç­‰ï¼‰
        """
        definition_lower = definition.lower() if definition else ""
        
        if any(keyword in definition_lower for keyword in ['mandatory', 'shall', 'required']):
            return "Mandatory"
        elif any(keyword in definition_lower for keyword in ['optional', 'may']):
            return "Optional"
        else:
            return "Optional"  # é»˜è®¤ä¸ºOptional
    
    def _infer_supported_start_value(self, condition_id: str, definition: str) -> str:
        """
        æ¨æ–­æ”¯æŒçš„èµ·å§‹å€¼
        
        Args:
            condition_id: PICSæ¡ä»¶ID
            definition: åŠŸèƒ½å®šä¹‰
            
        Returns:
            str: æ¨æ–­çš„èµ·å§‹å€¼ï¼ˆTRUEæˆ–FALSEï¼‰
        """
        definition_lower = definition.lower() if definition else ""
        
        # åŸºäºå®šä¹‰å†…å®¹æ¨æ–­
        if any(keyword in definition_lower for keyword in ['mandatory', 'default', 'basic']):
            return "TRUE"
        else:
            return "FALSE"
    
    def _get_group_description(self, group: str, spec_id: str) -> str:
        """
        è·å–ç»„æè¿°
        
        Args:
            group: ç»„åç§°
            spec_id: è§„èŒƒID
            
        Returns:
            str: ç»„æè¿°
        """
        # åŸºäºç»„åç§°å’Œè§„èŒƒIDæ¨æ–­æè¿°
        group_descriptions = {
            "Table A.0": "UE Release information",
            "Table A.1": "UE Radio Technologies",
            "Table A.2": "Roles",
            "Table A.3": "UE capabilities",
            "Table A.4": "RF capabilities",
            "Protocol Conditions": "Protocol-specific conditions",
            "Other Conditions": "Other conditions"
        }
        
        # æŸ¥æ‰¾åŒ¹é…çš„æè¿°
        for key, desc in group_descriptions.items():
            if key in group:
                return desc
        
        return "Feature group"  # é»˜è®¤æè¿°
    
    def _generate_interlab_excel(self, all_spec_data: Dict[str, SpecificationPICS], output_path: str):
        """
        ç”ŸæˆInterlab Excelæ¨¡æ¿
        
        Args:
            all_spec_data: æ‰€æœ‰è§„èŒƒçš„PICSæ•°æ®
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        logger.info("ğŸ“ Creating Interlab Excel template...")
        
        with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
            # 1. åˆ›å»ºOverviewå·¥ä½œè¡¨
            self._create_overview_sheet(writer, all_spec_data)
            
            # 2. åˆ›å»ºInfoå·¥ä½œè¡¨
            self._create_info_sheet(writer)
            
            # 3. ä¸ºæ¯ä¸ªè§„èŒƒåˆ›å»ºå·¥ä½œè¡¨
            for spec_id, spec_pics in all_spec_data.items():
                sheet_name = f"3GPP {spec_pics.spec_name}"
                self._create_spec_sheet(writer, sheet_name, spec_pics)
        
        logger.info(f"âœ… Excel template created with {len(all_spec_data)} specification sheets")
    
    def _create_overview_sheet(self, writer: pd.ExcelWriter, all_spec_data: Dict[str, SpecificationPICS]):
        """åˆ›å»ºOverviewå·¥ä½œè¡¨"""
        overview_data = []
        
        overview_data.append([
            "The purpose of this Feature Spreadsheet is to import product features into InterLab to describe an Object Under Test and create a device-specific test plan. Enter 'TRUE' or 'FALSE' in the value field to indicate support of a specific feature. Values for some features are enumerated types. The Allowed Values column indicates the expected values. Each individual worksheets represent one specification (as shown in the table below) which contains Features / Requirements / PICS / PIXIT.\n\nIt is strongly recommended not change the format of this document. Template Version: 1.2.1 (Generated)",
            None,
            None
        ])
        
        overview_data.append(["Test Specification", "Release", "Comments"])
        
        for spec_id, spec_pics in all_spec_data.items():
            overview_data.append([
                f"3GPP {spec_pics.spec_name}",
                "Latest",
                f"Generated from 3GPP documents ({len(spec_pics.pics_items)} PICS items)"
            ])
        
        overview_df = pd.DataFrame(overview_data, columns=["Feature Spreadsheet Overview", "Unnamed: 1", "Unnamed: 2"])
        overview_df.to_excel(writer, sheet_name="Overview", index=False)
    
    def _create_info_sheet(self, writer: pd.ExcelWriter):
        """åˆ›å»ºInfoå·¥ä½œè¡¨"""
        info_data = [
            [None, None],
            ["Project Name:", "Generated 3GPP PICS"],
            ["Generated By:", "Enhanced 3GPP-2 PICS Extractor"],
            ["Generation Date:", pd.Timestamp.now().strftime("%Y-%m-%d %H:%M:%S")],
            ["Version:", "1.0"]
        ]
        
        info_df = pd.DataFrame(info_data, columns=["Unnamed: 0", "Feature Spreadsheet Info"])
        info_df.to_excel(writer, sheet_name="Info", index=False)
    
    def _create_spec_sheet(self, writer: pd.ExcelWriter, sheet_name: str, spec_pics: SpecificationPICS):
        """ä¸ºè§„èŒƒåˆ›å»ºå·¥ä½œè¡¨ï¼ˆå®Œå…¨åŒ¹é…åŸå§‹æ¨¡æ¿æ ¼å¼ï¼‰"""
        import numpy as np
        
        # æå–è§„èŒƒåç§°
        spec_name_col = sheet_name.split(' ')[-1]  # å¦‚"36.521-2"
        
        # åˆ›å»ºå®Œå…¨åŒ¹é…åŸå§‹æ¨¡æ¿çš„æ•°æ®ç»“æ„
        all_rows = []
        
        # ç¬¬ä¸€è¡Œï¼šExcelå·¥ä½œè¡¨æ ‡é¢˜è¡Œï¼ˆä¸åŸå§‹æ¨¡æ¿å®Œå…¨ä¸€è‡´ï¼‰
        title_row = [np.nan, np.nan, f'3GPP TS {spec_name_col}', np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]
        all_rows.append(title_row)
        
        # ç¬¬äºŒè¡Œï¼šåˆ—æ ‡é¢˜è¡Œ
        column_headers = ['Group', 'Group Description', 'Item', 'Description', 'Mnemonic', 'Value', 'Allowed\nSettings', 'Is Test Plan\nRelevant', 'Status', 'Response Details', 'FeatureID', 'ExternalFeatureGID', 'SupportedStartValue']
        all_rows.append(column_headers)
        
        # æ•°æ®è¡Œ
        if spec_pics.pics_items:
            for pics_item in spec_pics.pics_items:
                data_row = [
                    pics_item.group,
                    pics_item.group_description,
                    pics_item.item,
                    pics_item.description,
                    pics_item.mnemonic,
                    pics_item.value,
                    pics_item.allowed_settings,
                    pics_item.is_test_plan_relevant,
                    pics_item.status,
                    pics_item.response_details,
                    pics_item.feature_id,
                    pics_item.external_feature_gid,
                    pics_item.supported_start_value
                ]
                all_rows.append(data_row)
        
        # åˆ›å»ºDataFrameï¼ˆæ— åˆ—åï¼‰
        final_df = pd.DataFrame(all_rows)
        
        # å†™å…¥Excelï¼ˆæ— æ ‡é¢˜ï¼Œæ— ç´¢å¼•ï¼‰
        final_df.to_excel(writer, sheet_name=sheet_name, index=False, header=False)
        
        if spec_pics.pics_items:
            logger.info(f"   Created sheet '{sheet_name}' with {len(spec_pics.pics_items)} PICS items (perfect format match)")
        else:
            logger.warning(f"   Created empty sheet '{sheet_name}' (perfect format match)")


def main():
    """ä¸»ç¨‹åºå…¥å£"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Enhanced 3GPP-2 PICS Extractor for Interlab Templates')
    parser.add_argument('--output', '-o', default='generated_interlab_template.xlsx', 
                       help='Output Excel file path (default: generated_interlab_template.xlsx)')
    parser.add_argument('--specs', nargs='+', help='Specific specs to extract (e.g., 36.521-2 36.523-2)')
    
    args = parser.parse_args()
    
    # åˆ›å»ºæå–å™¨
    extractor = Enhanced3GPP2PICSExtractor()
    
    # å¦‚æœæŒ‡å®šäº†ç‰¹å®šè§„èŒƒï¼Œé™åˆ¶å¤„ç†èŒƒå›´
    if args.specs:
        original_specs = extractor.supported_specs.copy()
        extractor.supported_specs = {spec: original_specs[spec] for spec in args.specs if spec in original_specs}
        logger.info(f"Processing only specified specs: {list(extractor.supported_specs.keys())}")
    
    try:
        # æ‰§è¡Œæå–å¹¶ç”ŸæˆExcelæ¨¡æ¿
        result = extractor.extract_all_specs_to_excel(args.output)
        
        print("\nğŸ‰ Enhanced PICS extraction completed!")
        print(f"ğŸ“Š Summary:")
        print(f"   Processed specifications: {result['total_specs_processed']}")
        print(f"   Total PICS items extracted: {result['total_pics_items']}")
        print(f"   Output file: {result['output_file']}")
        
        if result['successful_specs']:
            print(f"   âœ… Successful: {', '.join(result['successful_specs'])}")
        if result['failed_specs']:
            print(f"   âŒ Failed: {', '.join(result['failed_specs'])}")
        
        return 0
        
    except Exception as e:
        logger.error(f"âŒ Extraction failed: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    import sys
    sys.exit(main())su