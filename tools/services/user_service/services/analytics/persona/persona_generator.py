#!/usr/bin/env python3
"""
Persona Generator Service - åŸºäºMLåˆ†æç»“æœç”Ÿæˆä¸“ä¸šç”¨æˆ·ç”»åƒæ–‡æœ¬æè¿°
Gold Data -> ML Analysis -> AI-Generated Persona -> pgvectorå­˜å‚¨
"""

import json
from datetime import datetime
from typing import Dict, List, Any, Optional
from core.logging import get_logger
from core.database import get_supabase_client
from tools.services.intelligence_service.language.text_generator import text_generator

logger = get_logger(__name__)

class PersonaGenerator:
    """
    ä¸“ä¸šç”¨æˆ·ç”»åƒç”Ÿæˆå™¨
    
    åŠŸèƒ½ï¼š
    1. åŸºäºMLåˆ†æç»“æœæ„å»ºä¸“ä¸šçš„persona prompt
    2. è°ƒç”¨text_generatorç”Ÿæˆå®Œæ•´ç”¨æˆ·ç”»åƒæ–‡æœ¬
    3. æå–å…³é”®ç‰¹å¾å¹¶å­˜å‚¨åˆ°pgvector
    4. æ”¯æŒpersonaç‰ˆæœ¬ç®¡ç†å’Œæ›´æ–°
    """
    
    def __init__(self):
        self.db_client = get_supabase_client()
        
    async def generate_user_persona(self, user_id: str, ml_features: Dict[str, Any], 
                                  gold_data: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆç”¨æˆ·çš„ä¸“ä¸špersonaæè¿°"""
        try:
            logger.info(f"ğŸ­ Generating persona for user: {user_id}")
            
            # 1. æ„å»ºä¸“ä¸šçš„personaç”Ÿæˆprompt
            persona_prompt = self._build_persona_prompt(user_id, ml_features, gold_data)
            
            # 2. ä½¿ç”¨text_generatorç”Ÿæˆpersonaæ–‡æœ¬
            persona_text = await text_generator.generate(
                prompt=persona_prompt,
                temperature=0.7,  # é€‚ä¸­çš„åˆ›é€ æ€§
                max_tokens=1500   # è¶³å¤Ÿè¯¦ç»†çš„æè¿°
            )
            
            # 3. è§£æå’Œç»“æ„åŒ–personaå†…å®¹
            structured_persona = self._parse_persona_response(persona_text)
            
            # 4. ç”Ÿæˆpersonaå‘é‡ç‰¹å¾ï¼ˆç”¨äºpgvectorï¼‰
            persona_vector = await self._generate_persona_embedding(persona_text)
            
            # 5. æ„å»ºå®Œæ•´çš„personaè®°å½•
            persona_record = {
                "user_id": user_id,
                "persona_text": persona_text,
                "structured_persona": structured_persona,
                "persona_vector": persona_vector,
                "ml_features_used": ml_features,
                "gold_data_summary": self._summarize_gold_data(gold_data),
                "generation_timestamp": datetime.now().isoformat(),
                "persona_version": "1.0",
                "confidence_score": self._calculate_persona_confidence(ml_features, gold_data),
                "persona_tags": self._extract_persona_tags(structured_persona)
            }
            
            # 6. å­˜å‚¨åˆ°æ•°æ®åº“
            await self._store_persona(persona_record)
            
            logger.info(f"âœ… Persona generated successfully for user: {user_id}")
            logger.info(f"ğŸ“ Persona length: {len(persona_text)} characters")
            logger.info(f"ğŸ·ï¸ Tags: {', '.join(persona_record['persona_tags'])}")
            
            return {
                "success": True,
                "user_id": user_id,
                "persona_text": persona_text,
                "structured_persona": structured_persona,
                "confidence_score": persona_record["confidence_score"],
                "persona_tags": persona_record["persona_tags"]
            }
            
        except Exception as e:
            logger.error(f"âŒ Persona generation failed for user {user_id}: {e}")
            import traceback
            traceback.print_exc()
            return {"success": False, "error": str(e), "user_id": user_id}
    
    def _build_persona_prompt(self, user_id: str, ml_features: Dict[str, Any], 
                            gold_data: Dict[str, Any]) -> str:
        """æ„å»ºä¸“ä¸šçš„personaç”Ÿæˆprompt"""
        
        # æå–å…³é”®MLç‰¹å¾
        work_pattern = ml_features.get('primary_work_pattern', 'flexible')
        usage_intensity = ml_features.get('usage_intensity', 'moderate')
        peak_hours = ml_features.get('peak_activity_hours', [])
        consistency = ml_features.get('behavior_consistency', 'moderate')
        
        # æå–é‡‘æ•°æ®ç‰¹å¾
        technical_skills = gold_data.get('technical_skills', [])
        knowledge_domains = gold_data.get('knowledge_domains', [])
        key_insights = gold_data.get('key_insights', [])
        
        prompt = f"""You are a professional user experience researcher and data analyst. Based on comprehensive behavioral analysis and machine learning insights, create a detailed, professional user persona.

## User Behavioral Analysis Data

### Time & Work Patterns (ML-Analyzed)
- Work Pattern: {work_pattern}
- Usage Intensity: {usage_intensity} 
- Peak Activity Hours: {peak_hours}
- Behavior Consistency: {consistency}
- Analysis Period: {ml_features.get('analysis_period_days', 'N/A')} days
- Total Data Points: {ml_features.get('total_data_points', 'N/A')}
- Pattern Confidence: {ml_features.get('pattern_confidence', 0):.2f}

### Technical Competencies (Content-Analyzed)
- Technical Skills: {', '.join(technical_skills) if technical_skills else 'General user'}
- Knowledge Domains: {', '.join(knowledge_domains) if knowledge_domains else 'Not specified'}
- Key Professional Insights: {'. '.join(key_insights) if key_insights else 'Limited technical activity'}

### Content Analysis Summary
- Total Content Analyzed: {gold_data.get('content_length', 0)} characters
- Data Completeness: {gold_data.get('data_completeness_score', 0):.2f}

## Persona Generation Instructions

Create a comprehensive, professional user persona following this structure:

### 1. PROFESSIONAL IDENTITY
- Role/Title (inferred from activities and skills)
- Industry/Domain focus
- Experience level assessment

### 2. WORK STYLE & PREFERENCES  
- Detailed work pattern analysis (based on peak hours and consistency data)
- Preferred working environment
- Task management approach
- Communication style

### 3. TECHNICAL PROFILE
- Core technical competencies 
- Learning approach and preferences
- Problem-solving methodology
- Tool preferences and proficiency

### 4. BEHAVIORAL CHARACTERISTICS
- Usage intensity and engagement patterns
- Consistency in routine vs. flexibility
- Response to different types of tasks
- Collaboration vs. independent work preference

### 5. GROWTH TRAJECTORY
- Current skill development areas
- Learning velocity and patterns
- Potential career progression
- Recommended development paths

### 6. INTERACTION PREFERENCES
- Preferred communication style
- Information consumption patterns
- Feedback and guidance preferences
- Optimal support approaches

## Writing Guidelines:
- Write in third person, professional tone
- Be specific and actionable, not generic
- Base all observations on provided data
- Include confidence indicators where appropriate  
- Make persona relatable and realistic
- Focus on professional context and capabilities

Generate a comprehensive persona (800-1200 words) that would be valuable for personalized user experience design, content customization, and professional development recommendations."""

        return prompt
    
    def _parse_persona_response(self, persona_text: str) -> Dict[str, str]:
        """è§£æAIç”Ÿæˆçš„personaæ–‡æœ¬ï¼Œæå–ç»“æ„åŒ–ä¿¡æ¯"""
        try:
            structured = {}
            
            # ç®€å•çš„æ–‡æœ¬è§£æï¼Œæå–ä¸»è¦æ®µè½
            sections = [
                "PROFESSIONAL IDENTITY", "WORK STYLE & PREFERENCES", 
                "TECHNICAL PROFILE", "BEHAVIORAL CHARACTERISTICS",
                "GROWTH TRAJECTORY", "INTERACTION PREFERENCES"
            ]
            
            current_section = "overview"
            current_content = []
            
            for line in persona_text.split('\n'):
                line = line.strip()
                if not line:
                    continue
                    
                # æ£€æŸ¥æ˜¯å¦æ˜¯æ–°çš„æ®µè½æ ‡é¢˜
                section_found = None
                for section in sections:
                    if section in line.upper():
                        section_found = section.lower().replace(' ', '_').replace('&', 'and')
                        break
                
                if section_found:
                    # ä¿å­˜å‰ä¸€ä¸ªæ®µè½
                    if current_content:
                        structured[current_section] = '\n'.join(current_content)
                    
                    # å¼€å§‹æ–°æ®µè½
                    current_section = section_found
                    current_content = []
                else:
                    current_content.append(line)
            
            # ä¿å­˜æœ€åä¸€ä¸ªæ®µè½
            if current_content:
                structured[current_section] = '\n'.join(current_content)
            
            # å¦‚æœè§£æå¤±è´¥ï¼Œè‡³å°‘ä¿ç•™å®Œæ•´æ–‡æœ¬
            if not structured or len(structured) < 3:
                structured = {"full_text": persona_text}
            
            return structured
            
        except Exception as e:
            logger.warning(f"âš ï¸ Failed to parse persona response: {e}")
            return {"full_text": persona_text}
    
    async def _generate_persona_embedding(self, persona_text: str) -> List[float]:
        """ç”Ÿæˆpersonaæ–‡æœ¬çš„å‘é‡è¡¨ç¤ºï¼ˆç”¨äºpgvectorå­˜å‚¨ï¼‰- ä½¿ç”¨ç°æœ‰çš„embedding_generator"""
        try:
            # ä½¿ç”¨ç°æœ‰çš„embedding_generatoræœåŠ¡
            from tools.services.intelligence_service.language.embedding_generator import embedding_generator
            
            # æˆªå–åˆé€‚é•¿åº¦é¿å…tokené™åˆ¶
            max_chars = 5000  # embedding_generatorå†…éƒ¨ä¼šå¤„ç†é•¿åº¦é™åˆ¶
            truncated_text = persona_text[:max_chars] if len(persona_text) > max_chars else persona_text
            
            # ç”Ÿæˆembeddingå‘é‡
            embedding_vector = await embedding_generator.embed_single(
                text=truncated_text,
                model="text-embedding-3-small"  # 1536ç»´å‘é‡
            )
            
            logger.info(f"ğŸ“Š Generated {len(embedding_vector)}-dimensional embedding vector using ISA")
            return embedding_vector
            
        except Exception as e:
            logger.warning(f"âš ï¸ Failed to generate persona embedding with ISA: {e}")
            # è¿”å›é›¶å‘é‡ä½œä¸ºfallback (1536ç»´åŒ¹é…text-embedding-3-small)
            return [0.0] * 1536
    
    def _summarize_gold_data(self, gold_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ±‡æ€»é‡‘æ•°æ®ç”¨äºå­˜å‚¨"""
        return {
            "content_length": gold_data.get('content_length', 0),
            "technical_skills_count": len(gold_data.get('technical_skills', [])),
            "knowledge_domains_count": len(gold_data.get('knowledge_domains', [])),
            "data_completeness_score": gold_data.get('data_completeness_score', 0),
            "key_insights_count": len(gold_data.get('key_insights', []))
        }
    
    def _calculate_persona_confidence(self, ml_features: Dict[str, Any], gold_data: Dict[str, Any]) -> float:
        """è®¡ç®—personaç½®ä¿¡åº¦è¯„åˆ†"""
        try:
            confidence_factors = []
            
            # MLç‰¹å¾è´¨é‡
            pattern_confidence = ml_features.get('pattern_confidence', 0)
            confidence_factors.append(pattern_confidence * 0.4)
            
            # æ•°æ®å®Œæ•´æ€§
            data_completeness = gold_data.get('data_completeness_score', 0)
            confidence_factors.append(data_completeness * 0.3)
            
            # åˆ†ææ—¶é—´è·¨åº¦
            analysis_days = ml_features.get('analysis_period_days', 1)
            time_factor = min(1.0, analysis_days / 7)  # 7å¤©ä¸ºæ»¡åˆ†
            confidence_factors.append(time_factor * 0.2)
            
            # æŠ€æœ¯ç‰¹å¾ä¸°å¯Œåº¦
            tech_skills = len(gold_data.get('technical_skills', []))
            tech_factor = min(1.0, tech_skills / 5)  # 5ä¸ªæŠ€èƒ½ä¸ºæ»¡åˆ†
            confidence_factors.append(tech_factor * 0.1)
            
            total_confidence = sum(confidence_factors)
            return round(total_confidence, 2)
            
        except Exception as e:
            logger.warning(f"âš ï¸ Failed to calculate persona confidence: {e}")
            return 0.5
    
    def _extract_persona_tags(self, structured_persona: Dict[str, str]) -> List[str]:
        """ä»ç»“æ„åŒ–personaä¸­æå–æ ‡ç­¾"""
        try:
            tags = []
            
            # ä»æ–‡æœ¬å†…å®¹æå–å…³é”®æ ‡ç­¾
            full_text = ' '.join(structured_persona.values()).lower()
            
            # æŠ€æœ¯æ ‡ç­¾
            tech_terms = ['python', 'javascript', 'java', 'sql', 'react', 'fastapi', 'django', 'aws', 'docker', 'kubernetes']
            for term in tech_terms:
                if term in full_text:
                    tags.append(f"tech_{term}")
            
            # è§’è‰²æ ‡ç­¾
            if 'developer' in full_text or 'engineer' in full_text:
                tags.append('role_developer')
            if 'data' in full_text and ('scientist' in full_text or 'analyst' in full_text):
                tags.append('role_data_professional')
            if 'student' in full_text or 'learning' in full_text:
                tags.append('role_learner')
            
            # å·¥ä½œæ¨¡å¼æ ‡ç­¾
            if 'morning' in full_text:
                tags.append('pattern_morning_person')
            elif 'night' in full_text or 'evening' in full_text:
                tags.append('pattern_night_owl')
            
            # ä½¿ç”¨å¼ºåº¦æ ‡ç­¾
            if 'heavy' in full_text or 'intensive' in full_text:
                tags.append('usage_heavy')
            elif 'moderate' in full_text:
                tags.append('usage_moderate')
            elif 'light' in full_text:
                tags.append('usage_light')
            
            # é™åˆ¶æ ‡ç­¾æ•°é‡
            return tags[:10]
            
        except Exception as e:
            logger.warning(f"âš ï¸ Failed to extract persona tags: {e}")
            return ['general_user']
    
    async def _store_persona(self, persona_record: Dict[str, Any]):
        """å­˜å‚¨personaåˆ°æ•°æ®åº“"""
        try:
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨persona
            existing_response = self.db_client.table('user_personas')\
                .select('id')\
                .eq('user_id', persona_record['user_id'])\
                .execute()
            
            if existing_response.data:
                # æ›´æ–°ç°æœ‰persona
                update_data = {
                    **persona_record,
                    'updated_at': datetime.now().isoformat()
                }
                self.db_client.table('user_personas')\
                    .update(update_data)\
                    .eq('user_id', persona_record['user_id'])\
                    .execute()
                logger.info(f"ğŸ“ Updated existing persona for user: {persona_record['user_id']}")
            else:
                # åˆ›å»ºæ–°persona
                insert_data = {
                    **persona_record,
                    'created_at': datetime.now().isoformat(),
                    'updated_at': datetime.now().isoformat()
                }
                self.db_client.table('user_personas')\
                    .insert(insert_data)\
                    .execute()
                logger.info(f"ğŸ†• Created new persona for user: {persona_record['user_id']}")
            
        except Exception as e:
            logger.error(f"âŒ Failed to store persona: {e}")
            raise
    
    async def get_user_persona(self, user_id: str) -> Optional[Dict[str, Any]]:
        """è·å–ç”¨æˆ·çš„persona"""
        try:
            response = self.db_client.table('user_personas')\
                .select('*')\
                .eq('user_id', user_id)\
                .single()\
                .execute()
            
            return response.data if response.data else None
            
        except Exception as e:
            logger.warning(f"âš ï¸ Failed to get persona for user {user_id}: {e}")
            return None
    
    async def generate_persona_from_ml_analysis(self, user_id: str) -> Dict[str, Any]:
        """å®Œæ•´çš„pipelineï¼šä»ç”¨æˆ·IDç”Ÿæˆpersonaï¼ˆé›†æˆå‰é¢çš„MLåˆ†æï¼‰"""
        try:
            # è¿™é‡Œåº”è¯¥è°ƒç”¨å‰é¢çš„MLåˆ†ææœåŠ¡
            # ä¸ºæ¼”ç¤ºç›®çš„ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
            logger.info(f"ğŸ”„ Running complete persona generation pipeline for: {user_id}")
            
            # 1. æ”¶é›†Gold Dataï¼ˆæ¨¡æ‹Ÿï¼Œå®é™…ä¸­è°ƒç”¨ETLæœåŠ¡ï¼‰
            gold_data = {
                "technical_skills": ["python", "sql"],
                "knowledge_domains": ["Setting up a Python web application using FastAPI", "Database integration with FastAPI"],
                "key_insights": ["Python 3.9 is installed", "FastAPI and Uvicorn installed via pip", "PostgreSQL chosen for production"],
                "content_length": 3464,
                "data_completeness_score": 1.0
            }
            
            # 2. MLç‰¹å¾ï¼ˆæ¨¡æ‹Ÿï¼Œå®é™…ä¸­è°ƒç”¨MLåˆ†ææœåŠ¡ï¼‰
            ml_features = {
                "peak_activity_hours": [8, 9],
                "primary_work_pattern": "morning_person", 
                "usage_intensity": "heavy",
                "behavior_consistency": "variable",
                "total_data_points": 50,
                "analysis_period_days": 2,
                "pattern_confidence": 1.0
            }
            
            # 3. ç”Ÿæˆpersona
            return await self.generate_user_persona(user_id, ml_features, gold_data)
            
        except Exception as e:
            logger.error(f"âŒ Complete persona generation pipeline failed: {e}")
            return {"success": False, "error": str(e)}

# å…¨å±€å®ä¾‹
persona_generator = PersonaGenerator()

# ä¾¿æ·å‡½æ•°
async def generate_user_persona(user_id: str) -> Dict[str, Any]:
    """ç”Ÿæˆç”¨æˆ·personaï¼ˆå®Œæ•´pipelineï¼‰"""
    return await persona_generator.generate_persona_from_ml_analysis(user_id)

async def get_persona(user_id: str) -> Optional[Dict[str, Any]]:
    """è·å–ç”¨æˆ·persona"""
    return await persona_generator.get_user_persona(user_id)