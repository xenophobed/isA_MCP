#!/usr/bin/env python3
"""
Machine Learning Processor V2
åŸºäºæ–°çš„ BaseDataProcessor çš„ç»Ÿä¸€æœºå™¨å­¦ä¹ æ¥å£
ä½¿ç”¨ç»Ÿä¸€çš„æ¨¡å‹å¯¼å…¥æœåŠ¡ï¼Œå®Œå…¨é¿å… mutex é”é—®é¢˜
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Any, Optional, Tuple, Union
from datetime import datetime
import logging
import json
from pathlib import Path

# å¯¼å…¥æ–°çš„åŸºç±»
from tools.services.data_analytics_service.processors.data_processors.base_data_processor import MLModelProcessor, ProcessorCapabilities
from tools.services.data_analytics_service.services.model_import_service import MLLibrary

logger = logging.getLogger(__name__)

class MLProcessor(MLModelProcessor):
    """
    æœºå™¨å­¦ä¹ å¤„ç†å™¨
    
    æä¾›ç»Ÿä¸€çš„æœºå™¨å­¦ä¹ æ¥å£ï¼Œæ”¯æŒï¼š
    - æ¨¡å‹è®­ç»ƒå’Œé¢„æµ‹
    - è‡ªåŠ¨ç®—æ³•æ¨è
    - è¶…å‚æ•°ä¼˜åŒ–
    - æ¨¡å‹è¯„ä¼°
    """
    
    def __init__(self, csv_processor=None, file_path: Optional[str] = None):
        """åˆå§‹åŒ–MLå¤„ç†å™¨"""
        super().__init__(csv_processor, file_path)
        
        # MLç‰¹å®šçš„é…ç½®
        self.execution_stats = {
            'total_operations': 0,
            'successful_operations': 0,
            'failed_operations': 0,
            'models_trained': 0
        }
        
        logger.info(f"ğŸ¤– MLProcessor initialized with libraries: {self._get_available_libraries()}")
    
    def _define_capabilities(self) -> ProcessorCapabilities:
        """å®šä¹‰MLå¤„ç†å™¨çš„å…·ä½“èƒ½åŠ›"""
        return ProcessorCapabilities(
            required_libraries=[MLLibrary.SKLEARN],
            optional_libraries=[MLLibrary.XGBOOST, MLLibrary.LIGHTGBM, MLLibrary.PYTORCH, MLLibrary.TENSORFLOW],
            supports_training=True,
            supports_prediction=True,
            supports_evaluation=True,
            supports_visualization=False
        )
    
    def _get_available_libraries(self) -> List[str]:
        """è·å–å¯ç”¨çš„åº“åˆ—è¡¨"""
        available = []
        if self.sklearn_available:
            available.append("sklearn")
        if self.xgboost_available:
            available.append("xgboost")
        if self.lightgbm_available:
            available.append("lightgbm")
        if self.pytorch_available:
            available.append("pytorch")
        if self.tensorflow_available:
            available.append("tensorflow")
        return available
    
    # ==================== æ•°æ®é¢„å¤„ç† ====================
    
    def prepare_data(self, target_column: str, test_size: float = 0.2, random_state: int = 42) -> Dict[str, Any]:
        """
        å‡†å¤‡è®­ç»ƒæ•°æ®
        
        Args:
            target_column: ç›®æ ‡åˆ—å
            test_size: æµ‹è¯•é›†æ¯”ä¾‹
            random_state: éšæœºç§å­
        
        Returns:
            åŒ…å«è®­ç»ƒæµ‹è¯•æ•°æ®çš„å­—å…¸
        """
        if not self.validate_data():
            raise ValueError("No valid data available")
        
        if target_column not in self.df.columns:
            raise ValueError(f"Target column '{target_column}' not found in data")
        
        # åˆ†ç¦»ç‰¹å¾å’Œç›®æ ‡
        X = self.df.drop(columns=[target_column])
        y = self.df[target_column]
        
        # è·å–æ•°æ®åˆ†å‰²å‡½æ•°
        train_test_split = self.get_train_test_split()
        if train_test_split is None:
            raise ImportError("sklearn train_test_split not available")
        
        # åˆ†å‰²æ•°æ®
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=random_state
        )
        
        return {
            'X_train': X_train,
            'X_test': X_test,
            'y_train': y_train,
            'y_test': y_test,
            'feature_names': X.columns.tolist(),
            'target_name': target_column,
            'data_shape': X.shape,
            'target_type': self._detect_target_type(y)
        }
    
    def _detect_target_type(self, y) -> str:
        """æ£€æµ‹ç›®æ ‡å˜é‡ç±»å‹"""
        if pd.api.types.is_numeric_dtype(y):
            unique_values = y.nunique()
            if unique_values <= 10:
                return 'classification'
            else:
                return 'regression'
        else:
            return 'classification'
    
    # ==================== ç®—æ³•æ¨è ====================
    
    def recommend_algorithms(self, target_column: str, problem_type: Optional[str] = None) -> Dict[str, Any]:
        """
        æ¨èåˆé€‚çš„ç®—æ³•
        
        Args:
            target_column: ç›®æ ‡åˆ—å
            problem_type: é—®é¢˜ç±»å‹ ('classification' æˆ– 'regression')
        
        Returns:
            ç®—æ³•æ¨èç»“æœ
        """
        if not self.validate_data():
            return {'error': 'No valid data available'}
        
        # è‡ªåŠ¨æ£€æµ‹é—®é¢˜ç±»å‹
        if problem_type is None:
            y = self.df[target_column] if target_column in self.df.columns else None
            if y is not None:
                problem_type = self._detect_target_type(y)
            else:
                problem_type = 'classification'
        
        recommendations = {
            'problem_type': problem_type,
            'data_info': {
                'shape': self.df.shape,
                'features': len(self.df.columns) - 1,
                'samples': len(self.df)
            },
            'algorithms': []
        }
        
        # åŸºäºsklearnçš„ç®—æ³•æ¨è
        if self.sklearn_available:
            if problem_type == 'classification':
                recommendations['algorithms'].extend([
                    {
                        'name': 'RandomForest',
                        'library': 'sklearn',
                        'complexity': 'medium',
                        'interpretability': 'medium',
                        'performance': 'high',
                        'pros': ['Good default performance', 'Handles missing values', 'Feature importance'],
                        'cons': ['Can overfit', 'Memory intensive']
                    },
                    {
                        'name': 'LogisticRegression', 
                        'library': 'sklearn',
                        'complexity': 'low',
                        'interpretability': 'high',
                        'performance': 'medium',
                        'pros': ['Fast', 'Interpretable', 'Probabilistic output'],
                        'cons': ['Assumes linear relationship', 'Sensitive to outliers']
                    }
                ])
            else:
                recommendations['algorithms'].extend([
                    {
                        'name': 'RandomForestRegressor',
                        'library': 'sklearn', 
                        'complexity': 'medium',
                        'interpretability': 'medium',
                        'performance': 'high',
                        'pros': ['Robust', 'Feature importance', 'Non-linear'],
                        'cons': ['Can overfit', 'Not good for extrapolation']
                    },
                    {
                        'name': 'LinearRegression',
                        'library': 'sklearn',
                        'complexity': 'low',
                        'interpretability': 'high', 
                        'performance': 'medium',
                        'pros': ['Fast', 'Interpretable', 'Simple'],
                        'cons': ['Assumes linear relationship', 'Sensitive to outliers']
                    }
                ])
        
        # XGBoostæ¨è
        if self.xgboost_available:
            xgb_rec = {
                'name': 'XGBoost',
                'library': 'xgboost',
                'complexity': 'high',
                'interpretability': 'low',
                'performance': 'very_high',
                'pros': ['Excellent performance', 'Feature importance', 'Handles missing values'],
                'cons': ['Requires tuning', 'Can overfit', 'Complex']
            }
            recommendations['algorithms'].append(xgb_rec)
        
        # LightGBMæ¨è
        if self.lightgbm_available:
            lgb_rec = {
                'name': 'LightGBM',
                'library': 'lightgbm',
                'complexity': 'high', 
                'interpretability': 'low',
                'performance': 'very_high',
                'pros': ['Fast training', 'Memory efficient', 'High performance'],
                'cons': ['Requires tuning', 'Can overfit on small data']
            }
            recommendations['algorithms'].append(lgb_rec)
        
        return recommendations
    
    # ==================== æ¨¡å‹è®­ç»ƒ ====================
    
    def train_model(self, algorithm: str, target_column: str, **kwargs) -> Dict[str, Any]:
        """
        è®­ç»ƒæ¨¡å‹
        
        Args:
            algorithm: ç®—æ³•åç§°
            target_column: ç›®æ ‡åˆ—å
            **kwargs: æ¨¡å‹å‚æ•°
        
        Returns:
            è®­ç»ƒç»“æœ
        """
        try:
            self.execution_stats['total_operations'] += 1
            
            # å‡†å¤‡æ•°æ®
            data = self.prepare_data(target_column)
            
            # åˆ›å»ºæ¨¡å‹
            model = self._create_model(algorithm, data['target_type'], **kwargs)
            if model is None:
                raise ValueError(f"Algorithm '{algorithm}' not available")
            
            # è®­ç»ƒæ¨¡å‹
            start_time = datetime.now()
            model.fit(data['X_train'], data['y_train'])
            training_time = (datetime.now() - start_time).total_seconds()
            
            # è¯„ä¼°æ¨¡å‹
            evaluation = self._evaluate_model(model, data)
            
            result = {
                'success': True,
                'algorithm': algorithm,
                'model': model,
                'training_time': training_time,
                'data_info': {
                    'features': len(data['feature_names']),
                    'samples': len(data['X_train']),
                    'target_type': data['target_type']
                },
                'evaluation': evaluation,
                'timestamp': datetime.now().isoformat()
            }
            
            self.execution_stats['successful_operations'] += 1
            self.execution_stats['models_trained'] += 1
            
            logger.info(f"âœ… Model {algorithm} trained successfully in {training_time:.2f}s")
            return result
            
        except Exception as e:
            self.execution_stats['failed_operations'] += 1
            logger.error(f"âŒ Model training failed: {e}")
            return {
                'success': False,
                'algorithm': algorithm,
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }
    
    def _create_model(self, algorithm: str, target_type: str, **kwargs) -> Optional[Any]:
        """åˆ›å»ºæ¨¡å‹å®ä¾‹"""
        algo_lower = algorithm.lower()
        
        # sklearn æ¨¡å‹
        if 'randomforest' in algo_lower:
            if target_type == 'classification':
                return self.create_random_forest('classification', **kwargs)
            else:
                return self.create_random_forest('regression', **kwargs)
        
        elif 'logistic' in algo_lower:
            LogisticRegression = self.get_sklearn_component('LogisticRegression')
            return LogisticRegression(**kwargs) if LogisticRegression else None
        
        elif 'linear' in algo_lower:
            LinearRegression = self.get_sklearn_component('LinearRegression')
            return LinearRegression(**kwargs) if LinearRegression else None
        
        # XGBoost æ¨¡å‹
        elif 'xgb' in algo_lower or 'xgboost' in algo_lower:
            return self.create_xgboost_model(target_type, **kwargs)
        
        # LightGBM æ¨¡å‹
        elif 'lgb' in algo_lower or 'lightgbm' in algo_lower:
            if target_type == 'classification':
                LGBMClassifier = self.get_lightgbm_component('LGBMClassifier')
                return LGBMClassifier(**kwargs) if LGBMClassifier else None
            else:
                LGBMRegressor = self.get_lightgbm_component('LGBMRegressor')
                return LGBMRegressor(**kwargs) if LGBMRegressor else None
        
        return None
    
    def _evaluate_model(self, model, data: Dict[str, Any]) -> Dict[str, float]:
        """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
        try:
            # é¢„æµ‹
            y_pred = model.predict(data['X_test'])
            
            metrics = {}
            
            if data['target_type'] == 'classification':
                # åˆ†ç±»æŒ‡æ ‡
                accuracy_score = self.get_accuracy_score()
                if accuracy_score:
                    metrics['accuracy'] = accuracy_score(data['y_test'], y_pred)
                
                # å…¶ä»–åˆ†ç±»æŒ‡æ ‡
                precision_score = self.get_sklearn_component('precision_score')
                if precision_score:
                    try:
                        metrics['precision'] = precision_score(data['y_test'], y_pred, average='weighted')
                    except:
                        pass
                
                recall_score = self.get_sklearn_component('recall_score')
                if recall_score:
                    try:
                        metrics['recall'] = recall_score(data['y_test'], y_pred, average='weighted')
                    except:
                        pass
            
            else:
                # å›å½’æŒ‡æ ‡
                mean_squared_error = self.get_sklearn_component('mean_squared_error')
                if mean_squared_error:
                    metrics['mse'] = mean_squared_error(data['y_test'], y_pred)
                
                mean_absolute_error = self.get_sklearn_component('mean_absolute_error')
                if mean_absolute_error:
                    metrics['mae'] = mean_absolute_error(data['y_test'], y_pred)
                
                r2_score = self.get_sklearn_component('r2_score')
                if r2_score:
                    metrics['r2'] = r2_score(data['y_test'], y_pred)
            
            return metrics
            
        except Exception as e:
            logger.error(f"Model evaluation failed: {e}")
            return {}
    
    # ==================== ä¸»å¤„ç†æ–¹æ³• ====================
    
    def process(self, operation: str, **kwargs) -> Dict[str, Any]:
        """
        ä¸»å¤„ç†å…¥å£
        
        Args:
            operation: æ“ä½œç±»å‹ ('recommend', 'train', 'predict', 'evaluate')
            **kwargs: æ“ä½œå‚æ•°
        """
        if operation == 'recommend':
            return self.recommend_algorithms(**kwargs)
        elif operation == 'train':
            return self.train_model(**kwargs)
        elif operation == 'status':
            return self.get_status()
        else:
            return {'error': f"Unknown operation: {operation}"}
    
    def get_status(self) -> Dict[str, Any]:
        """è·å–å¤„ç†å™¨çŠ¶æ€"""
        return {
            'class_name': self.__class__.__name__,
            'available_libraries': self._get_available_libraries(),
            'library_status': self.get_library_status(),
            'capabilities': {
                'training': self.can_perform_task('training'),
                'prediction': self.can_perform_task('prediction'),
                'evaluation': self.can_perform_task('evaluation')
            },
            'execution_stats': self.execution_stats,
            'data_loaded': self.df is not None and not self.df.empty
        }