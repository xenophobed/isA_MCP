#!/usr/bin/env python3
"""
Retrieval Supervisor - æ£€ç´¢ç­–ç•¥æ™ºèƒ½è·¯ç”±å™¨
è‡ªåŠ¨é€‰æ‹©æœ€ä½³æ£€ç´¢ç­–ç•¥ï¼ˆvector/keyword/hybridï¼‰

åŸºäºDeep-Thinking RAGè®ºæ–‡ï¼š
- æ¦‚å¿µæ€§æŸ¥è¯¢ â†’ Vector Search (è¯­ä¹‰æœç´¢)
- ç²¾ç¡®æœ¯è¯­æŸ¥è¯¢ â†’ Keyword Search (BM25/å…³é”®è¯)
- æ··åˆæŸ¥è¯¢ â†’ Hybrid Search (RRFèåˆ)
"""

import logging
import re
from typing import Dict, Any, Optional, Literal
from dataclasses import dataclass
from enum import Enum


logger = logging.getLogger(__name__)


class SearchStrategy(Enum):
    """æ£€ç´¢ç­–ç•¥æšä¸¾"""
    VECTOR = "vector"      # å‘é‡/è¯­ä¹‰æœç´¢
    KEYWORD = "keyword"    # å…³é”®è¯/BM25æœç´¢
    HYBRID = "hybrid"      # æ··åˆæœç´¢ï¼ˆRRFèåˆï¼‰


@dataclass
class SupervisorDecision:
    """ç›‘ç£å™¨å†³ç­–ç»“æœ"""
    strategy: SearchStrategy
    confidence: float  # 0-1, å†³ç­–ç½®ä¿¡åº¦
    justification: str  # å†³ç­–ç†ç”±
    metadata: Dict[str, Any]  # é¢å¤–ä¿¡æ¯ï¼ˆå¦‚æ£€æµ‹åˆ°çš„ç‰¹å¾ï¼‰


class RetrievalSupervisor:
    """
    æ£€ç´¢ç›‘ç£å™¨ - æ™ºèƒ½é€‰æ‹©æœ€ä½³æ£€ç´¢ç­–ç•¥

    æ ¸å¿ƒé€»è¾‘ï¼š
    1. åˆ†ææŸ¥è¯¢ç‰¹å¾ï¼ˆå…³é”®è¯ã€å®ä½“ã€æ¦‚å¿µæ€§ç­‰ï¼‰
    2. åŸºäºè§„åˆ™æˆ–LLMåˆ¤æ–­æœ€ä¼˜ç­–ç•¥
    3. è¿”å›ç­–ç•¥å†³ç­–å’Œç†ç”±
    """

    def __init__(
        self,
        use_llm: bool = False,
        llm_generator: Optional[Any] = None,
        fallback_strategy: SearchStrategy = SearchStrategy.HYBRID
    ):
        """
        Args:
            use_llm: æ˜¯å¦ä½¿ç”¨LLMè¿›è¡Œå†³ç­–ï¼ˆæ›´å‡†ç¡®ä½†æ›´æ…¢ï¼‰
            llm_generator: LLMç”Ÿæˆå™¨ï¼ˆå¦‚æœuse_llm=Trueï¼‰
            fallback_strategy: æ— æ³•å†³ç­–æ—¶çš„é»˜è®¤ç­–ç•¥
        """
        self.use_llm = use_llm
        self.llm_generator = llm_generator
        self.fallback_strategy = fallback_strategy
        self.logger = logging.getLogger(self.__class__.__name__)

    async def decide_strategy(
        self,
        query: str,
        user_context: Optional[Dict[str, Any]] = None
    ) -> SupervisorDecision:
        """
        å†³å®šæœ€ä½³æ£€ç´¢ç­–ç•¥

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            user_context: ç”¨æˆ·ä¸Šä¸‹æ–‡ï¼ˆå¦‚å†å²æŸ¥è¯¢ã€åå¥½ç­‰ï¼‰

        Returns:
            SupervisorDecisionå¯¹è±¡
        """
        if self.use_llm and self.llm_generator:
            return await self._llm_based_decision(query, user_context)
        else:
            return await self._rule_based_decision(query, user_context)

    async def _rule_based_decision(
        self,
        query: str,
        user_context: Optional[Dict[str, Any]] = None
    ) -> SupervisorDecision:
        """
        åŸºäºè§„åˆ™çš„ç­–ç•¥å†³ç­–ï¼ˆå¿«é€Ÿã€æ— LLMè°ƒç”¨ï¼‰

        è§„åˆ™é€»è¾‘ï¼š
        1. æ£€æµ‹ç²¾ç¡®åŒ¹é…ç‰¹å¾ â†’ Keyword Search
        2. æ£€æµ‹æ¦‚å¿µæ€§ç‰¹å¾ â†’ Vector Search
        3. æ— æ˜æ˜¾ç‰¹å¾ â†’ Hybrid Search
        """
        query_lower = query.lower()
        features = self._extract_query_features(query_lower)

        # ç‰¹å¾æƒé‡è®¡åˆ†ï¼ˆä½¿ç”¨æ›´ç»†ç²’åº¦çš„è¯„åˆ†ï¼‰
        keyword_score = (
            features['has_quotes'] * 0.5 +         # å¼•å·æ˜¯å¼ºä¿¡å·
            features['has_exact_terms'] * 0.4 +    # ç²¾ç¡®æœ¯è¯­æ˜¯å¼ºä¿¡å·
            features['has_codes'] * 0.3 +          # ä»£ç /IDæ˜¯å¼ºä¿¡å·
            features['is_short'] * 0.15            # çŸ­æŸ¥è¯¢å€¾å‘keyword
        )

        vector_score = (
            features['is_conceptual'] * 0.5 +      # æ¦‚å¿µæ€§æ˜¯å¼ºä¿¡å·
            features['has_sentiment_words'] * 0.3 + # æƒ…æ„Ÿè¯æ˜¯å¼ºä¿¡å·
            features['is_long'] * 0.2 +            # é•¿æŸ¥è¯¢å€¾å‘vector
            features['has_abstract_words'] * 0.4   # æŠ½è±¡æ¦‚å¿µæ˜¯å¼ºä¿¡å·
        )

        # å†³ç­–é€»è¾‘ï¼ˆé™ä½é˜ˆå€¼ï¼Œä½¿å†³ç­–æ›´æ•æ„Ÿï¼‰
        if keyword_score > 0.3:  # é™ä½é˜ˆå€¼ä»0.6åˆ°0.3
            strategy = SearchStrategy.KEYWORD
            confidence = min(keyword_score + 0.5, 0.95)  # æå‡ç½®ä¿¡åº¦
            justification = self._build_justification(features, "keyword")

        elif vector_score > 0.3:  # é™ä½é˜ˆå€¼ä»0.6åˆ°0.3
            strategy = SearchStrategy.VECTOR
            confidence = min(vector_score + 0.5, 0.95)  # æå‡ç½®ä¿¡åº¦
            justification = self._build_justification(features, "vector")

        else:
            strategy = SearchStrategy.HYBRID
            confidence = 0.7  # Hybrid is safe default
            justification = "Query has mixed characteristics, using hybrid search for balanced recall and precision"

        self.logger.info(
            f"ğŸš¦ Supervisor Decision: {strategy.value.upper()} "
            f"(confidence={confidence:.2f}) - {justification[:60]}..."
        )

        return SupervisorDecision(
            strategy=strategy,
            confidence=confidence,
            justification=justification,
            metadata={
                'features': features,
                'keyword_score': keyword_score,
                'vector_score': vector_score,
                'decision_method': 'rule_based'
            }
        )

    def _extract_query_features(self, query: str) -> Dict[str, bool]:
        """æå–æŸ¥è¯¢ç‰¹å¾"""
        return {
            # Keyword Search indicators
            'has_quotes': '"' in query or "'" in query,
            'has_exact_terms': any(term in query for term in ['exact:', 'term:', 'code:', 'id:']),
            'has_codes': bool(re.search(r'\b[A-Z0-9]{3,}\b', query)),  # e.g., "SKU123", "ITEM_1A"
            'is_short': len(query.split()) <= 5,

            # Vector Search indicators
            'is_conceptual': any(word in query for word in [
                'explain', 'describe', 'understand', 'concept', 'idea',
                'sentiment', 'feeling', 'opinion', 'analysis', 'overview'
            ]),
            'has_sentiment_words': any(word in query for word in [
                'good', 'bad', 'positive', 'negative', 'better', 'worse',
                'best', 'worst', 'recommend', 'suggest'
            ]),
            'has_abstract_words': any(word in query for word in [
                'strategy', 'approach', 'methodology', 'philosophy',
                'perspective', 'implication', 'significance'
            ]),
            'is_long': len(query.split()) > 15,

            # Hybrid indicators
            'has_and_or': ' and ' in query or ' or ' in query,
            'has_multiple_clauses': len(query.split(',')) > 1 or len(query.split(';')) > 1
        }

    def _build_justification(
        self,
        features: Dict[str, bool],
        decision_type: str
    ) -> str:
        """æ„å»ºå†³ç­–ç†ç”±"""
        if decision_type == "keyword":
            reasons = []
            if features['has_quotes']:
                reasons.append("contains quoted exact phrases")
            if features['has_exact_terms']:
                reasons.append("uses exact term identifiers")
            if features['has_codes']:
                reasons.append("contains specific codes/IDs")
            if features['is_short']:
                reasons.append("is a short, precise query")

            return f"Keyword search recommended: query {', '.join(reasons)}"

        elif decision_type == "vector":
            reasons = []
            if features['is_conceptual']:
                reasons.append("is conceptual in nature")
            if features['has_sentiment_words']:
                reasons.append("involves sentiment/opinion")
            if features['has_abstract_words']:
                reasons.append("contains abstract concepts")
            if features['is_long']:
                reasons.append("is a complex, multi-part query")

            return f"Vector search recommended: query {', '.join(reasons)}"

        return "Hybrid search recommended: balanced approach for this query"

    async def _llm_based_decision(
        self,
        query: str,
        user_context: Optional[Dict[str, Any]] = None
    ) -> SupervisorDecision:
        """
        åŸºäºLLMçš„ç­–ç•¥å†³ç­–ï¼ˆæ›´å‡†ç¡®ä½†æ›´æ…¢ï¼‰

        ä½¿ç”¨LLMåˆ†ææŸ¥è¯¢å¹¶é€‰æ‹©æœ€ä½³ç­–ç•¥
        """
        try:
            prompt = f"""You are a retrieval strategy expert. Analyze the query and decide the best search strategy.

Query: "{query}"

Available strategies:
1. **vector**: Best for conceptual, semantic, or similarity-based queries
2. **keyword**: Best for queries with specific terms, codes, exact phrases, or IDs
3. **hybrid**: Combines both, good for balanced recall and precision

Choose ONE strategy and provide a brief justification (max 100 chars).

Output format (JSON):
{{
    "strategy": "vector|keyword|hybrid",
    "confidence": 0.0-1.0,
    "justification": "brief reason"
}}"""

            # è°ƒç”¨LLM
            if hasattr(self.llm_generator, 'generate_json'):
                response = await self.llm_generator.generate_json(prompt)
            elif callable(self.llm_generator):
                response_text = await self.llm_generator(prompt)
                # ç®€å•JSONè§£æ
                import json
                response = json.loads(response_text)
            else:
                raise ValueError("Invalid llm_generator")

            strategy = SearchStrategy(response['strategy'])
            confidence = float(response.get('confidence', 0.8))
            justification = response.get('justification', 'LLM-based decision')

            self.logger.info(
                f"ğŸ¤– LLM Supervisor Decision: {strategy.value.upper()} "
                f"(confidence={confidence:.2f})"
            )

            return SupervisorDecision(
                strategy=strategy,
                confidence=confidence,
                justification=justification,
                metadata={'decision_method': 'llm_based'}
            )

        except Exception as e:
            self.logger.error(f"LLM decision failed: {e}, falling back to rule-based")
            return await self._rule_based_decision(query, user_context)


# ===== ä¾¿æ·å·¥å‚å‡½æ•° =====

def create_default_supervisor() -> RetrievalSupervisor:
    """åˆ›å»ºé»˜è®¤ç›‘ç£å™¨ï¼ˆåŸºäºè§„åˆ™ï¼‰"""
    return RetrievalSupervisor(
        use_llm=False,
        fallback_strategy=SearchStrategy.HYBRID
    )


def create_llm_supervisor(llm_generator: Any) -> RetrievalSupervisor:
    """åˆ›å»ºLLMé©±åŠ¨çš„ç›‘ç£å™¨ï¼ˆæ›´å‡†ç¡®ï¼‰"""
    return RetrievalSupervisor(
        use_llm=True,
        llm_generator=llm_generator,
        fallback_strategy=SearchStrategy.HYBRID
    )


def create_fast_supervisor() -> RetrievalSupervisor:
    """åˆ›å»ºå¿«é€Ÿç›‘ç£å™¨ï¼ˆæ€»æ˜¯ä½¿ç”¨hybridï¼‰"""
    supervisor = RetrievalSupervisor(use_llm=False)
    # Override decide_strategy to always return hybrid
    async def fast_decide(query, ctx=None):
        return SupervisorDecision(
            strategy=SearchStrategy.HYBRID,
            confidence=0.9,
            justification="Fast mode: always use hybrid for reliability",
            metadata={'decision_method': 'fast_mode'}
        )
    supervisor.decide_strategy = fast_decide
    return supervisor
