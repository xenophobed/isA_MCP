#!/usr/bin/env python3
"""
Multi-Stage Retrieval Funnel
å¤šé˜¶æ®µæ£€ç´¢æ¼æ–— - ä»å¹¿æ³›å¬å›åˆ°ç²¾ç¡®æ’åºå†åˆ°ä¸Šä¸‹æ–‡è’¸é¦

åŸºäºDeep-Thinking RAGè®ºæ–‡çš„æ ¸å¿ƒæ€æƒ³ï¼š
Stage 1: Broad Recall (å¹¿æ³›å¬å›) - ä½¿ç”¨hybrid/semantic/keyword search
Stage 2: High Precision (ç²¾ç¡®é‡æ’) - ä½¿ç”¨Cross-Encoder reranking
Stage 3: Contextual Distillation (ä¸Šä¸‹æ–‡è’¸é¦) - ä½¿ç”¨LLMå‹ç¼©å’Œæ€»ç»“
"""

import logging
from typing import List, Dict, Any, Optional, Literal
from dataclasses import dataclass
from sentence_transformers import CrossEncoder

logger = logging.getLogger(__name__)


@dataclass
class RetrievalConfig:
    """æ£€ç´¢é…ç½®"""
    # Stage 1: Broad Recall
    initial_top_k: int = 10  # åˆå§‹æ£€ç´¢æ•°é‡ï¼ˆå¹¿æ³›å¬å›ï¼‰
    search_strategy: Literal["auto", "vector", "keyword", "hybrid"] = "auto"

    # Stage 2: High Precision
    enable_rerank: bool = True
    rerank_top_n: int = 3  # é‡æ’åä¿ç•™çš„æ•°é‡
    rerank_model: str = "cross-encoder/ms-marco-MiniLM-L-6-v2"

    # Stage 3: Contextual Distillation
    enable_distillation: bool = True
    max_distilled_length: int = 500  # è’¸é¦åçš„æœ€å¤§é•¿åº¦


class MultiStageRetrievalFunnel:
    """
    å¤šé˜¶æ®µæ£€ç´¢æ¼æ–—

    æ ¸å¿ƒæµç¨‹ï¼š
    1. Broad Recall: ä½¿ç”¨å¤šç§æ£€ç´¢ç­–ç•¥è·å–å€™é€‰æ–‡æ¡£ï¼ˆtop_k=10ï¼‰
    2. High Precision: ä½¿ç”¨Cross-Encoderå¯¹å€™é€‰æ–‡æ¡£ç²¾ç¡®é‡æ’ï¼ˆä¿ç•™top_n=3ï¼‰
    3. Contextual Distillation: ä½¿ç”¨LLMå°†top_næ–‡æ¡£å‹ç¼©æˆå•ä¸€è¿è´¯æ®µè½
    """

    def __init__(self, config: RetrievalConfig):
        self.config = config
        self._reranker = None
        self.logger = logging.getLogger(self.__class__.__name__)

    @property
    def reranker(self) -> CrossEncoder:
        """æ‡’åŠ è½½Cross-Encoderæ¨¡å‹"""
        if self._reranker is None and self.config.enable_rerank:
            try:
                self._reranker = CrossEncoder(self.config.rerank_model)
                self.logger.info(f"âœ… Cross-Encoder loaded: {self.config.rerank_model}")
            except Exception as e:
                self.logger.error(f"âŒ Failed to load Cross-Encoder: {e}")
                self._reranker = None
        return self._reranker

    async def execute_funnel(
        self,
        query: str,
        initial_results: List[Dict[str, Any]],
        llm_generator: Optional[Any] = None
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œå®Œæ•´çš„ä¸‰é˜¶æ®µæ£€ç´¢æ¼æ–—

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            initial_results: åˆå§‹æ£€ç´¢ç»“æœï¼ˆæ¥è‡ªStage 1ï¼‰
            llm_generator: LLMç”Ÿæˆå™¨ï¼ˆç”¨äºStage 3è’¸é¦ï¼‰

        Returns:
            åŒ…å«ä¸‰é˜¶æ®µç»“æœçš„å­—å…¸
        """
        try:
            # Stage 1: Broad Recall (å·²ç”±å¤–éƒ¨å®Œæˆï¼Œè¿™é‡Œæ¥æ”¶)
            stage1_results = initial_results[:self.config.initial_top_k]
            self.logger.info(f"ğŸ“Š Stage 1 (Broad Recall): {len(stage1_results)} candidates")

            # Stage 2: High Precision Reranking
            stage2_results = await self._stage2_rerank(query, stage1_results)
            self.logger.info(f"ğŸ¯ Stage 2 (Reranking): {len(stage2_results)} high-precision docs")

            # Stage 3: Contextual Distillation
            distilled_context = None
            if self.config.enable_distillation and llm_generator:
                distilled_context = await self._stage3_distill(
                    query, stage2_results, llm_generator
                )
                self.logger.info(f"âœ‚ï¸ Stage 3 (Distillation): {len(distilled_context)} chars")

            return {
                'stage1_broad_recall': stage1_results,
                'stage2_reranked': stage2_results,
                'stage3_distilled': distilled_context,
                'final_sources': stage2_results,  # ç”¨äºcitation
                'funnel_metadata': {
                    'initial_count': len(stage1_results),
                    'reranked_count': len(stage2_results),
                    'distilled': distilled_context is not None
                }
            }

        except Exception as e:
            self.logger.error(f"Retrieval funnel failed: {e}")
            return {
                'stage1_broad_recall': initial_results,
                'stage2_reranked': initial_results[:self.config.rerank_top_n],
                'stage3_distilled': None,
                'final_sources': initial_results[:self.config.rerank_top_n],
                'funnel_metadata': {'error': str(e)}
            }

    async def _stage2_rerank(
        self,
        query: str,
        documents: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """
        Stage 2: é«˜ç²¾åº¦é‡æ’åº

        ä½¿ç”¨Cross-Encoderå¯¹æ–‡æ¡£è¿›è¡Œæ·±åº¦ç›¸å…³æ€§è¯„åˆ†ï¼Œç„¶åé‡æ–°æ’åº
        """
        if not self.config.enable_rerank or not documents:
            return documents[:self.config.rerank_top_n]

        if not self.reranker:
            self.logger.warning("Cross-Encoder not available, skipping rerank")
            return documents[:self.config.rerank_top_n]

        try:
            # å‡†å¤‡query-document pairs
            pairs = [(query, doc.get('text', '')) for doc in documents]

            # ä½¿ç”¨Cross-Encoderè®¡ç®—ç›¸å…³æ€§åˆ†æ•°
            scores = self.reranker.predict(pairs)

            # å°†æ–‡æ¡£ä¸åˆ†æ•°é…å¯¹
            doc_scores = list(zip(documents, scores))

            # æŒ‰åˆ†æ•°é™åºæ’åº
            doc_scores.sort(key=lambda x: x[1], reverse=True)

            # ä¿ç•™top_næ–‡æ¡£
            reranked_docs = [
                {**doc, 'rerank_score': float(score)}
                for doc, score in doc_scores[:self.config.rerank_top_n]
            ]

            self.logger.debug(f"Reranked scores: {[f'{s:.3f}' for _, s in doc_scores[:3]]}")
            return reranked_docs

        except Exception as e:
            self.logger.error(f"Reranking failed: {e}")
            return documents[:self.config.rerank_top_n]

    async def _stage3_distill(
        self,
        query: str,
        documents: List[Dict[str, Any]],
        llm_generator: Any
    ) -> Optional[str]:
        """
        Stage 3: ä¸Šä¸‹æ–‡è’¸é¦

        ä½¿ç”¨LLMå°†å¤šä¸ªé«˜è´¨é‡æ–‡æ¡£å‹ç¼©æˆå•ä¸€ã€è¿è´¯çš„æ®µè½
        è¿™æ˜¯è®ºæ–‡ä¸­çš„"Contextual Distillation"æ­¥éª¤
        """
        if not documents:
            return None

        try:
            # æ„å»ºä¸Šä¸‹æ–‡
            context_parts = []
            for i, doc in enumerate(documents):
                text = doc.get('text', '')
                context_parts.append(f"[Document {i+1}]\n{text}")

            full_context = "\n\n".join(context_parts)

            # æ„å»ºè’¸é¦prompt
            distillation_prompt = f"""You are a contextual distillation assistant.
Your task is to synthesize the following {len(documents)} document snippets into a single, concise, and coherent paragraph that directly answers the question: "{query}".

Requirements:
1. Remove redundant information
2. Organize content logically
3. Keep only the most relevant facts
4. Maximum {self.config.max_distilled_length} characters
5. DO NOT add any information not present in the documents

Documents:
{full_context}

Distilled Context (one paragraph):"""

            # è°ƒç”¨LLMè¿›è¡Œè’¸é¦
            if hasattr(llm_generator, 'generate'):
                distilled = await llm_generator.generate(distillation_prompt)
            elif callable(llm_generator):
                distilled = await llm_generator(distillation_prompt)
            else:
                self.logger.warning("Invalid llm_generator, skipping distillation")
                return full_context[:self.config.max_distilled_length]

            # æˆªæ–­åˆ°æœ€å¤§é•¿åº¦
            if len(distilled) > self.config.max_distilled_length:
                distilled = distilled[:self.config.max_distilled_length] + "..."

            return distilled

        except Exception as e:
            self.logger.error(f"Distillation failed: {e}")
            # é™çº§ï¼šè¿”å›æ‹¼æ¥çš„åŸæ–‡æœ¬
            return "\n\n".join([doc.get('text', '')[:200] for doc in documents])


# ===== ä¾¿æ·å·¥å‚å‡½æ•° =====

def create_default_funnel() -> MultiStageRetrievalFunnel:
    """åˆ›å»ºé»˜è®¤é…ç½®çš„æ£€ç´¢æ¼æ–—"""
    config = RetrievalConfig(
        initial_top_k=10,
        search_strategy="auto",
        enable_rerank=True,
        rerank_top_n=3,
        enable_distillation=True,
        max_distilled_length=500
    )
    return MultiStageRetrievalFunnel(config)


def create_fast_funnel() -> MultiStageRetrievalFunnel:
    """åˆ›å»ºå¿«é€Ÿé…ç½®ï¼ˆç¦ç”¨è’¸é¦ï¼‰"""
    config = RetrievalConfig(
        initial_top_k=5,
        enable_rerank=True,
        rerank_top_n=3,
        enable_distillation=False  # å¿«é€Ÿæ¨¡å¼ä¸ä½¿ç”¨è’¸é¦
    )
    return MultiStageRetrievalFunnel(config)


def create_precision_funnel() -> MultiStageRetrievalFunnel:
    """åˆ›å»ºé«˜ç²¾åº¦é…ç½®ï¼ˆå¢åŠ åˆå§‹å¬å›å’Œè’¸é¦ï¼‰"""
    config = RetrievalConfig(
        initial_top_k=20,  # æ›´å¤šåˆå§‹å€™é€‰
        enable_rerank=True,
        rerank_top_n=5,    # ä¿ç•™æ›´å¤šé«˜è´¨é‡æ–‡æ¡£
        enable_distillation=True,
        max_distilled_length=800  # æ›´é•¿çš„è’¸é¦ç»“æœ
    )
    return MultiStageRetrievalFunnel(config)
