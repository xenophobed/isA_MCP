#!/usr/bin/env python3
"""
HyDE RAG Service - Hypothetical Document Embeddings

æ ¸å¿ƒæ€æƒ³ï¼š
1. ç”¨æˆ·æŸ¥è¯¢ â†’ ç”Ÿæˆå‡è®¾æ€§ç­”æ¡ˆï¼ˆhypothetical documentï¼‰
2. ç”¨å‡è®¾ç­”æ¡ˆçš„embeddingæ£€ç´¢ï¼Œè€Œä¸æ˜¯ç”¨åŸå§‹æŸ¥è¯¢
3. å‡è®¾ç­”æ¡ˆå’ŒçœŸå®æ–‡æ¡£æ›´è¯­ä¹‰ç›¸ä¼¼ï¼Œæ£€ç´¢æ›´å‡†ç¡®

é€‚ç”¨åœºæ™¯ï¼š
- ç”¨æˆ·æŸ¥è¯¢å’Œæ–‡æ¡£ç”¨è¯ä¸åŒ¹é…
- æŠ½è±¡/poorly-worded æŸ¥è¯¢
- è·¨é¢†åŸŸçŸ¥è¯†æ£€ç´¢

ä¼˜åŠ¿ï¼š
- æå‡è¯­ä¹‰åŒ¹é…åº¦ 15-25%
- å¤„ç†æ­§ä¹‰æŸ¥è¯¢
- æ— éœ€é¢å¤–è®­ç»ƒ

è®ºæ–‡ï¼šPrecise Zero-Shot Dense Retrieval without Relevance Labels (2022)
"""

import os
import time
from typing import Dict, Any, List, Optional

from ..base.base_rag_service import BaseRAGService
from ..base.rag_models import (
    RAGMode,
    RAGConfig,
    RAGStoreRequest,
    RAGRetrieveRequest,
    RAGGenerateRequest,
    RAGResult,
    RAGSource
)

# Qdrant client
try:
    from isa_common.qdrant_client import QdrantClient
    QDRANT_AVAILABLE = True
except ImportError:
    QDRANT_AVAILABLE = False
    QdrantClient = None


class HyDERAGService(BaseRAGService):
    """
    HyDE RAG æœåŠ¡ - å‡è®¾æ–‡æ¡£åµŒå…¥

    æ ¸å¿ƒæµç¨‹:
    1. æ¥æ”¶ç”¨æˆ·æŸ¥è¯¢
    2. ç”¨ LLM ç”Ÿæˆå‡è®¾æ€§ç­”æ¡ˆï¼ˆæ¨¡æ‹Ÿ"å®Œç¾ç­”æ¡ˆ"ï¼‰
    3. ç”¨å‡è®¾ç­”æ¡ˆçš„ embedding æ£€ç´¢çœŸå®æ–‡æ¡£
    4. åŸºäºæ£€ç´¢ç»“æœç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
    """

    def __init__(self, config: RAGConfig):
        super().__init__(config)

        # Initialize Qdrant
        self.qdrant_client: Optional[QdrantClient] = None
        self.qdrant_collection = os.getenv('QDRANT_COLLECTION', 'user_knowledge')
        self._init_qdrant()

        # HyDE config
        self.hyde_model = config.extra_config.get('hyde_model', 'gpt-4.1-nano') if config.extra_config else 'gpt-4.1-nano'
        self.num_hypotheses = config.extra_config.get('num_hypotheses', 1) if config.extra_config else 1  # å¯ç”Ÿæˆå¤šä¸ªå‡è®¾æ–‡æ¡£

        self.logger.info(f"âœ… HyDE RAG Service initialized (model={self.hyde_model}, hypotheses={self.num_hypotheses})")

    def _init_qdrant(self):
        """åˆå§‹åŒ– Qdrant å®¢æˆ·ç«¯"""
        if not QDRANT_AVAILABLE:
            self.logger.warning("Qdrant not available")
            return

        try:
            host = os.getenv('QDRANT_HOST', 'isa-qdrant-grpc')
            port = int(os.getenv('QDRANT_PORT', '50062'))
            vector_dim = int(os.getenv('VECTOR_DIMENSION', '1536'))

            self.qdrant_client = QdrantClient(host=host, port=port)
            self.logger.info(f"âœ… Qdrant initialized: {host}:{port}")

            # Ensure collection exists
            try:
                collection_info = self.qdrant_client.get_collection_info(self.qdrant_collection)
                if collection_info:
                    self.logger.info(f"âœ… Collection '{self.qdrant_collection}' exists")
            except Exception as e:
                self.logger.error(f"Collection check failed: {e}")

        except Exception as e:
            self.logger.error(f"Qdrant initialization failed: {e}")
            self.qdrant_client = None

    async def store(self, request: RAGStoreRequest) -> RAGResult:
        """
        å­˜å‚¨å†…å®¹ï¼ˆä¸ Simple RAG ç›¸åŒï¼‰

        HyDE åªæ”¹è¿›æ£€ç´¢ï¼Œå­˜å‚¨é€»è¾‘ä¸å˜
        """
        start_time = time.time()
        try:
            if not self.qdrant_client:
                return RAGResult(
                    success=False,
                    content="",
                    sources=[],
                    metadata={},
                    mode_used=RAGMode.HYDE,
                    processing_time=time.time() - start_time,
                    error="Qdrant client not available"
                )

            # Process document into chunks
            chunks = self._chunk_text(request.content)
            stored_count = 0

            for chunk_data in chunks:
                chunk_text = chunk_data['text']
                chunk_id = chunk_data['id']

                # Generate embedding
                embedding = await self._generate_embedding(chunk_text)
                if not embedding:
                    self.logger.warning(f"Failed to generate embedding for chunk {chunk_id}")
                    continue

                # Prepare payload
                payload = {
                    'user_id': request.user_id,
                    'text': chunk_text,
                    'chunk_id': chunk_data['chunk_index'],
                    'start_pos': chunk_data['start'],
                    'end_pos': chunk_data['end'],
                    'stored_at': chunk_data['timestamp'],
                    'rag_mode': 'hyde'
                }

                # Add metadata
                if request.metadata:
                    payload.update(request.metadata)

                # Upsert to Qdrant
                try:
                    self.qdrant_client.upsert_points(
                        self.qdrant_collection,
                        [{
                            'id': chunk_id,
                            'vector': embedding,
                            'payload': payload
                        }]
                    )
                    stored_count += 1
                except Exception as e:
                    self.logger.error(f"Failed to upsert chunk {chunk_id}: {e}")

            return RAGResult(
                success=True,
                content=f"Stored {stored_count}/{len(chunks)} chunks",
                sources=[],
                metadata={'chunks_stored': stored_count, 'total_chunks': len(chunks)},
                mode_used=RAGMode.HYDE,
                processing_time=time.time() - start_time
            )

        except Exception as e:
            self.logger.error(f"Store failed: {e}")
            return RAGResult(
                success=False,
                content="",
                sources=[],
                metadata={},
                mode_used=RAGMode.HYDE,
                processing_time=time.time() - start_time,
                error=str(e)
            )

    async def retrieve(self, request: RAGRetrieveRequest) -> RAGResult:
        """
        æ£€ç´¢ - HyDE æ ¸å¿ƒé€»è¾‘

        æµç¨‹:
        1. ç”Ÿæˆå‡è®¾æ–‡æ¡£ï¼ˆhypothetical documentï¼‰
        2. ç”¨å‡è®¾æ–‡æ¡£çš„ embedding æ£€ç´¢
        3. è¿”å›æ£€ç´¢ç»“æœ
        """
        start_time = time.time()
        try:
            if not self.qdrant_client:
                return RAGResult(
                    success=False,
                    content="",
                    sources=[],
                    metadata={},
                    mode_used=RAGMode.HYDE,
                    processing_time=time.time() - start_time,
                    error="Qdrant client not available"
                )

            # Step 1: Generate hypothetical document
            self.logger.info(f"ğŸ”® Generating hypothetical document for query: '{request.query}'")
            hypothetical_doc = await self._generate_hypothetical_document(request.query)

            if not hypothetical_doc:
                self.logger.warning("Failed to generate hypothetical document, falling back to query embedding")
                # Fallback to direct query embedding
                query_embedding = await self._generate_embedding(request.query)
            else:
                self.logger.info(f"âœ… Generated hypothetical doc ({len(hypothetical_doc)} chars)")
                # Use hypothetical document embedding
                query_embedding = await self._generate_embedding(hypothetical_doc)

            if not query_embedding:
                return RAGResult(
                    success=False,
                    content="",
                    sources=[],
                    metadata={},
                    mode_used=RAGMode.HYDE,
                    processing_time=time.time() - start_time,
                    error="Failed to generate embedding"
                )

            # Step 2: Search with hypothetical document embedding
            filter_conditions = {'user_id': request.user_id}
            search_results = self.qdrant_client.search_with_filter(
                collection_name=self.qdrant_collection,
                vector=query_embedding,
                filter_conditions=filter_conditions,
                limit=request.top_k
            )

            # Convert to RAGSource
            sources = []
            for result in search_results:
                payload = result.get('payload', {})
                score = result.get('score', 0.0)

                source = RAGSource(
                    text=payload.get('text', ''),
                    score=score,
                    metadata=payload
                )
                sources.append(source)

            self.logger.info(f"âœ… HyDE retrieval: {len(sources)} results")

            return RAGResult(
                success=True,
                content="",
                sources=sources,
                metadata={
                    'hypothetical_document': hypothetical_doc if hypothetical_doc else None,
                    'hypothetical_doc_length': len(hypothetical_doc) if hypothetical_doc else 0,
                    'retrieval_method': 'hyde_embedding',
                    'fallback_to_query': not hypothetical_doc
                },
                mode_used=RAGMode.HYDE,
                processing_time=time.time() - start_time
            )

        except Exception as e:
            self.logger.error(f"Retrieve failed: {e}")
            return RAGResult(
                success=False,
                content="",
                sources=[],
                metadata={},
                mode_used=RAGMode.HYDE,
                processing_time=time.time() - start_time,
                error=str(e)
            )

    async def generate(self, request: RAGGenerateRequest) -> RAGResult:
        """
        ç”Ÿæˆç­”æ¡ˆï¼ˆåŸºäºHyDEæ£€ç´¢çš„ç»“æœï¼‰
        """
        start_time = time.time()
        try:
            # Get sources (from request or retrieve with HyDE)
            if request.retrieval_sources:
                sources = [
                    RAGSource(**s) if isinstance(s, dict) else s
                    for s in request.retrieval_sources
                ]
                retrieval_metadata = {}
            else:
                # Retrieve with HyDE
                retrieval = await self.retrieve(
                    RAGRetrieveRequest(
                        query=request.query,
                        user_id=request.user_id,
                        top_k=self.config.top_k,
                        options=request.options
                    )
                )
                if not retrieval.success:
                    return retrieval
                sources = retrieval.sources
                retrieval_metadata = retrieval.metadata

            # Build context
            use_citations = request.options.get('use_citations', True) if request.options else True
            context_text = self._build_context(sources, use_citations=use_citations)

            # Generate response
            prompt = f"""Based on the following sources (retrieved via HyDE - hypothetical document embeddings), provide a comprehensive answer.

SOURCES:
{context_text}

QUESTION: {request.query}

Please provide a detailed answer with proper citations."""

            response_text = await self._generate_response(prompt, model="gpt-4.1-nano")

            if not response_text:
                return RAGResult(
                    success=False,
                    content="",
                    sources=sources,
                    metadata={'error': 'Failed to generate response'},
                    mode_used=RAGMode.HYDE,
                    processing_time=time.time() - start_time,
                    error='Failed to generate response'
                )

            return RAGResult(
                success=True,
                content=response_text,
                sources=sources,
                metadata={
                    'context_length': len(context_text),
                    'sources_count': len(sources),
                    'use_citations': use_citations,
                    'hyde_enabled': True,
                    **retrieval_metadata  # Include HyDE retrieval metadata
                },
                mode_used=RAGMode.HYDE,
                processing_time=time.time() - start_time
            )

        except Exception as e:
            self.logger.error(f"Generate failed: {e}")
            return RAGResult(
                success=False,
                content="",
                sources=[],
                metadata={'error': str(e)},
                mode_used=RAGMode.HYDE,
                processing_time=time.time() - start_time,
                error=str(e)
            )

    async def _generate_hypothetical_document(self, query: str) -> Optional[str]:
        """
        ç”Ÿæˆå‡è®¾æ–‡æ¡£

        ç»™å®šç”¨æˆ·æŸ¥è¯¢ï¼Œç”Ÿæˆä¸€ä¸ªå‡è®¾æ€§çš„"å®Œç¾ç­”æ¡ˆ"
        è¿™ä¸ªå‡è®¾ç­”æ¡ˆä¼šæ›´æ¥è¿‘çŸ¥è¯†åº“ä¸­çœŸå®æ–‡æ¡£çš„è¯­ä¹‰
        """
        prompt = f"""Given the following question, write a comprehensive, detailed answer as if you were an expert responding to this question.
Write in a style similar to how information would appear in a knowledge base or documentation.

Question: {query}

Write a detailed answer (2-3 paragraphs):"""

        try:
            hypothetical_doc = await self._generate_response(
                prompt,
                model=self.hyde_model,
                temperature=0.7,  # ç¨é«˜æ¸©åº¦ä»¥è·å¾—æ›´è‡ªç„¶çš„æ–‡æ¡£
                max_tokens=300  # é™åˆ¶é•¿åº¦ï¼Œé¿å…è¿‡é•¿
            )

            if not hypothetical_doc:
                self.logger.warning("Failed to generate hypothetical document")
                return None

            return hypothetical_doc.strip()

        except Exception as e:
            self.logger.error(f"Hypothetical document generation failed: {e}")
            return None
